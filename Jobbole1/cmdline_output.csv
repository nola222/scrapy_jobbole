art_url,art_title,art_img_url,create_time,art_content
http://python.jobbole.com/89012/,实现属于自己的TensorFlow(二) - 梯度计算与反向传播,http://pytlab.org/assets/images/blog_img/2018-01-24-%E5%AE%9E%E7%8E%B0%E5%B1%9E%E4%BA%8E%E8%87%AA%E5%B7%B1%E7%9A%84TensorFlow-%E4%B8%80-%E8%AE%A1%E7%AE%97%E5%9B%BE%E4%B8%8E%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD/feature.png,2018-02-04,"中介绍了计算图以及前向传播的实现，本文中将主要介绍对于模型优化非常重要的反向传播算法以及反向传播算法中梯度计算的实现。因为在计算梯度的时候需要涉及到矩阵梯度的计算，本文针对几种常用操作的梯度计算和实现进行了较为详细的介绍。如有错误欢迎指出。,首先先简单总结一下, 实现反向传播过程主要就是完成两个任务:,再附上SimpleFlow的代码地址: ,对于我们构建的模型进行优化通常需要两步：1.求损失函数针对变量的梯度；2.根据梯度信息进行参数优化(例如梯度下降). 那么该如何使用我们构建的计算图来计算损失函数对于图中其他节点的梯度呢？通过,。我们还是通过上篇中的表达式,对应的计算图来说明:,我们把上面的操作节点使用字母进行标记，可以将每个操作看成一个函数，接受一个或两个输入有一个或者多个输出, 则上面的表达,那么根据链式法则我们可以得到,对,的导数为:"
http://python.jobbole.com/88967/,不想再被鄙视？那就看进来！ 一文搞懂Python2字符编码,http://jbcdn2.b0.upaiyun.com/2017/11/8ef4df4888b257b5ea7bbd4b033a519c.png,2017-12-14,"程序员都自视清高，觉得自己是创造者，经常鄙视不太懂技术的产品或者QA。可悲的是，程序员之间也相互鄙视，,流传甚广，作为一个Python程序员，自然最关心的是下面这幅图啦,我们项目组一值使用Python2.7，虽然我们也知道Python3的诸多好处，也曾经蠢蠢欲动过，但由于各种历史原因，以及业务的压力，我们只可能继续使用Python2.7。更悲哀的是，我们组不是那么international，所以代码中还是涉及到大量的中文，因此偶尔也会遇到乱码以及UnicodeError，于是生活在了鄙视链的末端。,因此，本文的目标是解释清楚python2.7中unicode、str的编解码关系，力求在鄙视链中前进一步。,：本文实验主要基于win7，Python2.7；以及Linux ，Python2.7。除非特殊说明，所有的命令都是在终端中交互式输入；如果没有强调平台，那么就是window上的结果。下面是一些默认的环境信息（其重要性后文会介绍）,windows,注意，上面,，在,可以查看。,Linux,首先来说一说gbk gb2312 unicode utf-8这些术语，这些术语与语言无关。,计算机的世界只有0和1，因此任何字符（也就是实际的文字符号）也是由01串组成。计算机为了运算方便，都是8个bit组成一个字节（Byte），字符表达的最小单位就是字节，即一个字符占用一个或者多个字节。字符编码（,g）就是字集码，编码就是将字符集中的字符映射为一个唯一二进制的过程。,计算机发源于美国，使用的是英文字母（字符），所有26个字母的大小写加上数字0到10，加上符号和控制字符，总数也不多，用一个字节（8个bit）就能表示所有的字符，这就是ANSI的“Ascii”编码（American Standard Code for Information Interchange，美国信息互换标准代码）。比如，小写字母‘a’的ascii 码是01100001，换算成十进制就是97，十六进制就是0x61。计算机中，一般都是用十六进制来描述字符编码。,但是当计算机传到中国的时候，ASCII编码就行不通了，汉字这么多，一个字节肯定表示不下啊，于是有了GB 2312（中国国家标准简体中文字符集）。GB2312使用两个字节来对一个字符进行编码，其中前面的一个字节（称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，GB2312能表示几千个汉字，而且与asill吗也是兼容的。,但后来发现，GB2312还是不够用，于是进行扩展，产生了GBK（即汉字内码扩展规范）， GBK同Gb2312一样，两个字节表示一个字符，但区别在于，放宽了对低字节的要求，因此能表示的范围扩大到了20000多。后来，为了容纳少数名族，以及其他汉字国家的文字，出现了GB13080。GB13080是兼容GBK与GB2312的，能容纳更多的字符，与GBK与GB2312不同的是，GB18030采用单字节、双字节和四字节三种方式对字符编码,因此，就我们关心的汉字而言，三种编码方式的表示范围是：,GB18030 》 GBK 》 GB2312,即,。后面也会看到，一个汉字可以用GBK表示，但不一定能被GB2312所表示,当然，世界上还有更多的语言与文字，每种文字都有自己的一套编码规则，这样一旦跨国就会出现乱码，亟待一个全球统一的解决办法。这个时候ISO（国际标准化组织）出马了，发明了”Universal Multiple-Octet Coded Character Set”，简称 UCS, 俗称 “unicode”。目标很简单：废了所有的地区性编码方案，重新搞一个包括了地球上所有文化、所有字母和符号 的编码！,unicode每种语言中的每个字符设定了统一并且唯一的二进制编码，以满足跨语言、跨平台进行文本转换、处理的要求。unicode编码一定以u开头。,但是，unicode只是一个编码规范，是所有字符对应二进制的集合，而不是具体的编码规则。或者说，,。这个就跟GBK这些不一样，GBK是表里如下，表现形式即存储形式。,比如汉字“严”的unicode编码是u4e25，对应的二进制是1001110 00100101，但是当其经过网络传输或者文件存储时，是没法知道怎么解析这些二进制的，容易和其他字节混在一起。那么怎么存储unicode呢，于是出现了UTF（UCS Transfer Format），这个是具体的编码规则，即UTF的表现形式与存储格式是一样的。,因此，可以说，,。只不过，转换成Utf-8，大家都能懂，更懂用，而转换成GBK，只有中国人才看得懂,UTF也有不同的实现，如UTF-8， UTF-16， 这里以UTF-8为例进行讲解（下面一小节引用了,）。,UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。UTF-8的编码规则很简单，只有二条：,1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。,2）对于n字节的符号（n>1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。,下表总结了编码规则，字母x表示可用编码的位。,以汉字“严”为例，演示如何实现UTF-8编码。,已知“严”的unicode是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800-0000 FFFF），因此“严”的UTF-8编码需要三个字节，即格式是“1110xxxx 10xxxxxx 10xxxxxx”。然后，从“严”的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，“严”的UTF-8编码是“11100100 10111000 10100101”，转换成十六进制就是E4B8A5。,下面使用Python语言来验证上面的理论。在这一章节中，当提到unicode，一般是指unicode type，即Python中的类型；也会提到unicode编码、unicode函数，请大家注意区别。,另外，对于编码，也有两种意思。第一个是名字，指的是字符的二进制表示，如unicode编码、gbk编码。第二个是动词，指的是从字符到二进制的映射过程。不过后文中，编码作为动词，狭义理解为从unicode类型转换成str类型的过程，解码则是相反的过程。,在python2.7中，有两种“字符串”类型，分别是str 与 unicode，他们有同一个基类basestring。str是plain string，其实应该称之为,，因为是每一个字节换一个单位长度。而unicode就是unicode string，这才是真正的,，一个字符（可能多个字节）算一个单位长度。,python2.7中，unicode类型需要在文本之间加u表示。,从上可以看到，第一，us、s的类型是不一样的；其二，同一个汉字，不同的类型其长度也是不一样的，对于unicode类型的实例，其长度一定是字符的个数，而对于str类型的实例，其长度是字符对应的字节数目。这里强调一下，s（s = ‘严’）的长度在不同的环境下是不一样的！后文会解释,这是python中两个magic method，很容易让新手迷糊，因为很多时候，二者的实现是一样的，但是这两个函数是用在不同的地方,_str__， 主要是用于展示，,或者,的时候调用，返回值一定是一个str 对象,__repr__， 是被,， 或者在终端直接打,的时候调用,可以看到，不使用print返回的是一个更能反映对象本质的结果，即us是一个unicode对象（最前面的u表示，以及unicode编码是用的u），且“严”的unicode编码确实是4E25。而print调用可us.__str__，等价于print str(us)，使得结果对用户更友好。那么unicode.__str__是怎么转换成str的呢，答案会在后面揭晓,前面已经提到，unicode只是编码规范（只是字符与二进制的映射集合），而utf-8是具体的编码规则（不仅包含字符与二进制的映射集合，而且映射后的二进制是可以用于存储和传输的），即utf-8负责把unicode转换成可存储和传输的二进制字符串即str类型，我们称这个转换过程为编码。而从str类型到unicode类型的过程，我们称之为解码。,Python中使用decode()和encode()来进行解码和编码，以unicode类型作为中间类型。如下图所示,。for example,从上可以看出encode与decode两个函数的作用，也可以看出’严’的utf8编码是E4B8A5。,就是说我们使用unicode.encode将unicode类型转换成了str类型，在上面也提到unicode.__str__也是将unicode类型转换成str类型。二者有什么却比呢,首先看看文档,注意：str.encode 这里的str是basestring，是str类型与unicode类型的基类,可以看到encode方法是有可选的参数：encoding 和 errors，在上面的例子中encoding即为utf-8；而__str__是没有参数的，我们可以猜想，对于unicode类型，__str__函数一定也是使用了某种encoding来对unicode进行编码。,首先不禁要问，如果encode方法没有带入参数，是什么样子的：,不难看出，默认使用的就是ascii码来对unicode就行编码，为什么是ascii码，其实就是,编码（sys.getdefaultencoding的返回值）。ascii码显然无法表示汉字，于是抛出了异常。而使用utf-8编码的时候，由于utf能够表示这个汉字，所以没报错。,如果直接打印ss（us.encode(‘utf-8’)的返回值）会怎么样,结果略有些奇怪，us.__str__(即直接打印us）的结果不一样，那么试试encoding = gbk呢？,U got it! 事实上也是如此，python会采用,的编码（用locale.getdefaultlocale()查看，windows是为gbk）将unicode编码成str类型。,在Linux（终端编码为utf-8），结果如下：,注意上面的乱码！,在上上小节，介绍了unicode可以通过utf-8编码（encoding = utf-8），转换成utf-8表示的str，在上一节也可以看出unicode也可以通过gbk编码（encoding=gbk），转换成gbk表示的str。这里有点晕，留作第一个问题，后面解释,unicode与utf8之间的相互转换可以计算得知，但unicode与gbk之间的相互转换没有计算公式，就只能靠查表了，就是说有一张映射表，有某一个汉字对应的unicode表示与gbk表示的映射关系,从上不难看出，严的unicdoe编码是4e25，GBK编码是d1cf，因此us通过gbk编码就是d1cf。同样也能看到，GB18030，GBK，GB2312是兼容的,， ss是一个str类型，直接打印结果有点奇怪，一个“涓”字，那一个str类型的“涓”是哪些二进制组成的呢,可以看到，str类型的“涓”，其二进制是E4B8，跟’严’的utf8编码（E4B8A5）相差了一个A5，那么就是因为A5显示不出来，验证如下：,因此，只是碰巧显示了“涓”而已，事实上ss跟“”涓“”毫无关系,在上上小节，提到了utf-8编码的str，与gbk编码的str，感觉有点绕。我们知道，一个汉字‘严’，可存储的编码格式可以是gbk（’xd1xcf’），也可以是utf-8（’xe4xb8xa5’），那么当我们在终端敲入这个汉字的时候，是哪一种格式呢？取决于,windows上（默认终端编码为gbk）：,Linux上（默认终端编码为utf-8）：,同样一个汉字，同样都是Python中的str类型，在不同的编码格式下，其二进制是不一样的。因此，其长度也是不一样的，对于str类型，其长度是对应的字节长度。,也能看出gbk编码的字节长度一般小于utf-8，这也是gbk继续存在的一个原因。,这里，,！这个也不难理解。,str类型到unicode类型的转换，出了上面提到的str.decode，还有一个unicode函数。两个函数的签名为：,二者参数相同，事实上二者是等价的，encoding的默认值也是一样的，都是sys.getdefaultencoding()的结果。for example：,第一个UnicodeDecodeError，就是因为系统默认的编码是asill吗；第二个UnicodeDecodeError，是因为，s（str类型的实例）的编码取决于终端默认编码（即windows下的gbk），为了能打印出来，也就必须用gbk编码来表示这个str，因此只能查询gbk与unicode的映射表将s转换成unicode类型。,在诸多Python代码中，都会看到这么一段：,不难猜想，,跟,是配对的，为啥要将系统的默认编码设置成utf-8，其实就是解决str到unicode的转换问题。,上一小节已经提到过，使用unicode函数将str类型转换成unicode类型时，要考虑两个因素：第一，str本身是什么编码的；第二，如果没有传入encoding参数，默认使用sys.getdefaultencoding。encoding参数必须与str本身的编码对应，否则就是UnicodeDecodeError。,写python代码的程序都知道，我们要在py文件第一行写上：,这句话的作用在于，告诉编辑器，该文件里面的所有str都采用utf-8编码，且存储文件的时候也是使用utf-8格式。,然后文件中就会使用下面的这种代码。,使用unicode强制转换的时候，都不习惯带参数，为了保证encoding参数必须与str本身的编码一致，所以使用,将系统默认编码设置为utf-8,下面介绍几种常见的乱码与异常UnicodeError， 大多数乱码或者异常的原因在前面已经讲过了，同时，对于一些乱码，也试图给出可行的解决办法。,UnicodeError包括UnicodeDecodeError 与UnicodeEncodeError ，前者是decode也就是str转unicode的时候出了异常，后者则是encode也就是unicode转str的时候出了异常。,例子就是上面反复提到的例子,如果一个str类型来自网络或者文件读取，最好先按照对端encode的方式先decode成unicode，然后再输出（输出的时候会自动转换成期望终端支持的编码格式的str）,直接上例子,可以看到，‘囍’字可以被gbk编码，但是不能被gb2312编码。,在上面讲unicode函数的时候已经举过例子，会爆出UnicodeDecodeError 异常。,这个错误比较的原因，更多来自str到unicode的默认转换，比如一个str与一个unicode相加的时候：,unicode 与 str相加，str会转换为unicode,使用默认的unicode(strobj, encoding = sys.getdefaultencoding()),某些情况下，我们打印出一个str类型，看到结果是’\u4e25’， 或者’u4e25’，对于这个字符串，是不是很眼熟，不错， ‘严‘的unicode编码就是u’u4e25’。仔细一看，只是在引号前面多了一个u（表示是一个unicode类型）。那么当我们看到一个’u4e25’的时候，怎么知道对应的汉字是什么？对于已知的这种格式的str，自然可以手动加一个u，然后在终端输出，但是如果是一个变量，需要自动转换成unicode呢，这个时候就可以使用,中的unicode_escape,有时候，也会看到类似这样的str，’\xd1\xcf’， 看起来也很熟悉，跟汉字“严”的gbk编码’xd1xcf’很像，区别在于前者多了一个‘’， 这样就无法解释成一个十六进制了。解决办法是,中的string_escape,在这里留下一个问题：,返回值是True 还是 False呢？当然这里故意省去了上下文环境，不过明确的说，在不同的编码环境下，答案是不一样的，原因都在上文中！,不管怎么样解释，python2.x中的字符编码还是一件让人头疼的事情，即使搞懂了，之后遇到了也可能忘记。对于这个问题，诸多建议如下：,第一：使用python3，就不用再纠结str于unicode了；但是这个很难开发者说了算；,第二：不要使用中文，注释什么的都用英文；理想很丰满，现实很难，只是导致大量的拼音；,第三：对于中文字符串，不要用str表示，而是用unicode表示；现实中也不好实施，大家都不愿意多写一个u,第四：只在传输，或者持久化的时候对unicode进行encode，相反的过程时decode,第五：对于网络接口，约定好编解码格式，强烈建议使用utf-8,第六：看到UnicodeXXXError不要慌，如果XXX是Encode，那么一定是unicode转str的时候出了问题；如果是Decode，一定是str转unicode的时候出了问题。"
http://python.jobbole.com/88705/,使用 Python 开始机器学习,http://wx1.sinaimg.cn/mw690/63918611gy1fmukayefezj20sw0e447u.jpg,2017-12-26,"目前机器学习红遍全球。男女老少都在学机器学习模型，分类器，神经网络和吴恩达。你也想成为一份子，但你该如何开始？,在这篇文章中我们会讲Python的重要特征和它适用于机器学习的原因，介绍一些重要的机器学习包，以及其他你可以获取更详细资源的地方。,Python很适合用于机器学习。首先，它很简单。如果你完全不熟悉Python但是有一些其他的编程经验（C或者其他编程语言），要上手是很快的。其次，Python的社区很强大。这使得Python的文档不仅条理性好，而且容易读。你还可以在StackOverFlow上找到关于很多问题详细解答（学习基石）。再次，一个强大的社区带来的副产品就是大量有用程序库（Python内部自带的和第三方软件），基本上可以解决你所有的问题（包括机器学习）。,Python是很慢。它不是执行最快的语言，拥有那么多好用的抽象是要付出代价的。,但这是个可以解决的问题：程序库可以把计算量繁重的部分外包给其他更高效（但更难使用）的语言，例如C和C++。比如NumPy这个提供数值运算的程序库，就是用C写的，运行速度超快。在实际运用中，几乎所有程序库都会使用NumPy去完成计算繁重的部分。如果你看到Numpy，你应该想到它很快。,所以你是可以让程序的运行速度跟它的低层语言实现的运行速度相比拟的。你没有必要担心程序的运行速度。, ,你刚开始学机器学习吗？如果你需要一个涵盖了特征工程，模型训练和模型测试所有功能的程序库，,是你的最佳选择！这个优秀的免费软件提供了机器学习和数据挖掘所需要的所有工具。它是目前Python机器学习的标准库。要使用任何成熟的机器学习算法都推荐使用这个库。,这个程序库支持分类和回归，实现了基本所有的经典算法（支持向量机，随机森林，朴素贝叶斯等等）。程序库的设计让迁移算法十分容易，使用不同的算法做实验非常轻松。这些经典算法可用性很强，能用于大量不同的情况。,但这并不是Scikit-learn的全部功能，它同样可以用来做降维，聚类等等任何你所能想到的。由于它构建在Numpy和Scipy之上（所有的数值计算都是由C语言来完成的），它的运行速度也超快。,可以告诉你这个库的功能，如果你想学习如何使用它，可以阅读,不算是一个机器学习的程序库，但它是做自然语言处理（NLP）必须的一个库。除了用于文字处理的功能，例如聚类，分词，词干提取，标记，解析等，它还包含了大量的数据集和其他关于词法的资源（可用于模型训练）。,把所有这些打包在一起的好处就不用再多说了。如果你对NLP感兴趣，可以看看,!,被广泛应用于工业界和学术界，它是所有深度学习架构的鼻祖。Theano是用Python，结合Numpy实现的。你可以用它来构建用多维数组实现神经网络。Theano会处理所有数学计算，你不需要知道底层的数学公式实现。,早在支持使用GPU进行计算不像今天这样普及的时候，Theano就已经提供了对GPU计算的支持。这个程序库目前已经非常成熟，能够支持很多不同类型的操作。这使得Theano可以在和其他库比较的时候胜出。,目前关于Theano最大的问题是API不是很好用，对于新手来说上手困难。不过市面上已经有了解决这个问题的封装包，比如,, , 和 ,，都可以简化Theano的使用。,谷歌大脑团队为了内部使用创造了,，2015年将其开源化。设计初衷是取代他们已有的封闭机器学习框架DistBelief，据说该构架太过于依赖Google的整体构架，也不够灵活，在分享代码的时候非常不方便。,于是就有了TensorFlow。谷歌从以前的错误中吸取了教训。许多人认为TensorFlow是Theano的改进版，它提供了更灵活和好用的API。可以用于科研和工业界，同时支持使用大量的GPU进行模型训练。TensorFlow支持的操作没有Theano多，但是它的,比Theano好。,TensorFlow目前非常流行。如果今天这篇文章里面提到的名字你只听说了一个，那很有可能是这个。每天都有新的提到TensorFlow的博文或学术文章发表。这个流行度提供了大量的用户和,，新人很容易上手。,是一个提供更高层神经网络API的库，它可以基于Theano或者TensorFlow。它拥有这两个库强大的功能却又同时大大地简化了使用难度。它将用户的体验放在首要地位，提供简单的API和很有用的错误信息。,同时Keras的设计基于模块，这就使得你能自由组合不同的模型（神经层，成本函数等等），而且模型的可扩展性很好，因为你只需要简单的将新模块跟已有的连起来即可。,有人觉得Keras太好用了，,。如果你开始用深度学习，可以看看, 和 ,，对于你可以用它做什么有个数。如果你要学习使用它，可以从 ,开始。,两个类似的库有, 和 ,, 但它们只支持Theano。如果你试过了Keras但是你不喜欢它你可以试试这些其他的库，也许它们更适合你。,还有一个有名的深度学习架构是,它是用Lua实现的。Facebook用Python实现了Torch，叫做,，并将它开源了。用这个库你可以使用Torch使用的低层的库，但是你可以使用Python而不是Lua。,PyTorch对查错的支持很好，这是因为Theano和TensorFlow使用符号计算而PyTorch则不是。使用符号计算就表明在一行代码被解释的时候，一个操作（x+y）并不会被执行，在那之前，它必须先被编译（解释成CUDA或者C语言）。这就让用Theano和TensorFlow的时候很难查错，因为很难把报错跟当前的代码联系起来。这样做有它的好处，不过查错简单不在其中。,如果你想开始学PyTorch，,适合初学者也会包含有难度的内容。,你讲了这么多机器学习的包，我应该用哪一个？我怎样比较它们？我从哪里开始？,你可以试用我们面向初学者的平台Ape Advice™，就不用烦细节的问题了。如果你完全没有接触过机器学习，从,开始。你可以了解标记，训练和测试是怎样工作的，以及一个模型是如何被建立的。,如果你想试试深度学习，从,开始，毕竟这是大家公认的最简单的框架。你可以先试试，找找感觉。当你有点经验之后，你可以开始考虑你最需要的是什么：速度，不同的API，或者别的什么，之后你就能更好地决定了。,目前有,比较Theano，Torch和TensorFlow。没有人能说哪个最好。你要记住的是所有包都支持很多东西，而且也在不断改进，想相互比较它们也越来越难。六个月前的标准有可能已经过时了，一年前的评价说框架X没有Y功能也不一定还有效。,最后，如果你想用NLP，可以试试,!我们的这个平台所提供的用户界面让建造模型，训练模型和改进NLP模型都非常容易试下。你可以用事先训练好的模型处理常见问题（意见挖掘，话题探测或者提取关键字），也可以为你特有的问题设计一个新的算法。你不需要担心底层实现或者发布你的模型，我们可扩展的云系统会帮你完成这些。你可以,，马上开始试用我们超棒的API。,关于机器学习的网络资源很多！下面列举一些：,这篇关于用Python库做机器学习的简介就到此为止。我想强调的是不要被细节吓住了，放手尝试。让你的好奇心指导你前进，不要害怕进行不同的实验。"
http://python.jobbole.com/88977/,Ruby 和 Python 分析器是如何工作的？,http://jbcdn2.b0.upaiyun.com/2015/02/591d8b55a524f825dd29a22b8df70000.jpg,2017-12-24,"你好！ 我作为一名编写Ruby profiler的先驱，我想对现有的Ruby和Python profiler如何工作进行一次调查。 这也有助于回答很多人的问题：“你怎么写一个profiler？”,在这篇文章中，我们只关注CPUprofiler（而不是内存/堆profiler）。 我将解释一些编写profiler的一般基本方法，给出一些代码示例，以及大量流行的Ruby和Pythonprofiler的例子，并告诉你它们是如何工作的。,在这篇文章中可能会有一些错误（为了研究这篇文章，我阅读了14个不同的分析库的代码部分），请让我们开始吧！, ,有两种基本CPU profilers类型 – ,profilers和,profilers。,tracingprofilers记录您的程序所调用的每个函数，然后在最后打印出报告。 samplingprofilers采用更加统计化的方法 – 他们每隔几毫秒记录程序的堆栈情况，然后报告结果。,使用sampling profilers而不是tracing profilers的主要原因是sampling profilers的开销较低。 如果每秒只抽取20或200个样本，那不会花费多少时间。 而且它们非常有效率 – 如果您遇到严重的性能问题（比如80％的时间花费在1个慢速函数上），那么每秒200个样本通常就足以确定那个函数的问题所在了！,下边类出了我们这篇文章要讨论的分析器(,)。我之后将会解释表格中的术语(setitimer, rb_add_event_hook, ptrace)。这里最有趣的是，所有的分析器都是通过一小部分函数的特性实现的。,“gbd hacks”并不完全是一个Python分析器：它是一个讲述如何实现用脚本包装gdb来实现hacky分析器的链接。由于新版本的gdb事实上会展开Python堆栈，所以也是和Python有关的。一种简化版的pyflame。,在我们开始详细分析这些分析器之前，有一个非常重要的事情需要说明一下：除fyflame外所有的分析器都运行在你的Python/Ruby进程里面。如果你在一个Python/Ruby程序里面，你通常可以很容易的获取该程序的堆栈。例如下边代码中的简单的Python程序答应出每一个运行线程的堆栈：,你可以从下边的输出里面看到堆栈的函数名，行号，文件名等你在做分析的时候需要的所有信息。,在Ruby程序中，获取堆栈也很容易：你只需要通过caoller来获取堆栈。,这些分析器处于性能考虑都是C扩展所有它们有一点不一样，但是Ruby/Python程序的C扩展也可以很容易的获取调用堆栈。,我调查过上边表格中所有的追踪分析器:rblineprof、ruby-prof和cProfile。它们工作原理基本相同。它们都记录所有的函数调用并且用C语言编写来降低耗时。,它们是如何工作的呢？Ruby和Python都允许指定一个回调函数，当各种解释事件(例如调用一个函数或者执行一行代码)发生的时候调用。当回调函数被调用的时候，会记录堆栈供以后分析。,我认为确切了解在代码中哪里设置这些回调函数是很有用的，所以我连接了所有在github上边的相关代码。,在Python中，可以通过PyEval_SetTrace或者 PyEval_SetProfile设置回调函数。在Python官方文档的,里有说明。文档中说道：除了追踪函数会收到line-number事件外“PyEval_SetTrace和PyEval_SetProfile一样。,在Ruby里，你可以用rb_add_event_hook来设置回调，我找不到任何关于此处是如何调用的文档,prof_event_hook的类型是,这看起来像极了Python的PyEval_SetTrace，但是比Python更灵活——您可以选择你关注的事件类型（就像“函数调用”一样）。,追踪分析器的主要的缺点是它的实现方式是对于每个函数/行代码都执行固定的次数，这样可能使你做出错误的决定。例如，如果你有某个事物的两个实现：一个通过大量的函数调用实现，另一个没有大量函数调用，两个实现耗时相同，有大量函数调用的相比没有大量函数调用的在分析的时候会变得慢。,为了测试这一点，我做了一个包含下边内容的小文件test.py，并且比较了python -mcProfile test.py和python test.py的耗时。python test.py执行需要大约0.6秒，python -mcProfile test.py执行需要大约1秒。对于这个特定的例子cProfile引入了额外的大约60%的开销。,cProfile文档中说：,这似乎是一个合理的说法：上边的示例(执行350万次函数调用)显然不是个典型的Python程序，并且几乎任何其他程序开销都比该示例小。,我没有测试ruby-prof(一个ruby追踪分析器)的开销，但是它的README说：,现在讨论第二种分析器：采样分析器。,大多数Ruby和Python的采样分析器都是通过系统调用setitimer实现的。这是怎么回事呢？,好吧，比方说你想要每秒获取一个程序的堆栈50次，一种方法是：,如果你想要看一个实际的用setitimer实现采样分析器的例子的话，我认为,是一个最好的例子，stacksampler.py是一个有用的有效的分析器并且代码只有大约100行，好酷啊！,stacksampler.py只有100多行的一个原因是：当你把一个Python函数注册成信号处理器的时候，该函数被传送到你的Python程序的当前堆栈中。所以stacksampler.py信号处理器注册是非常简单的：,它只是将堆栈从堆栈帧中取出来并且增加堆栈查看计数，非常简单！非常酷！,我们看继续剩下的使用setitimer的分析器并找到它们调用settimer的代码：,关于setitimer很重要的一点是，你需要决定,。你想要真正的20 ms的“挂钟”时间？你想要20 ms的用户CPU时间？或者20 ms的用户+系统CPU时间？如果你仔细看电话网站上的内容，你就会发现，这些分析器实际上对setitimer做出了不同的选择 — 有时候它是可配置的，有时候却不可。setitimer手册页十分精悍，并且值得去读懂上面所有的观点。, 在推特上指出了一个使用setitimer时出现的有趣的问题，这个问题和这个问题拥有的一系列更多细节。,有些采样分析器不使用setitimer：,所有这3个分析器使用挂钟定时采样。, ,有很多关于pyflame是如何工作的。我不打算在这里进行介绍，但是Evan Klitke写了很多关于它的非常好的博客：,还有很多在 ,。所有有趣的东西，我会更详细地阅读——也许ptrace是比实现一个Ruby分析器process_vm_readv更好的方法！（process_vm_readv开销低，因为它不会阻断进程，但它也可以给你一个不一致的快照，因为它不会阻断进程：））, ,在这篇文章中我没有涉及很多重要的细节 – 比如我基本上说vmprof和stacksampler是一样的（但实际上它们不是 – vmprof支持线性分析和用C语言编写的Python函数分析，我相信这在分析器中引入了更多的复杂性）。 但一些基本原理是一样的，所以我认为这项调查是一个很好的起点。"
http://python.jobbole.com/88318/,码农不识贝叶斯，虽知数据也枉然,http://jbcdn2.b0.upaiyun.com/2015/02/301f8986e2ad36a068277f2795edeeb9.jpg,2017-12-27,"数据的重要性毋庸置疑，但是如何让数据产生价值呢？,对一个全栈老码农而言，经常在开发或者研发管理的时候遇到各种预测、决策、推断、分类、检测、排序等诸多问题。面对“你的代码还有 bug 么？”这样的挑战，一种理智的回答是，我们已经执行了若干测试用例，代码中存在bug的可能性是百分之零点几。也就是说，我们对当前程序中没有bug的信心是百分之九十九点几。这实际上就是一直贝叶斯思维，或者说使用了贝叶斯方法。不论我们看到，还是没有看到，它都在那里，熠熠生辉。,如果预测当前软件有没有bug呢？还是要从贝叶斯定理看起。,对老码农来说，贝叶斯定理的概率表达相对清晰，理解起来会相对容易。回忆一下我们学过的概率论，联合概率是满足交换律的，即：,对联合概率以条件概率展开：,从而得到：,简单的变换一下，得到：,大功告成，这就是神奇的贝叶斯定理。其中：,还可以加点料，在计算P（A）的时候，可以用加法定理表示：,从而有：,其中B_ 是与B相反的事件。就测试与bug 之间的估算而言，《,》一文给出了贝叶斯推断的结果，其中就使用了这样的方法。,贝叶斯方法是一个非常通用的推理框架，用客观的新信息更新我们最初关于某个事物的信念后，就会得到一个新的改进了的信念。通过引入先验的不确定性，允许了初始推断的错误，获得了更新的证据后，也没有放弃初始的推断，而是调整为更符合目前的证据。,但是，P（A|B） 和 P（B|A） 之类的经常让人混淆，@待字闺中的陈老师给出了理解的一个关键点，区分出规律和现象，就是将A看成“规律”，B看成“现象”，那么贝叶斯公式看成：, ,陈老师在《这的理解贝叶斯公式吗》和《又一个生活中的贝叶斯应用》给出了几个通俗易懂的例子，这里不再赘述。,回归到码农生活，我们在改善系统功能的时候，通常的一个手段是AB测试。AB测试是用来检测两种不同处理方式的差异化程度的一种统计设计模式，例如两个网站谁会带来更高的转化率，这里的转化可以是用户的购买、注册、或其他的行为。AB测试的关键点在于组别之间只能容许一个不同点。实验后的分析一般都是用假设检验完成的，例如均值差异检验或者比例差异检验，往往涉及Z分数或令人困惑的p值，而用贝叶斯方法则会自然的多。,对A，B两个网站的转化概率进行建模。转化率在0～1之间，可采用Beta分布。如果先验是Beta（a1，b1），且 观测到N次访问里有X次转化，那么此时的后验分布是Beta（a1+X,b1+N-X). 假设先验是Beta（1，1），等价于【0，1】上的均匀分布，则示例代码如下：,使用贝叶斯方法，是从思考数据是如何产生的开始。,
1）什么随机变量能过描述这些统计数据,
2）确实概率分布的所需参数,
3）参数对应早期行为，或后期行为，定义各种变化点,
4）定义参数的概率分布,
5）参数概率分布的变量选择，直到一个可以假设的均匀分布,对先验及后验概率的选择，针对应用场景而定。就先验分布而言，除了常见的分布外，还有：,
* Gamma分布，指数随机变量的推广,
* 威沙特分布 ，是所有半正定矩阵的分布，是一个协方差矩阵的适当的先验。,
* Beta分布，随机变量定义在0到1之间，使其成为概率和比例的热门选择。,
* 幂律分布，满足公司规模和公司数量之间的关系,在AB测试中使用了Beta分布， 应用了一个Beta先验分布连同二项式生成的观测数据形成一个Beta后验分布这一原理。,当面对多种对象之间的因果关系的时候，贝叶斯方法演变成为了贝叶斯网络。,贝叶斯网络是为了解决不定性和不完整性问题而提出的，在多个领域中获得了广泛应用。贝叶斯网络是基于概率推理的图形化网络，而贝叶斯公式则是这个概率网络的基础。贝叶斯网络中的每个点代表一个随机变量，都是具有实际含义、需要人为设计的，点和点之间的边代表不确定的因果关系，例如 节点E直接影响到节点H，即E→H，则用从E指向H的箭头建立结点E到结点H的有向弧(E,H)，权值(即连接强度)用条件概率P(H|E)来表示。,实际上，如果事物之间的关系能够用一条链串起来，形成了贝叶斯网络的一个特例——马尔可夫链，换个角度看， 贝叶斯网络是马尔可夫链的非线性扩展。贝叶斯网络中当某点的一个证据出现后，整个网络中事件的概率都会变化。,简单地，由于多个变量间存在着可能的依赖性，贝叶斯网络说明了其中的联合条件概率分布，允许在变量的子集间定义条件独立性。使用贝叶斯网络的过程与使用贝叶斯方法的过程是类似的：,例如， 社交网络中不真实账户的检测问题。首先确定网络中的随机变量：,
* 账户的真实性 A,
* 头像的真实性 H,
* 发帖即日志的密度 L,
* 好友的密度 F,使用观测值示例化H，L，F，把随机值赋给A，得到,P（A|H,L,F) = P(H|A)P(L|A)P(F|A,H),然后就可以在社交网络中尝试使用该推理结果了。在《算法杂货铺——分类算法之贝叶斯网络》一文中对这一例子给出了相对详细的说明。,可以说，贝叶斯方法席卷了整个概率论，并将应用延伸到各个问题领域，所有需要作出概率预测的地方都可以见到贝叶斯方法的影子，特别地，贝叶斯方法对机器学习能够有什么帮助呢？,机器学习在业界炙手可热，但我们在机器学习里同样会遇到预测、决策、分类、检测等问题，贝叶斯方法同样大有用武之地。,机器学习中有大量的模型，如线性模型、非线性模型，可以采用贝叶斯方法来做模型的预测。也就是说，某一场景可能采用的模型是无限多的，可以用概率分布去描述它。对于假设的先验，对新来的样本做预测如计算它的似然，然后用前面推出来的后验分布做积分，这个给定模型下样本的似然，就是所有可能模型的分布。,机器学习中模型的选择和比较也是一个常见的问题。例如，在分类问题时，我们使用线性模型还是深度学习的非线性模型呢？贝叶斯方法是这样考虑的： 用A 表示一个模型类别，可能是线性模型，B 表示另一个模型类别，可能是非线性模型。在同样的数据集X下，计算在A，B 情况下观察到训练集的似然Ma，Mb，然后比较Ma和Mb，这是贝叶斯方法做模型选择的一个基本规则。,实际上， 贝叶斯定理是信息处理的一种准则， 输入是一个先验分布和一个似然函数，输出是一个后验分布。对机器学习中的模型本身，也可以通过贝叶斯方法尝试改进，例如贝叶斯SVM, 高斯过程的贝叶斯等等。,另外，贝叶斯方法对深度学习而言，至少在调参的这一环节还是很有用的。在神经网络中，每一层参数如卷积核的大小和数量等，都不会在深度学习中被模型自动优化的，需要手工指定，这或许就是贝叶斯优化。,感慨一下，码农不识贝叶斯，虽知数据也枉然呀！"
http://python.jobbole.com/88958/,Python 开发者的 6 个必备库,http://jbcdn2.b0.upaiyun.com/2017/11/722f435a6aa288edb0916821e53d878d.png,2017-11-28,"无论你是正在使用 Python 进行快速开发，还是在为 Python 桌面应用制作原生 UI ，或者是在优化现有的 Python 代码，以下这些 Python 项目都是应该使用的。,Python 凭借其易用的特点，已经被工业界和学术界广泛采用。另一方面，Python 丰富的第三方项目——库、附加组件，和辅助的开发成果——使得 Python 语言的应用范围被不断扩大。,其中一些项目，比如 PyInstaller 和 WxPython ，为那些制作桌面应用和终端应用的 Python 开发者提供了便利。其他的项目, 比如 PyPy , 则是用来给服务器端 Python 应用提供额外的动力。还有一些，像 PBR 、CFFI 和 MyPy , 适用于差不多所有五花八门的 Python 应用，无论在什么地方运行。,如果你是一个 Python 开发者，所有这六个项目都值得你来熟悉一下。而且所有这些项目，在近几周都发布了新的主要版本。,如果你需要更快的 Python 应用程序，最简单的实现的方法就是通过 PyPy ，Python 运行时与实时（JIT）编译器。与使用普通的 Python 对等程序相比，使用 PyPy 的 Python 应用程序的运行速度平均提升7.5倍。不幸的是，PyPy 与许多 Python 的明星框架并不是很好地兼容。, 在解决这个问题上取得了重大进展。,数据科学框架 NumPy 和 Pandas 现在运行在 PyPy 的 Python 2.7 兼容版本上。这些框架的大部分问题来源于 PyPy 与现有 C 代码的接口。为了解决这个问题，PyPy 5.9 对 CFFI 库（见下文）和 PyPy 的 Python C API 兼容性层进行了改进。,
此外，在 5.9 发布版本中，PyPy 的 JSON 解析器在处理多种 JSON 对象，尤其是那些重复使用的相同的词典键值时，明显更快。,官方二进制文件包括 Windows、Mac OS 和 Linux 的不同 CPU 架构。请注意，为了兼容 Python 2.7 和 Python 3.5 ，存在不同的二进制文件，因此请确保你正在获取与你将要运行的脚本所匹配的版本。,（CFFI）为 Python 应用程序与独立 C 库的交互提供了一种机制。虽然 Python 的 stock 版本，CPython，也拥有自己的库来完成此类功能，称为 , ，但对 Python 用户来说，比起 Ctypes ，CFFI 使得与 C 库的交互更容易、更简便。,与 PyPy 一起更新的 , 增加了很小但很有用的改动。现在可以在即将发布的 Python 3.7 上使用betas了，在 Windows 上更好地支持外部错误处理，并支持 C 语言中更多的现代标准类型，例如 float/double _Complex 和 char16_t和char_32t 类型。最后两个也是最重要的，在 C 库中默认使用 Unicode 编码。,CFFI 在 ,，或通过 Python 的 pip 工具安装：pip install cffi 。源码和问题跟踪可以在 , 上找到。,关于 Python 的最常见的问题之一是“如何从 Python 脚本中生成独立的可执行文件？” , 一直是对此最好的答案之一。,PyInstaller 将 Python 应用程序打包到单目录或单文件的可执行文件中，捆绑任何所需的第三方库，并可与绝大多数常见的库和框架配合使用。, 中最大的改进是对 Python 3.6 的支持，因为鉴于 Python 3.6 已经发布这确实是必要的,PyInstaller 3.3 还包括一个更广泛兼容的引导加载程序，适用于 Windows 可执行文件，并扩展了对捆绑常见库（如 QT、GTK +、NumPy 和 Django ）的支持。,PyInstaller 在不久之后可能添加的一个功能是交叉打包，例如，在 Windows 上创建 Mac 兼容的应用程序。你需要在要部署的同一平台上运行该 PyInstaller ，无论是 Windows、Mac 还是 Linux 。,，也可通过 Python 的 pip 工具安装：pip install pyinstaller 。对于那些需要自己编译引导加载程序的人，, 上找到，但对多数人而言是不需要这么做的。,Setuptools 是用于打包 Python 项目的标准的 Python 问题子系统。管理特定项目的 Setuptools 可能会变得非常繁琐，特别是在自动生成需求、管理文档文件或编辑项目贡献者数据时。,, Python Build Reasonableness 的缩写，是以一致的方式用于管理 Setuptools 包的库。它可以自动化许多 Setuptools 打包的设置，例如版本号、生成作者和 ChangeLog 文件，以及生成 Sphinx 风格的文档。PBR 最初是作为 OpenStack 项目的一部分开发的，但现在你所使用 PBR 中维护的内容与 OpenStack 已经没有任何联系了。,，并且可以和 pip 一起安装，只需要输入 pip install pbr 即可。 源码可在 , 上下载。,想要实现跨平台桌面应用程序的 Python 开发人员可以从多个工具包中进行选择。 ,，是 , 库的一个封装，使用了其所支持主机平台的原生 UI 元素，包括 Windows、Mac、Linux 和其他类 Unix 操作系统。,早期版本的 WxPython 被放弃了是由于其传统的设计决策，使其变得越来越慢，而且不太适合使用。为了解决这个问题，WxPython 的开发人员对 WxPython 的 4.0 分支做了重大改变。,目标是允许开发人员更快地上手 WxPython ，并且使通过它创建的框架和应用程序更加高性能和易维护。然而，为了使用 WxPython 4.0 ，任何现有的使用 WxPython 项目都,。,WxPython 4.0 官方版本依然是 beta 版。它可以在 ,，即通过 pip install wxpython 命令。在正式发布前它可能会更新数次，注意经常检查更新。,那些想直接破解的人可以查看 ,。请注意，WxPython 的 4.0 分支以 “Phoenix” 代号进行标记的，以使其与早期版本不同。,Python 的动态性既是一种福音，也是一种烦恼，对于快速构建软件非常棒，但是当代码难以推理、测试和调试时，并不是很棒。, 在编译时向 Python 添加静态类型检查，使 Python 程序更加一致和可维护，并且不会增加运行时开销。, 添加了不同,的支持，该协议是用于 Python 子类的目前实验性类型的功能。它还在仅用于包含特定类型的对象的字典中添加 “TypedDict” 类型，并且可以逐个对文件进行更严格的类型检查的选项。,Mypy 可以在 ,，并通过 pip install mypy 来安装。那些对 Mypy 实现感兴趣的人可以通过 , 检出源码。"
http://python.jobbole.com/88954/,让 Python 更加充分的使用 Sqlite3,http://jbcdn2.b0.upaiyun.com/2015/02/edecceebedd0d04aa17bccba430ddcaf.jpg,2017-12-01,"我最近在涉及大量数据处理的项目中频繁使用 sqlite3。我最初的尝试根本不涉及任何数据库，所有的数据都将保存在内存中，包括字典查找、迭代和条件等查询。这很好，但可以放入内存的只有那么多，并且将数据从磁盘重新生成或加载到内存是一个繁琐又耗时的过程。,我决定试一试sqlite3。因为只需打开与数据库的连接，这样可以增加可处理的数据量，并将应用程序的加载时间减少到零。此外，我可以通过 SQL 查询替换很多Python逻辑语句。,我想分享一些关于这次经历的心得和发现。,如果你需要在数据库中一次性插入很多行，那么你真不应该使用 execute。sqlite3 模块提供了批量插入的方式：executemany。,而不是像这样做：,你可以利用这个事实，即 executemany 接受元组的生成器作为参数：,这不仅更简洁，而且更高效。实际上，sqlite3 在幕后利用 executemany 实现 execute，但后者插入一行而不是多行。,我写了一个小的基准测试，将一百万行插入空表（数据库在内存中）：,一开始我经常搞混的事情就是，光标管理。在线示例和文档中通常如下：,但大多数情况下，你根本不需要光标，你可以直接使用连接对象（,末尾会提到）。,
像execute和executemany类似的操作可以直接在连接上调用。以下是一个证明此事的示例：,你可能经常会看到使用fetchone或fetchall来处理SELECT查询结果的示例。但是我发现处理这些结果的最自然的方式是直接在光标上迭代：,这样一来，只要你得到足够的结果，你就可以终止查询，并且不会引起资源浪费。当然，如果事先知道你需要多少结果，可以改用LIMIT SQL语句，但Python生成器是非常方便的，可以让你将数据生成与数据消耗分离。,即使在处理SQL事务的中间，也会发生讨厌的事情。为了避免手动处理回滚或提交，你可以简单地使用连接对象作为上下文管理器。 在以下示例中，我们创建了一个表，并错误地插入了重复的值：,…当它真的有用时,在你的程序中有几个 pragma 可用于调整 sqlite3 的行为。特别地，其中一个可以改善性能的是synchronous：,你应该知道这可能是危险的。如果应用程序在事务中间意外崩溃，数据库可能会处于不一致的状态。所以请小心使用！ 但是如果你要更快地插入很多行，那么这可能是一个选择。,假设你需要在数据库上创建几个索引，而你需要在插入很多行的同时创建索引。把索引的创建推迟到所有行的插入之后可以导致实质性的性能改善。,使用 Python 字符串操作将值包含到查询中是很方便的。但是这样做非常不安全，而 sqlite3 给你提供了更好的方法来做到这一点：,此外，使用Python％s（或格式或格式的字符串常量）的字符串插值对于executemany来说并不是总是可行。所以在此尝试没有什么真正意义！,请记住，这些小技巧可能会（也可能不会）给你带来好处，具体取决于特定的用例。你应该永远自己去尝试，决定是否值得这么做。"
http://python.jobbole.com/89004/,15 分钟用 ML 破解一个验证码系统,http://jbcdn2.b0.upaiyun.com/2018/01/86b4998ac58e5925e767a18e41b5438f.png,2018-01-29,"人人都恨,——那些恼人的图片，显示着你在登陆某网站前得输入的文本。设计,的目的是，通过验证你是真实的人来避免电脑自动填充表格。但是随着深度学习和计算机视觉的兴起，现在验证码常常易被攻破。,我拜读了 Adrian Rosebrock 写的《,》。在书中，Adrian 描述了他是怎样用机器学习绕过纽约 E-ZPass 网站上的验证码：,Adrian 无法接触到该应用生成,的源代码。为了攻破该系统，他不得不下载数百张示例图片，并手动处理它们来训练他自己的系统。,但是如果我们想攻破的是一个开源,系统，我们确实能接触到源代码该怎么办呢？,我访问了 ,频道，并搜索了“验证码”。第一条搜索结果是 Really Simple CAPTCHA，并且有超过一百万次的活跃安装：,最好的一点是，它是开源的！既然我们已经有了生成,的源代码，那它应该挺容易被攻破的。为了让这件事更有挑战性，让我们给自己规定个时限吧。我们能在 15 分钟内完全攻破这个,系统吗？来试试吧！,为了构思一个攻击计划，来看看 , 会生成什么样的图片。在示例网站上，我们看到了以下图片：,好了，所以,似乎是四个字母。在 PHP 源代码中对其进行验证：,没错，它用四种不同字体的随机组合来生成四个字母的,。并且可以看到，它在代码中从未使用 O 或者 I，以此避免用户混淆。总共有 32 个可能的字母和数字需要我们识别。没问题！,在进行下一步前，提一下我们要用来解决问题的工具：,Python 是一种有趣的编程语言，它有大量的机器学习和计算机视觉库。,OpenCV 是一种流行的计算机视觉和图片处理框架。我们要使用 OpenCV 来处理,图片。由于它有 Python API，所以我们可以直接从 Python 中使用它。,Keras 是用 Python 编写的深度学习框架。它使得定义、训练和用最少的代码使用深度神经网络容易实现。,TensorFlow 是 Google 的机器学习库。我们会用 Keras 编程，但是 Keras 并没有真正实现神经网络的逻辑本身，而是在幕后使用 Google 的 TensorFlow 库来挑起重担。,好了，回到我们的挑战吧！,为了训练任何机器学习系统，我们需要训练数据。为了攻破一个,系统，我们想要像这样的训练数据：,鉴于我们有 WordPress 插件的源代码，我们可以调整它，一起保存 10,000 张,图片及分别对应的答案。,经过几分钟对代码的攻击，并添加了一个简单的 for 循环之后，我有了一个训练数据的文件夹——10,000 个 PNG 文件，文件名为对应的正确答案：,这是唯一一个我不会给你示例代码的部分。我们做这个是为了教育，我不希望你们真去黑 WordPress 网站。但是，我最后会给你生成的这10,000 张图片，这样你就能重复我的结果了。,既然有了训练数据，就可以直接用它来训练神经网络了：,有了足够的训练数据，这个方法可能会有用——但是我们可以使问题更简化来解决。问题越简单，要解决它需要的训练数据就越少，需要的计算能力也越低。毕竟我们只有 15 分钟！,幸运的是，,图片总是由仅仅四个字母组成。如果我们能想办法把图片分开，使得每个字母都在单独的图片中，这样我们只需要训练神经网络一次识别一个字母：,我没有时间去浏览 10,000 张训练图片并在 Photoshop 中手动把它们拆分开。这得花掉好几天的时间，而我只剩下 10 分钟了。我们还不能把图片分成相等大小的四块，因为该,插件把字母随机摆放在不同的水平位置上以防止这一做法：,幸运的是，我们仍然可以自动处理。在图像处理中，常常需要检测有相同颜色的像素块。这些连续像素块周围的界限被称为轮廓。OpenCV 中有一个 ,() 函数，可以被用来检测这些连续区域。,所以我们用一个未经处理的验证码图片开始：,接下来把该图片转换成纯黑白（这叫做 thresholding），这样容易找到连续区域：,接着，使用 OpenCV 的 ,() 函数来检测该图片中包含相同颜色像素块的不同部分：,接下来就是简单地把每个区域存成不同的图片文件。鉴于我们知道每张图片都应该包含从左到右的四个字母，我们可以利用这一点在保存的同时给字母标记。只要我们是按顺序保存的，我们就应该能保存好每个图片字母及其对应的字母名。,但是等等——我看到一个问题！有时,中有像这样重叠的字母：,这意味着我们会把两个字母分离成一个区域：,如果不处理这个问题，会创造出糟糕的训练数据。我们得解决这个问题，这样就不会意外地教机器把两个重叠的字母识别成一个字母了。,一个简单的方法是，如果一个轮廓区域比它的高度更宽，这意味着很可能有两个字母重叠在一起了。在这种情况下，我们可以把重叠的字母从中间拆分成两个，并将其看作两个不同的字母：,既然我们找到拆分出单个字母的方法了，就对所有,图片进行该操作。目标是收集每个字母的不同变体。我们可以将每个字母保存在各自对应的文件夹中，以保持条理。,在我分离出所有字母后，我的 W 文件夹长这样：,由于我们只需要识别单个字母和数字的图片，我们不需要非常复杂的神经网络结构。识别字母要比识别像猫狗这样复杂的图片容易得多。,我们要使用简单的卷积神经网络结构，有两层卷积层以及两层完全连接层：,如果你想要了解更多神经网络的工作，以及为什么它们是图片识别的理想工具，请参考 ,或者,。,定义该神经网络结构，只需要使用 Keras 的几行代码：,现在我们可以训练它了！,在 10 通过了训练数据集后，我们达到了几乎 100% 的正确率。此时，我们应该能随时自动绕过这个,了！我们成功了！,既然有了一个训练后的神经网络，利用它来攻破真实的验证码要很容易了：,在破解验证码时，我们的模型看起来是这样：,或者从命令来看：,如果你想自己试试，你可以从这里,（ http://t.cn/R8yFJiN ）。它包含 10,000 张示例图片和文章中每一步的所有代码。参考文件 README.md 中的运行指导。,但是如果你想了解每一行代码都做了什么，我强烈建议你看看《 ,。该书覆盖了更多的细节，而且有大量的详细示例。这本书是我目前见过的唯一一本既包含了运行原理，又包含了如何在现实生活中用其来解决复杂问题的书。去看看吧！"
http://python.jobbole.com/88998/,实现属于自己的TensorFlow(1)：计算图与前向传播,http://jbcdn2.b0.upaiyun.com/2018/01/f17481e084e126080cf07fdb1a43d451.jpg,2018-01-25,"前段时间因为课题需要使用了一段时间TensorFlow，感觉这种框架很有意思，除了可以搭建复杂的神经网络，也可以优化其他自己需要的计算模型，所以一直想自己学习一下写一个类似的图计算框架。前几天组会开完决定着手实现一个模仿TensorFlow接口的简陋版本图计算框架以学习计算图程序的编写以及前向传播和反向传播的实现。目前实现了前向传播和反向传播以及梯度下降优化器，并写了个优化线性模型的例子。,代码放在了GitHub上，取名,, 仓库链接: ,虽然前向传播反向传播这些原理了解起来并不是很复杂，但是真正着手写起来才发现,里面还是有很多细节需要学习和处理才能对实际的模型进行优化(例如Loss函数对每个计算节点矩阵求导的处理)。其中SimpleFlow的代码并没有考虑太多的东西比如,和张量,的检查等，因为只是为了实现主要图计算功能并没有考虑任何的优化, 内部张量运算使用的Numpy的接口(毕竟是学习和练手的目的嘛)。好久时间没更新博客了，在接下来的几篇里面我将把实现的过程的细节总结一下，希望可以给后面学习的童鞋做个参考。,本文主要介绍计算图以及前向传播的实现, 主要涉及,以及通过对构建好的图进行,然后进行前向传播计算得到具体节点上的输出值。,先贴上一个简单的实现效果吧:,计算图是计算代数中的一个基础处理方法，我们可以通过一个有向图来表示一个给定的数学表达式，并可以根据图的特点快速方便对表达式中的变量进行求导。而神经网络的本质就是一个多层复合函数, 因此也可以通过一个图来表示其表达式。,本部分主要总结计算图的实现，在计算图这个有向图中，每个节点代表着一种特定的运算例如求和，乘积，向量乘积，平方等等… 例如求和表达式$,使用有向图表示为:, ,表达式$,使用有向图表示为:,与TensorFlow的实现不同，为了简化，在SimpleFlow中我并没有定义,类来表示计算图中节点之间的数据流动，而是,，其中主要定义了四种类型来表示图中的节点:,其实图中的所有节点都可以看成是某种操作，其中,, ,, ,都是一种特殊的操作，只是相对于普通的,而言，他们没有输入，但是都会有输出（像上图中的,, ,节点，他们本身输出自身的值到,节点中去），通常会输出到,节点，进行进一步的计算。,下面我们主要介绍如何实现计算图的基本组件: 节点和边。,节点表示操作，边代表节点接收和输出的数据，操作节点需要含有以下属性:,下面我们定义了,基类用于表示图中的操作节点(详见,):,在初始化方法中除了定义上面提到的属性外，还需要进行两个操作:,另外，每个操作节点还有两个必须的方法: ,和,. 他们分别负责根据输入节点的值计算当前节点的输出值和根据操作属性和当前节点的值计算梯度。关于梯度的计算将在后续的文章中详细介绍，本文只对节点输出值的计算进行介绍。,下面我以,操作为例来说明具体操作节点的实现:,可见，计算当前节点,的值的,就是,。,与,节点类似，,节点也需要,, ,等属性，但是它没有输入节点，也就没有,属性了，而是需要在创建的时候确定一个初始值,:,和,节点与,节点类似，具体实现详见: ,在定义了图中的节点后我们需要将定义好的节点放入到一个图中统一保管，因此就需要定义一个,类来存放创建的节点，方便统一操作图中节点的资源。,为了提供一个默认的图，在导入simpleflow模块的时候创建一个全局变量来引用默认的图:,为了模仿TensorFlow的接口，我们给,添加上下文管理器协议方法使其成为一个上下文管理器, 同时也添加一个,方法:,这样在进入,代码块之前先保存旧的默认图对象然后将当前图赋值给全局图对象，这样,代码块中的节点默认会添加到当前的图中。最后退出,代码块时再对图进行恢复即可。这样我们可以按照TensorFlow的方式来在某个图中创建节点.,Ok，根据上面的实现我们已经可以创建一个计算图了:,实现了计算图和图中的节点，我们需要对计算图进行计算, 本部分对计算图的前向传播的实现进行总结。,首先，我们需要实现一个,来对一个已经创建好的计算图进行计算，因为当我们创建我们之前定义的节点的时候其实只是创建了一个空节点，节点中并没有数值可以用来计算，也就是,是空的。为了模仿TensorFlow的接口，我们在这里也把session定义成一个上下文管理器:,上面我们已经可以构建出一个计算图了，计算图中的每个节点与其相邻的节点有方向的联系起来，现在我们需要根据图中节点的关系来推算出某个节点的值。那么如何计算呢? 还是以我们刚才￥,的计算图为例,,若我们需要计算橙色,运算节点的输出值，我们需要计算与它相连的两个输入节点的输出值，进而需要计算绿色,的输入节点的输出值。我们可以通过后序遍历来获取计算一个节点所需的所有节点的输出值。为了方便实现，后序遍历我直接使用了递归的方式来实现:,通过此函数我们可以获取计算一个节点值所需要所有节点列表，再依次计算列表中节点的输出值，最后便可以轻易的计算出当前节点的输出值了。,上面我们实现了计算图以及前向传播，我们就可以创建计算图计算表达式的值了, 如下:,输出值:,本文使用Python实现了计算图以及计算图的前向传播，并模仿TensorFlow的接口创建了,以及,对象。下篇中将继续总结计算图节点计算梯度的方法以及反向传播和梯度下降优化器的实现。,最后再附上simpleflow项目的链接, 欢迎相互学习和交流: "
http://python.jobbole.com/88971/,Python Django 性能测试与优化指南,http://jbcdn2.b0.upaiyun.com/2017/12/a53e7beb8e5e1b23fa86c861187e62ad.png,2017-12-19,"唐纳德·克努特（Donald Knuth）曾经说过：“不成熟的优化方案是万恶之源。”然而，任何一个承受高负载的成熟项目都不可避免地需要进行优化。在本文中，我想谈谈优化Web项目代码的五种常用方法。虽然本文是以Django为例，但其他框架和语言的优化原则也是类似的。通过使用这些优化方法，文中例程的查询响应时间从原来的77秒减少到了3.7秒。,本文用到的例程是从一个我曾经使用过的真实项目改编而来的，是性能优化技巧的典范。如果你想自己尝试着进行优化，可以在GitHub上获取优化前的初始代码，并跟着下文做相应的修改。我使用的是Python 2，因为一些第三方软件包还不支持Python 3。,这个Web项目只是简单地跟踪每个地区的房产价格。因此，只有两种模型：,抽象类,提供了一个继承自模型并包含,属性的模型，这个属性包含了实例的主键和模型的内容类型。 这能够隐藏像实例ID这样的敏感数据，而用散列进行代替。如果项目中有多个模型，而且需要在一个集中的地方对模型进行解码并要对不同类的不同模型实例进行处理时，这可能会非常有用。 请注意，对于本文的这个小项目，即使不用散列也照样可以处理，但使用散列有助于展示一些优化技巧。,这是,类：,由于我们想通过API来提供这些数据，所以我们安装了Django REST框架并定义以下序列化器和视图：,现在，我们将用一些数据来填充数据库（使用,生成10万个房屋的实例：一个地区5万个，另一个4万个，第三个1万个），并准备测试应用程序的性能。,在一个项目中我们需要测量下面这几个方面：,但是，并不是所有这些都要用来度量项目的执行情况。一般来说，有两个指标比较重要：执行多长时间、需要多少内存。,在Web项目中，,（服务器接收由某个用户的操作产生的请求，处理该请求并返回结果所需的总的时间）通常是最重要的指标，因为过长的响应时间会让用户厌倦等待，并切换到浏览器中的另一个选项卡页面。,在编程中，分析项目的性能被称为,。为了分析API的性能，我们将使用,包。在安装完这个包，并调用,后，可以得到如下的结果：,整体响应时间为77秒，其中16秒用于查询数据库，总共有5万次查询。这几个数字很大，提升空间也有很大，所以，我们开始吧。,性能优化最常见的技巧之一是对数据库查询进行优化，本案例也不例外。同时，还可以对查询做多次优化来减小响应时间。,仔细看一下这5万次查询查的是什么：都是对,表的查询：,时间戳 表名 联合 执行时间（毫秒）,这个问题的根源是，Django中的查询是,。这意味着在你真正需要获取数据之前它不会访问数据库。同时，它只获取你指定的数据，如果需要其他附加数据，则要另外发出请求。,这正是本例程所遇到的情况。当通过,来获得查询集时，Django将获取特定地区的所有房屋。但是，在序列化一个,实例时，,需要房子的,实例来计算序列化器的,字段。由于地区数据不在查询集中，所以django需要提出额外的请求来获取这些数据。对于查询集中的每一个房子都是如此，因此，总共是五万次。,当然，解决方案非常简单。为了提取所有需要的序列化数据，你可以在查询集上使用,。因此，,函数将如下所示：,我们来看看这对性能有何影响：,总体响应时间降至36秒，在数据库中花费的时间约为100ms，只有4个查询！这是个好消息，但我们可以做得更多。,默认情况下，Django会从数据库中提取所有字段。但是，当表有很多列很多行的时候，告诉Django提取哪些特定的字段就非常有意义了，这样就不会花时间去获取根本用不到的信息。在本案例中，我们只需要5个字段来进行序列化，虽然表中有17个字段。明确指定从数据库中提取哪些字段是很有意义的，可以进一步缩短响应时间。,Django可以使用,和,这两个查询方法来实现这一点。第一个用于指定哪些字段,，第二个用于指定,哪些字段。,这减少了一半的查询时间，非常不错。总体时间也略有下降，但还有更多提升空间。,你不能无限制地优化数据库查询，并且上面的结果也证明了这一点。即使把查询时间减少到0，我们仍然会面对需要等待半分钟才能得到应答这个现实。现在是时候转移到另一个优化级别上来了，那就是：,。,有时，第三方软件包对于简单的任务来说有着太大的开销。本文例程中返回的序列化的房子实例正说明了这一点。,Django REST框架非常棒，包含了很多有用的功能。但是，现在的主要目标是缩短响应时间，所以该框架是优化的候选对象，尤其是我们要使用的序列化对象这个功能非常的简单。,为此，我们来编写一个自定义的序列化器。为了方便起见，我们将用一个静态方法来完成这项工作。,现在看起来好多了，由于没有使用DRF序列化代码，所以响应时间几乎减少了一半。,另外还有一个结果：在请求/响应周期内完成的总的函数调用次数从15,859,427次（上面1.2节的请求次数）减少到了9,257,469次。这意味着大约有三分之一的函数调用都是由Django REST Framework产生的。,上述几个优化技巧是最常见的，无需深入地分析和思考就可以做到。然而，17秒的响应时间仍然感觉很长。要减少这个时间，需要更深入地了解代码，分析底层发生了什么。换句话说，需要分析一下代码。,你可以自己使用Python内置的分析器来进行分析，也可以使用一些第三方软件包。由于我们已经使用了,，它可以分析代码并生成一个二进制的分析文件，因此，我们可以做进一步的可视化分析。有好几个可视化软件包可以将二进制文件转换为一些友好的可视化视图。本文将使用,。,这是上文一个请求的二进制分析文件的可视化图表：,从上到下是调用堆栈，显示了文件名、函数名及其行号，以及该方法花费的时间。可以很容易地看出，时间大部分都用在计算散列上（紫罗兰色的,和,矩形）。,目前，这是代码的主要性能瓶颈，但同时，这不是我们自己写的代码，而是用的第三方包。,在这种情况下，我们可以做的事情将非常有限：,幸运的是，我们找到了一个更新版本的,包。原代码使用的是v.2.1.0，而新的是v.3.0.4。,当查看v.3的发行说明时，这一句话看起来令人充满希望：,让我们来看一下！,响应时间从17秒缩短到了8秒以内。太棒了！但还有一件事我们应该来看看。,到目前为止，我们已经改进了查询、用自己特定的函数取代了第三方复杂而又泛型的代码、更新了第三方包，但是我们还是保留了原有的代码。但有时，对现有代码进行小规模的重构可能会带来意想不到的结果。但是，为此我们需要再次分析运行结果。,仔细看一下，你可以看到散列仍然是一个问题（毫不奇怪，这是我们对数据做的唯一的事情），虽然我们确实朝这个方向改进了，但这个绿色的矩形表示,花了2.14秒的时间，同时伴随着灰色的,。这意味着初始化工作需要很长的时间。,我们来看看,包的源代码。,正如你所看到的，一个,实例的初始化需要调用,函数，这是太重了，我们可以在上面的可视化图表中看到左下角的矩形。,我们再来看看,类：,正如你所看到的，我已经标记了这两个方法初始化,实例的方法，这并不是真正需要的。,由于散列是一个确定性的过程，这意味着对于一个给定的输入值，它必须始终生成相同的散列值，因此，我们可以把它作为类的一个属性。让我们来看看它将如何执行：,最后的结果是在4秒钟之内，比我们一开始的时间要小得多。对响应时间的进一步优化可以通过使用缓存来实现，但是我不会在这篇文章中介绍这个。,性能优化是一个分析和发现的过程。 没有哪个硬性规定能适用于所有情况，因为每个项目都有自己的流程和瓶颈。 然而，你应该做的第一件事是分析代码。 如果在这样一个简短的例子中，我可以将响应时间从77秒缩短到3.7秒，那么对于一个庞大的项目来说，就会有更大的优化潜力。"
http://python.jobbole.com/88884/,疏而不漏：随机森林,http://jbcdn2.b0.upaiyun.com/2017/11/1ed7c6d9074f6464e4702ca32251fc8a.png,2017-11-24,"在,中我们提到当决策树和装袋法(Bagging)和提升法(Boosting)结合后会成为更强大的算法，那么今天就介绍一种名叫随机森林(Random Forest)的算法，它是将决策树、装袋法以及随机特征选取结合后衍生出的一种增强型的树算法。,它有如下特点：,看到随机森林有这么多的优点，你是不是心动了呢？那么接下来和我一起来认识一下它吧！,上文提到随机森林不是一种全新的算法，而是几种算法的强强联合。随机森林的构建一般有这么几个步骤：,算法作者说OOB Error可以作为测试误差的无偏估计，也就是计算出OOB Error就可以得到测试误差，不用专门把数据专门拿出来一部分作为测试集。下面举例说明如何计算OOB Error，比如我们要在一个有7条数据的数据集上构建一个5棵树的随机森林，那么在步骤1的时候会出现下面这样一张表:,表里的X代表没有选中，√代表选中。对于树1，数据1和7就是OOB，对于树2，数据2和5就是OOB，其他以此类推，那么数据1的预测值由树1和树4决定，数据2的预测值由树2-5来决定，以这样的方式计算出每个数据的预测值，进而得到误差值，即OOB Error。,假设我们已经计算出了OOB Error，一个变量的重要性可以这么计算，将变量打散，然后重新计算打散后的OOB Error，取打散前后OOB Error差值的绝对值，越大代表这个变量越重要。变量重要性在实践过程中非常好用，比如在一个10000维度的数据集选出100个最重要的变量，即数据的降维。,相似性由相似性矩阵体现，相似性矩阵是一个NxN的对称矩阵，它的计算方式如下，如果数据n和数据p同属于同一颗树的同一个叶子节点，那么相似性加1，即proximities[n,p]和proximities[p,n]均加1，最后除以树的数目进行标准化。,有了相似性，也就可以计算离群点了。它基于这样的假设，如果一条数据和其他数据都不相似或者相似性很低，那么这条数据很可能是个离群点。这和人很类似阿，如果一个人不合群，那么他肯定是比较孤立的。不过在我实际操作的过程中，即使计算出了潜在的离群点，如何确定它真的是不是不是那么容易。,具体的计算过程如下，定义类别为j的数据n的平均相似性为：,得到非相似性：,然后在各自的类别中标准化，得到最终的Dissimilarity，算法作者给出的经验值是如果一条数据的Dissimilarity>10，那么可能是一个潜在的离群点。,对于缺失值，传统的方法就是数值变量取均值，分组变量取最多的那一类。而随机森林处理缺失值另有一套：先使用一个不太准确的初始值替换缺失值，然后计算数据间的相似性，数值变量取同一类别非缺失值的相似性加权平均；分组变量取频率最高的值，频率要经过相似性加权，然后重复这一过程4-6次。,在决策树代码的基础上稍加改动就得到了随机森林，下面检验一下新算法的能力。,1、在,里我尝试使用花萼长度(Sepal.Length)和花萼宽度(Sepal.Width)这两个变量来预测鸢尾花的种类(Species)，这里用随机森林试一试。,首先来看下不同数目的树对分类的影响，下图的分类边界(Decision Boundary)，使用的Node Size为1，特征数Feature Count也为1,,可以看到，与决策树相比，随机森林对过拟合(Overfit)有着很强的抗性，且随着树的数目增多过拟合越来越少。但是，另一方面也要看到尽管对过拟合很强的抗性，还是可以看到过拟合的影子，即便我们已经用了1000棵树。所以，还是要为随机森林选择一个合适的Node Size,,从上面的第一张图，可以看到Node Size从0～100增加时，OOB Error先降后增，且在Node Size为15时达到最低。从第二张图可以看到随机森林分类边界的变化过程，先是轻微的过拟合继而最合适的边界最后严重的欠拟合。第三张图是最合适的分类边界，尽管和决策树一样，预测的错误率都为0.2左右，但是和决策树的分类边界相比，随机森林的边界更平滑。,2、,为了和决策树作对比，我也用随机森林来预测下房价(price)，也是使用区域(area)、是否学区(school)、是否有地铁(subway)、总价(num)这四个变量，使用的参数为树的数目TS=100，特征数Feature Count=4，节点数目Node Size=5，得到的结果如下，,袋外决策系数R2为0.7，使用模型预测所有房屋价格的决策系数为0.74，比决策树的0.7高了4个百分点，大家不要小看了这4个百分点，在机器学习中哪怕1个百分点都要付出很大的努力。况且，我在这里并没有使用交叉验证获取最佳的参数，只是凭经验选取。另外模型还给出了预测房价各个变量的重要性，可以看到决定房价最重要的就是房子所在的区。,接下来是个分类问题，使用小区(region)、户型(zone)、面积(meters)、朝向(direction)、区域(con)、楼层(floor)、房龄(year)、学区(school)、地铁(subway)、税(tax)、总价(num)、单价(price)来预测区(area)。随机从29790中抽取了10000条数据构造100颗树的随机森林，构建一个100棵树的森林，OOB Error和变量重要性如下，,OOB Error约为0.12，使用得到的随机森林模型预测29790条房源的区域，误差约为0.08，两者还是比较接近的。不出所料，片区(con)的重要性最高，另外房价(price)、是否学区(school)对房子区域的重要性也决非浪得虚名。,上文提到，随机森林可以作为降维的工具，我从中选择前6个重要的变量重新构建一个随机森林，OOB Error和变量重要性如下，,可以看到，使用6个变量的OOB Error与使用全部12个变量的OOB Error不相上下。,下面看看有没有潜在的离群点，下图是每套房子的Dissimilarity，,有两套房子的Dissimilarity>10，看看是什么房子，,初步看来，这两套房子的总价(num)和价格(price)有点高，是不是这一点让它们鹤立鸡群呢？,本文简单介绍了随机森林的特点及算法，并简单分析了iris和北京二手房两个数据集。本文只是抛砖引玉，其实随机森林的还有一些其他的特性，大家可以多多去发掘。,参考资料："
http://python.jobbole.com/88921/,用 Python 实现一个大数据搜索引擎,http://jbcdn2.b0.upaiyun.com/2015/02/591d8b55a524f825dd29a22b8df70000.jpg,2017-11-25,"搜索是大数据领域里常见的需求。Splunk和ELK分别是该领域在非开源和开源领域里的领导者。本文利用很少的Python代码实现了一个基本的数据搜索功能，试图让大家理解大数据搜索的基本原理。,第一步我们先要实现一个,。,布隆过滤器是大数据领域的一个常见算法，它的目的是过滤掉那些不是目标的元素。也就是说如果一个要搜索的词并不存在与我的数据中，那么它可以以很快的速度返回目标不存在。,让我们看看以下布隆过滤器的代码：,看到这里，大家应该可以看出，如果布隆过滤器返回False，那么数据一定是没有索引过的，然而如果返回True，那也不能说数据一定就已经被索引过。在搜索过程中使用布隆过滤器可以使得很多没有命中的搜索提前返回来提高效率。,我们看看这段 code是如何运行的：,结果：,首先创建了一个容量为10的的布隆过滤器,然后分别加入 ‘dog’，‘fish’，‘cat’三个对象，这时的布隆过滤器的内容如下：,然后加入‘bird’对象，布隆过滤器的内容并没有改变，因为‘bird’和‘fish’恰好拥有相同的哈希。,最后我们检查一堆对象（’dog’, ‘fish’, ‘cat’, ‘bird’, ‘duck’, ’emu’）是不是已经被索引了。结果发现‘duck’返回True，2而‘emu’返回False。因为‘duck’的哈希恰好和‘dog’是一样的。, ,下面一步我们要实现分词。 分词的目的是要把我们的文本数据分割成可搜索的最小单元，也就是词。这里我们主要针对英语，因为中文的分词涉及到自然语言处理，比较复杂，而英文基本只要用标点符号就好了。,下面我们看看分词的代码：,主要分割,主要分割使用空格来分词，实际的分词逻辑中，还会有其它的分隔符。例如Splunk的缺省分割符包括以下这些，用户也可以定义自己的分割符。,] < >( ) { } | ! ; , ‘ ” * \n \r \s \t & ? + %21 %26 %2526 %3B %7C %20 %2B %3D — %2520 %5D %5B %3A %0A %2C %28 %29,次要分割,次要分割和主要分割的逻辑类似，只是还会把从开始部分到当前分割的结果加入。例如“1.2.3.4”的次要分割会有1，2，3，4，1.2，1.2.3,分词的逻辑就是对文本先进行主要分割，对每一个主要分割在进行次要分割。然后把所有分出来的词返回。,我们看看这段 code是如何运行的：, ,好了，有个分词和布隆过滤器这两个利器的支撑后，我们就可以来实现搜索的功能了。,上代码：,我们运行下看看把：,是不是很赞！, ,更进一步，在搜索过程中，我们想用And和Or来实现更复杂的搜索逻辑。,上代码：,利用Python集合的intersection和union操作，可以很方便的支持And（求交集）和Or（求合集）的操作。,运行结果如下：, ,以上的代码只是为了说明大数据搜索的基本原理，包括布隆过滤器，分词和倒排表。如果大家真的想要利用这代码来实现真正的搜索功能，还差的太远。所有的内容来自于Splunk Conf2017。大家如果有兴趣可以去看网上的视频。"
http://python.jobbole.com/88926/,Python 性能优化,http://jbcdn2.b0.upaiyun.com/2017/11/7acbaf502a752190a99c5c9f68548d53.png,2017-11-27,"本文除非特殊指明，”python“都是代表CPython，即C语言实现的标准python，且本文所讨论的是版本为2.7的CPython。另外，本文会不定期更新，如果大家有一些好的想法，请在评论里面留言，我会补充到文章中去。,当我们提到一门编程语言的效率时：通常有两层意思，,，这是对程序员而言，完成编码所需要的时间；,，这是对计算机而言，完成计算任务所需要的时间。编码效率和运行效率往往是鱼与熊掌的关系，是很难同时兼顾的。不同的语言会有不同的侧重，python语言毫无疑问更在乎编码效率，life is short，we use python。,虽然使用python的编程人员都应该接受其运行效率低的事实，但python在越多越来的领域都有广泛应用，比如科学计算 、web服务器等。程序员当然也希望python能够运算得更快，希望python可以更强大。,首先，python相比其他语言具体有多慢，这个不同场景和测试用例，结果肯定是不一样的。,给出了不同语言在各种case下的性能对比，,是python3和C++的对比，下面是两个case：,从上图可以看出，不同的case，python比C++慢了几倍到几十倍。,python运算效率低，具体是什么原因呢，下列罗列一些,一个变量所指向对象的类型在运行时才确定，编译器做不了任何预测，也就无从优化。举一个简单的例子：　,　a和b相加，但a和b的类型在运行时才知道，对于加法操作，不同的类型有不同的处理，所以每次运行的时候都会去判断a和b的类型，然后执行对应的操作。而在静态语言如C++中，编译的时候就确定了运行时的代码。,另外一个例子是属性查找，关于具体的查找顺序在,中有详细介绍。简而言之，访问对象的某个属性是一个非常复杂的过程，而且通过同一个变量访问到的python对象还都可能不一样（参见Lazy property的例子）。而在C语言中，访问属性用对象的地址加上属性的偏移就可以了。,，但是不支持JIT（just in time compiler）。虽然大名鼎鼎的google曾经尝试, 这个项目，但最终也折了。,，每个对象都需要维护引用计数，增加了额外的工作。,GIL是Python最为诟病的一点，因为GIL，python中的多线程并不能真正的并发。如果是在IO bound的业务场景，这个问题并不大，但是在CPU BOUND的场景，这就很致命了。所以笔者在工作中使用python多线程的情况并不多，一般都是使用多进程（pre fork），或者在加上协程。即使在单线程，GIL也会带来很大的性能影响，因为python每执行,（默认，可以通过sys.setcheckinterval()设置）就会尝试线程的切换，具体的源代码在ceval.c::PyEval_EvalFrameEx。,，这个可能是所有具有垃圾回收的编程语言的通病。python采用标记和分代的垃圾回收策略，每次垃圾回收的时候都会中断正在执行的程序，造成所谓的顿卡。,上有一篇文章，提到禁用Python的GC机制后，Instagram性能提升了10%。感兴趣的读者可以去细读。,Be pythonic,我们都知道 过早的优化是罪恶之源，一切优化都需要基于profile。但是，作为一个python开发者应该要pythonic，而且pythonic的代码往往比non－pythonic的代码效率高一些，比如：,dict的iteritems 而不是items（同itervalues，iterkeys）,使用generator，特别是在循环中可能提前break的情况,即使我们的代码已经非常pythonic了，但可能运行效率还是不能满足预期。我们也知道,了，优化的关键在于找出这些瓶颈代码。方式很多：到处加log打印时间戳、或者将怀疑的函数使用timeit进行单独测试，但最有效的是使用profile工具。,对于python程序，比较出名的profile工具有三个：,。其中profile是纯python语言实现的，Cprofile将profile的部分实现native化，hotshot也是C语言实现，hotshot与Cprofile的区别在于：hotshot对目标代码的运行影响较小，代价是更多的后处理时间，而且hotshot已经停止维护了。,，profile（Cprofile hotshot）只适合单线程的python程序。,对于多线程，可以使用,，yappi不仅支持多线程，还可以精确到CPU时间,对于协程（greenlet），可以使用,，基于yappi修改，用greenlet context hook住thread context,下面给出一段编造的”效率低下“的代码，并使用Cprofile来说明profile的具体方法以及我们可能遇到的性能瓶颈。,运行结果如下：,对于上面的的输出，每一个字段意义如下：,代码中的输出非常简单，事实上可以利用pstat，让profile结果的输出多样化，具体可以参见官方文档,。,虽然Cprofile的输出已经比较直观，但我们还是倾向于保存profile的结果，然后用图形化的工具来从不同的维度来分析，或者比较优化前后的代码。查看profile结果的工具也比较多，比如，,，本文用visualpytune做分析。对于上面的代码，按照注释生成修改后重新运行生成test.prof文件，用visualpytune直接打开就可以了，如下：,
字段的意义与文本输出基本一致，不过便捷性可以点击字段名排序。左下方列出了当前函数的calller（调用者），右下方是当前函数内部与子函数的时间占用情况。上如是按照cumtime（即该函数内部及其子函数所占的时间和）排序的结果。,造成性能瓶颈的原因通常是,。在我们前面的例子中，foo就属于高频调用的情况，bar属于单次消耗非常高的情况，这都是我们需要优化的重点。,中介绍了qcachegrind和runsnakerun的使用方法，这两个colorful的工具比visualpytune强大得多。具体的使用方法请参考原文，下图给出test.prof用qcachegrind打开的结果,qcachegrind确实要比visualpytune强大。从上图可以看到，大致分为三部：。第一部分同visualpytune类似，是每个函数占用的时间，其中Incl等同于cumtime， Self等同于tottime。第二部分和第三部分都有很多标签，不同的标签标示从不同的角度来看结果，如图上所以，第三部分的“call graph”展示了该函数的call tree并包含每个子函数的时间百分比，一目了然。,知道了热点，就可以进行针对性的优化，而这个优化往往根具体的业务密切相关，没用万能钥匙，具体问题，具体分析。个人经验而言，最有效的优化是找产品经理讨论需求，可能换一种方式也能满足需求，少者稍微折衷一下产品经理也能接受。次之是修改代码的实现，比如之前使用了一个比较通俗易懂但效率较低的算法，如果这个算法成为了性能瓶颈，那就考虑换一种效率更高但是可能难理解的算法、或者使用,模式。对于这些同样的方法，需要结合具体的案例，本文不做赘述。,接下来结合python语言特性，介绍一些让python代码不那么pythonic，但可以提升性能的一些做法,每一层函数调用都会带来不小的开销，特别对于调用频率高，但单次消耗较小的calltree，多层的函数调用开销就很大，这个时候可以考虑将其展开。,对于之前调到的profile的代码，foo这个call tree非常简单，但频率高。修改代码，增加一个plain_foo()函数, 直接返回最终结果，关键输出如下：,跟之前的结果对比：,可以看到，优化了差不多3倍。,上面提到，python 的属性查找效率很低，如果在一段代码中频繁访问一个属性（比如for循环），那么可以考虑用局部变量代替对象的属性。,在本文的第一章节已经提到，关闭GC可以提升python的性能，GC带来的顿卡在实时性要求比较高的应用场景也是难以接受的。但关闭GC并不是一件容易的事情。我们知道python的引用计数只能应付没有循环引用的情况，有了循环引用就需要靠GC来处理。在python语言中, 写出循环引用非常容易。比如：,当然，大家可能说，谁会这么傻，写出这样的代码，是的，上面的代码太明显，当中间多几个层级之后，就会出现“间接”的循环应用。在python的标准库 collections里面的OrderedDict就是case2：,要解决循环引用，第一个办法是使用弱引用（weakref），第二个是手动解循环引用。,如果程序确定是单线程，那么修改checkinterval为一个更大的值，,有介绍。,slots最主要的目的是用来节省内存，但是也能一定程度上提高性能。我们知道定义了__slots__的类，对某一个实例都会预留足够的空间，也就不会再自动创建__dict__。当然，使用__slots__也有许多注意事项，最重要的一点，继承链上的所有类都必须定义__slots__，python doc有详细的描述。下面看一个简单的测试例子：,输出结果：,也许通过profile，我们已经找到了性能热点，但这个热点就是要运行大量的计算，而且没法cache，没法省略。。。这个时候就该python的C扩展出马了，,。由于C语言的效率远远高于python代码，所以使用C扩展是非常普遍的做法，比如我们前面提到的cProfile就是基于_lsprof.so的一层封装。python的大所属对性能有要求的库都使用或者提供了C扩展，如gevent、protobuff、bson。,笔者曾经测试过纯python版本的bson和cbson的效率，在综合的情况下，cbson快了差不多10倍！,python的C扩展也是一个非常复杂的问题，本文仅给出一些注意事项：,这是最难最复杂的一点。我们都知道python基于指针技术来管理对象的生命周期，如果在扩展中引用计数出了问题，那么要么是程序崩溃，要么是内存泄漏。更要命的是，引用计数导致的问题很难debug。。。,C扩展中关于引用计数最关键的三个词是：steal reference，borrowed reference，new reference。建议编写扩展代码之前细读python的,。,这里的多线程是指在扩展中new出来的C语言线程，而不是python的多线程，出了python doc里面的介绍，也可以看看《python cookbook》的相关章节。,仅适合与业务代码的关系不那么紧密的逻辑，如果一段代码大量业务相关的对象 属性的话，是很难C扩展的,将C扩展封装成python代码可调用的接口的过程称之为binding，Cpython本身就提供了一套原生的API，虽然使用最为广泛，但该规范比较复杂。很多第三方库做了不同程度的封装，以便开发者使用，比如,（同时支持pypy cpython），具体怎么使用可以google。,尽管python的性能差强人意，但是其易学易用的特性还是赢得越来越多的使用者，业界大牛也从来没有放弃对python的优化。这里的优化是对python语言设计上、或者实现上的一些反思或者增强。这些优化项目一些已经夭折，一些还在进一步改善中，在这个章节介绍目前还不错的一些项目。,前面提到,可以用到binding c扩展，但是其作用远远不止这一点。,Cython的主要目的是加速python的运行效率，但是又不像上一章节提到的C扩展那么复杂。在Cython中，写C扩展和写python代码的复杂度差不多（多亏了,）。Cython是python语言的超集，增加了对C语言函数调用和类型声明的支持。从这个角度来看，cython将动态的python代码转换成静态编译的C代码，这也是cython高效的原因。使用cython同C扩展一样，需要编译成动态链接库，在linux环境下既可以用命令行，也可以用distutils。,如果想要系统学习cython，建议从,入手，文档写得很好。下面通过一个简单的示例来展示cython的使用方法和性能（linux环境）。,首先，安装cython：,下面是测试用的python代码，可以看到这两个case都是运算复杂度比较高的例子：,运行结果：,不改动任何python代码也可以享受到cython带来的性能提升，具体做法如下：,可以看到 增加了两个文件，对应中间结果和最后的动态链接库,运行结果：,性能提升了大概两倍，我们再来试试cython提供的静态类型（static typing），修改cython_example.pyx的核心代码，替换f()和integrate_f()的实现如下：,然后重新运行上面的第三 四步：结果如下,上面的代码，只是对参数引入了静态类型判断，下面对返回值也引入静态类型判断。,替换f()和integrate_f()的实现如下：,然后重新运行上面的第三 四步：结果如下,Amazing！,pypy是CPython的一个替代实现，其最主要的优势就是pypy的速度，下面是官网的测试结果：,在实际项目中测试，pypy大概比cpython要快3到5倍！pypy的性能提升来自JIT Compiler。在前文提到google的, 项目也是想在CPython中引入JIT，在这个项目失败后，很多开发人员都开始加入pypy的开发和优化。另外pypy占用的内存更少，而且支持stackless，基本等同于协程。,pypy的缺点在于对C扩展方面支持的不太好，需要使用CFFi来做binding。对于使用广泛的library来说，一般都会支持pypy，但是小众的、或者自行开发的C扩展就需要重新封装了。,2017.03.10 增加了对__slots__的介绍"
http://python.jobbole.com/88937/,深入理解 Python 的属性查找,http://jbcdn2.b0.upaiyun.com/2015/02/edecceebedd0d04aa17bccba430ddcaf.jpg,2017-11-27,"在Python中，属性查找（attribute lookup）是比较复杂的，特别是涉及到描述符descriptor的时候。,在,末尾，给出了一段代码，就涉及到descriptor与attribute lookup的问题。而get系列函数(__get__, __getattr__, __getattribute__) 也很容易搞晕，本文就这些问题简单总结一下。,首先，我们知道：,按照python doc，如果obj是某个类的实例，那么obj.name（以及等价的getattr(obj,’name’)）首先调用__getattribute__。如果类定义了__getattr__方法，那么在__getattribute__抛出 AttributeError 的时候就会调用到__getattr__，而对于描述符(__get__）的调用，则是发生在__getattribute__内部的。官网文档是这么描述的,obj = Clz(), 那么obj.attr 顺序如下：,（1）如果“attr”是出现在Clz或其基类的__dict__中， 且attr是data descriptor， 那么调用其__get__方法, 否则,（2）如果“attr”出现在obj的__dict__中， 那么直接返回 obj.__dict__[‘attr’]， 否则,（3）如果“attr”出现在Clz或其基类的__dict__中,（3.1）如果attr是non-data descriptor，那么调用其__get__方法， 否则,（3.2）返回 __dict__[‘attr’],（4）如果Clz有__getattr__方法，调用__getattr__方法，否则,（5）抛出AttributeError,下面是测试代码：,注意第50行，change_attr给实例的__dict__里面增加了两个属性。通过上下两条print的输出如下：,调用change_attr方法之后，dd_base既出现在类的__dict__（作为data descriptor）, 也出现在实例的__dict__， 因为attribute lookup的循序，所以优先返回的还是Clz.__dict__[‘dd_base’]。而ndd_base虽然出现在类的__dict__， 但是因为是nondata descriptor，所以优先返回obj.__dict__[‘dd_base’]。其他：line48,line56表明了__getattr__的作用。line49表明obj.__dict__优先于Clz.__dict__,我们再来看看,的这段代码。,cached_property是一个non-data descriptor。在TestClz中，用cached_property装饰方法complex_calc，返回值是一个descriptor实例，所以在调用的时候没有使用小括号。,第一次调用t.complex_calc之前，obj(t)的__dict__中没有”complex_calc“， 根据查找顺序第三条，执行cached_property.__get__, 这个函数代用缓存的complex_calc函数计算出结果，并且把结果放入obj.__dict__。那么第二次访问t.complex_calc的时候，根据查找顺序，第二条有限于第三条，所以就直接返回obj.__dict__[‘complex_calc’]。bottle的源码中还有两个descriptor，非常厉害！,前面提到过，类的也是对象，类是元类（metaclass）的实例，所以类属性的查找顺序基本同上。区别在于第二步，由于Clz可能有基类，所以是在Clz及其基类的__dict__,“attr，注意这里的查找并不是直接返回clz.__dict__[‘attr’]。具体来说，这第二步分为以下两种情况：,（2.1）如果clz.__dict__[‘attr’]是一个descriptor（不管是data descriptor还是non-data descriptor），都调用其__get__方法,（2.2）否则返回clz.__dict__[‘attr’],这就解释了一个很有意思的问题：method与function的问题,Widget是一个之定义了一个func函数的类，func是类的属性，这个也可以通过Widget.__dict__、w.__dict__看到。Widget.__dict__[‘func’]返回的是一个function，但Widget.func是一个unbound method，即Widget.func并不等同于Widget.__dict__[‘func’]，按照前面的类属性的访问顺序，我们可以怀疑，func是一个descriptor，这样才不会走到第2.2这种情况。验证如下：,Python的属性赋值（attribute assignment）也会受到descriptor（data descriptor）的影响，同时也会受到__setattr__函数的影响。当然Python中还有一个setattr，setattr(x, ‘foobar’, 123)等价于x.foobar = 123，二者都叫attribute assignment。,首先看看__setattr__:,那什么是normal mechanism，简单来说就是x.__dict__[‘foobar’] = 123，不管’foobar’之前是否是x的属性（当然赋值之后就一定是了）。但是如果‘’foobar‘’是类属性，且是data descriptor，那么回优先调用__set__。我们来看一个例子：,输出如下：,可以看到，即使Widget的实例也有一个‘a’属性，但是调用w.a的时候会调用类属性‘a’（一个descriptor）的__set__方法。如果不注释掉第18到第20行，输出如下,可以看到，优先调用Widget 的__setattr__方法。因此：对于属性赋值，obj = Clz(), 那么obj.attr = var，按照这样的顺序："
http://python.jobbole.com/88901/,动态语言的灵活性是把双刃剑 －－ 以 Python 语言为例,http://jbcdn2.b0.upaiyun.com/2015/02/edecceebedd0d04aa17bccba430ddcaf.jpg,2017-11-19,"本文有些零碎，总题来说，包括两个问题：（1）可变对象（最常见的是list dict）被意外修改的问题，（2）对参数（parameter）的检查问题。这两个问题，本质都是因为动态语言（动态类型语言）的特性造成了，动态语言的好处就不细说了，本文是要讨论因为动态－－这种灵活性带来的一些问题。,什么是动态语言（,）呢，是相对于静态语言而言，将很多静态语言编译（compilation）时期所做的事情推迟到运行时，在运行时修改代码的行为，比如添加新的对象和函数，修改既有代码的功能，改变类型。绝大多数动态语言都是动态类型（Dynamic Typed），所谓动态类型，是在运行时确定数据类型，变量使用之前不需要类型声明，通常变量的类型是被赋值的那个值的类型。Python就是属于典型的动态语言。,动态语言的魅力在于让开发人员更好的关注需要解决的问题本身，而不是冗杂的语言规范，也不用干啥都得写个类。运行时改变代码的行为也是非常有用，比如python的热更新，可以做到不关服务器就替换代码的逻辑，而静态语言如C++就很难做到这一点。笔者使用得最多的就是C++和Python，C++中的一些复杂的点，比如模板（泛型编程）、设计模式（比如template method），在Python中使用起来非常自然。我也看到过有一些文章指出，设计模式往往是特定静态语言的补丁 — 为了弥补语言的缺陷或者限制。,以笔者的知识水平，远远不足以评价动态语言与静态语言的优劣。本文也只是记录在我使用Python这门动态语言的时候，由于语言的灵活性，由于动态类型，踩过的坑，一点思考，以及困惑。,这个是在线上环境出现过的一个BUG,事后说起来很简单，服务端数据（放在dict里面的）被意外修改了，但查证的时候也花了许多时间，伪代码如下：,上述的代码很简单，dct是一个dict，极大概率会调用一个不用修改dct的子函数，极小概率出会调用到可能修改dct的子函数。问题就在于，调用routine函数的参数是服务端全局变量，理论上是不能被修改的。当然，上述的代码简单到一眼就能看出问题，但在实际环境中，调用链有七八层，而且，在routine这个函数的doc里面，声明不会修改dct，该函数本身确实没有修改dct，但调用的子函数或者子函数的子函数没有遵守这个约定。,本小节解释上面的代码为什么会出问题，简单来说两点：dict是mutable对象； dict实例作为参数传入函数，然后被函数修改了。,Python中一切都是对象(evething is object)，不管是int str dict 还是类。比如 a =5， 5是一个整数类型的对象（实例）；那么a是什么，a是5这个对象吗? 不是的，a只是一个名字，这个名字暂时指向（绑定、映射）到5这个对象。b = a 是什么意思呢， 是b指向a指向的对象，即a， b都指向整数5这个对象,那么什么是mutable 什么是immutable呢，mutable是说这个对象是可以修改的，immutable是说这个对象是不可修改的(废话)。还是看Python官方怎么说的吧,承接上面的例子（a = 5），int类型就是immutable，你可能说不对啊，比如对a赋值， a=6， 现在a不是变成6了吗？是的，a现在”变成”6了，但本质是a指向了6这个对象 — a不再指向5了,检验对象的唯一标准是id，id函数返回对象的地址，每个对象在都有唯一的地址。看下面两个例子就知道了,或者这么说，对于非可变对象，在对象的生命周期内，没有办法改变对象所在内存地址上的值。,python中，不可变对象包括：int, long, float, bool, str, tuple, frozenset；而其他的dict list 自定义的对象等属于可变对象。,： str也是不可变对象，这也是为什么在多个字符串连接操作的时候，推荐使用join而不是+,而且python没有机制，让一个可变对象不可被修改（此处类比的是C++中的const）,那在python中，调用函数时的参数传递是什么意思呢，是传值、传引用？事实上都不正确，我不清楚有没有专业而统一的说法，但简单理解，就是形参（parameter）和实参（argument）都指向同一个对象，仅此而已。来看一下面的代码：,运行结果：,可以看到，刚进入子函数double的时候，a，v指向的同一个对象（相同的id）。对于test int的例子，v因为v*=2，指向了另外一个对象，但对实参a是没有任何影响的。对于testlst的时候，v*=2是通过v修改了v指向的对象（也是a指向的对象），因此函数调用完之后，a指向的对象内容发生了变化。,为了防止传入到子函数中的可变对象被修改，最简单的就是使用copy模块拷贝一份数据。具体来说，包括copy.copy, copy.deepcopy, 前者是浅拷贝，后者是深拷贝。二者的区别在于：,简单来说，深拷贝会递归拷贝，遍历任何compound object然后拷贝，例如：,从例子可以看出浅拷贝的局限性，Python中，对象的基本构造也是浅拷贝，例如,正是由于浅拷贝与深拷贝本质上的区别，二者性能代价差异非常之大，即使对于被拷贝的对象来说毫无差异：,运行结果：,在上面的示例中，dct这个dict的values都是int类型，immutable对象，因为无论浅拷贝 深拷贝效果都是一样的，但是耗时差异巨大。如果在dct中存在自定义的对象，差异会更大,那么为了安全起见，应该使用深拷贝；为了性能，应该使用浅拷贝。如果compound object包含的元素都是immutable，那么浅拷贝既安全又高效，but，对于python这种灵活性极强的语言，很可能某天某人就加入了一个mutable元素。,好的API应该是,。API应该提供一种契约，约定如果使用者按照特定的方式调用，那么API就能实现预期的效果。,在静态语言如C++中，函数签名就是最好的契约。,在C++中，参数传递大约有三种形式，传值、传指针、传引用（这里不考虑右值引用）。指针和引用虽然表现形式上差异，但效果上是差不多的，因此这里主要考虑传值和传引用。比如下面四个函数签名：,对于第1、2个函数，对于调用者来说都是一样的，因为都会进行拷贝（深拷贝），无论func函数内部怎么操作，都不会影响到实参。二者的区别在于函数中能否对a进行修改，比如能否写 a *＝ 2。,第3个函数，非const引用，任何对a的修改都会影响到实参。调用者看到这个API就知道预期的行为：函数会改变实参的值。,第4个函数，const引用，函数承诺绝对不会修改实参，因此调用者可以放心大胆的传引用，无需拷贝。,从上面几个API，可以看到，通过函数签名，调用者就能知道函数调用对传入的参数有没有影响。,python是动态类型检查，除了运行时，没法做参数做任何检查。有人说，那就通过python doc或者变量名来实现契约吧，比如：,但是人是靠不住的，也是不可靠的，也许在这个函数的子函数（子函数的子函数，。。。）就会修改这个dict。怎么办，对可变类型强制copy（deepcopy），但拷贝又非常耗时。。。,上一节说明没有签名 对 函数调用者是多么不爽，而本章节则说明没有签名对函数提供者有多么不爽。没有类型检查真的蛋疼，我也遇到过有人为了方便，给一个约定是int类型的形参传入了一个int的list，而可怕的是代码不报错，只是表现不正常。,来看一个例子：,上述的代码很糟糕，根本没法“望名知意”，也看不出有关形参 arg的任何信息。但事实上这样的代码是存在的，而且还有比这更严重的，比如挂羊头卖狗肉。,这里有一个问题，函数期望arg是某种类型，是否应该写代码判断呢，比如：isinstance(arg, str)。因为没有编译器静态来做参数检查，那么要不要检查，如何检查就完全是函数提供者的事情。如果检查，那么影响性能，也容易违背python的灵活性 — duck typing； 不检查，又容易被误用。,但在这里，考虑的是另一个问题，看代码的第二行：,。python中，几乎是一切对象都可以当作布尔表达式求值，即这里的arg可以是一切python对象，可以是bool、int、dict、list以及任何自定义对象。不同的类型为“真”的条件不一样，比如数值类型(int float)非0即为真；序列类型（str、list、dict）非空即为真；而对于自定义对象，在python2.7种则是看是否定义了__nonzero__ 、__len__，如果这两个函数都没有定义，那么实例的布尔求值一定返回真。,在,，由以下关于对序列布尔求值的规范：,在,中也有一节专门关于,，指出“,”。 对于序列，推荐的判断方法与pep8相同，另外还由两点比较有意思：,第二点我个人很赞同；但第一点就觉得很别扭，因为这样的语句一点不直观，难以表达其真实目的。,在,中，指出：,这句话简单但实用！代码是写给人读的，清晰的表达代码的意图比什么都重要。也许有的人觉得代码写得复杂隐晦就显得牛逼，比如python中嵌套几层的list comprehension，且不知这样害人又害己。,回到布尔表达式求值这个问题，我觉得很多时候直接使用if arg：这种形式都不是好主意，因为不直观而且容易出错。比如参数是int类型的情况，,很难说当age=0时是不是一个合理的输入，上面的代码对None、0一视同仁，看代码的人也搞不清传入0是否正确。,另外一个具有争议性的例子就是对序列进行布尔求值，推荐的都是直接使用if seq: 的形式，但这种形式违背了”Explicit is better than implicit.“，因为这样写根本无法区分None和空序列，而这二者往往是由区别的，很多时候，空序列是一个合理的输入，而None不是。这个问题，,上也有相关的讨论“如何检查列表为空”，诚然，如果写成 seq == [] 是不那么好的代码， 因为不那么灵活 — 如果seq是tuple类型代码就不能工作了。python语言是典型的duck typing，不管你传入什么类型，只要具备相应的函数，那么代码就可以工作，但是否正确地工作就完完全全取决于使用者。个人觉得存在宽泛的约束比较好，比如Python中的ABC（abstract base class）, 既满足了灵活性需求，后能做一些规范检查。,以上两个问题，是我使用Python语言以来遇到的诸多问题之二，也是我在同一个地方跌倒过两次的问题。Python语言以开发效率见长，但是我觉得需要良好的规范才能保证在大型线上项目中使用。而且，我也倾向于假设：人是不可靠的，不会永远遵守拟定的规范，不会每次修改代码之后更新docstring …,因此，为了保证代码的可持续发展，需要做到以下几点,代码规范最好在项目启动时就应该拟定好，可以参照PEP8和google python styleguild。很多时候风格没有优劣之说，但是保证项目内的一致性很重要。并保持定期review、对新人review！,只要能静态发现的bug不要放到线上，比如对参数、返回值的检查，在python3.x中可以使用注解（Function Annotations），python2.x也可以自行封装decorator来做检查。对代码行为，既可以使用Coverity这种高大上的商业软件，或者王垠大神的Pysonar2，也可以使用ast编写简单的检查代码。,单元测试的重要性想必大家都知道，在python中出了官方自带的doctest、unittest，还有许多更强大的框架，比如nose、mock。,对于python这种动态语言，出了执行代码，几乎没有其他比较好的检查代码错误的手段，所以覆盖率测试是非常重要的。可以使用python原生的sys.settrace、sys.gettrace，也可以使用coverage等跟更高级的工具。,虽然我已经写了几年Python了，但是在Python使用规范上还是很欠缺。我也不知道在其他公司、项目中，是如何使用好Python的，如何扬长避短的。欢迎pythoner留言指导！"
http://python.jobbole.com/88907/,用不到 50 行的 Python 代码构建最小的区块链,http://jbcdn2.b0.upaiyun.com/2017/11/8cdceb83f2089cfe344252cbd73bb70f.png,2017-11-22,"尽管一些人认为区块链是一个等待问题的解决方案，但毫无疑问，这种新技术是计算机的奇迹。但是，区块链到底是什么呢?,在更一般的术语中，它是一个公共数据库，新数据存储在一个名为块的容器中，并被添加到一个不可变链（后来的区块链）中添加了过去的数据。在比特币和其他加密货币的情况下，这些数据是一组交易记录。当然，数据可以是任何类型的。,区块链技术已经催生了新的、完全数字化的货币，如比特币和莱特币，这些货币并不是由中央政府发行或管理的。因此为那些认为今天的银行系统是骗局或终将失败的人带来了新的自由。区块链所包含的以太坊技术对分布式计算进行了变革创新，它引入了一些有趣的概念，比如,。,在本文中，我将用不到50行的Python2代码来做一个简单的区块链。我称它为SnakeCoin。,首先将定义块将是什么样子。在区块链中，每个块都存储一个时间戳和一个索引。在SnakeCoin中，需要把两者都存储起来。为了确保整个区块链的完整性，每个块都有一个自动识别散列。与比特币一样，每个块的散列将是块索引、时间戳、数据和前块哈希的加密哈希。数据可以是你想要的任何东西。,这一步后有块结构，但现在是创建区块链，所以需要向实际的链中添加块。如前所述，每个块都需要上一个块的信息。但是按照这个说法就有一个问题，区块链的第一个区块是如何到达那里的呢？不得不说，第一个块，或者说是起源块，它是一个特殊的块。在很多情况下，它是手动添加的，或者有独特的逻辑允许添加。,下面将创建一个函数简单地返回一个起源块以便产生第一个区块。这个块是索引0，它具有任意的数据值和“前一个哈希”参数中的任意值。,现在已经创建好了起源块，接下来需要一个函数，以便在区块链中生成后续的块。这个函数将把链中的前一个块作为参数，创建要生成的块的数据，并使用适当的数据返回新块。当新的块哈希信息来自前面的块时，区块链的完整性会随着每个新块而增加。如果不这样做，外部组织就更容易“改变过去”，用全新的方式取代已有的链条。这一系列的散列可以作为加密的证据，有助于确保一旦将块添加到区块链，它就不能被替换或删除。,大部分的工作已经完成，现在可以创建区块链了。在这次的示例中，区块链本身是一个简单的Python列表。列表的第一个元素是起源块。当然，还需要添加后续的块，因为SnakeCoin是最小的区块链，这里只添加20个新的块。可以用for循环来生成新块。,下面来测试一下目前产生的区块链。,看到了吧，这就是区块链。如果希望在控制台中查看更多信息，可以,并打印每个块的时间戳或数据。,这就是SnakeCoin要提供的所有东西。为了使SnakeCoin规模达到今天生产区块链的规模，必须添加更多的功能，比如服务器层，以跟踪多台机器上的链变化，以及在给定的时间段内限制添加的块数量的,。,如果想了解更多的技术信息，可以在,查看原始的比特币白皮书。"
http://python.jobbole.com/88940/,从 Zero 到 Hero ，一文掌握 Python,http://jbcdn2.b0.upaiyun.com/2017/11/8ef4df4888b257b5ea7bbd4b033a519c.png,2017-11-28,"第一个问题，什么是 Python ？根据 Python 之父 Guido van Rossum 的话，Python 是：,对于我来说，学习 Python 的首要原因是，Python 是一种可以优雅编程的语言。它能够简单自然地写出代码和实现我的想法。,另一个原因是我们可以将 Python 用在很多地方：数据科学、Web 开发和机器学习等都可以使用 Python 来开发。Quora、Pinterest 和 Spotify 都使用 Python 来进行他们的后端 Web 开发。那么让我们来学习一下 Python 吧。,你可以把变量想象成一个用来存储值的单词。我们看个例子。,Python 中定义一个变量并为它赋值是很容易的。假如你想存储数字 1 到变量 “one” ，让我们试试看：,超级简单吧？你只需要把值 1 分配给变量 “one” 。,只要你想，你可以把任意的,赋给任何其他的,。正如你从上面看到的那样，变量 “,” 存储整型变量 ,变量 “,” 存储 10000 。,除了整型，我们还可以使用布尔值（True/Flase）、字符串、浮点型和其他数据类型。,“,” 使用一个表达式来判断一个语句是 True 还是 False ，如果是 True ，那么执行 if 内的代码，例子如下：,比 ,大，所以 ,代码被执行。,当“,”里面的表达式是 ,时，“,” 语句将会执行。,比 ,小，所以 “,” 里面的代码会执行。,你也可以使用 “,” 语句：,在 Python 中，我们可以用不同的形式进行迭代。我会说下 ,和 ,循环：当语句是 True 时，while 内部的代码块会执行。所以下面这段代码会打印出 ,到 ,循环需要,，如果条件一直是 True ，它将会一直迭代，当 num 的值为 11 时，循环条件为 false 。,另一段代码可以帮你更好的理解 while 语句的用法：,循环条件是 True 所以会一直迭代，直到为 False 。,：你可以在代码块上应用变量 “,” ，而 “for” 语句将为你迭代它。此代码将打印与 ,中相同的代码：从 1 到 10 。,瞧见没？这太简单了。i 的范围从 1 开始一直到第 11 个元素（10是第十个元素）,假如你想要在一个变量里存储整数 1 ，但是你也要存储 2 和 3 , 4 , 5 …,不是用成百上千个变量，我有别的方法存储这些我想要存储的整数吗？你已经猜到了，确实有别的存储它们的方法。,列表是一个集合，它能够存储一列值（就像你想要存储的这些），那么让我们来用一下它：,这真的很简单。我们创建了一个叫做 my_integer 的数组并且把数据存到了里面。,也许你会问：“我要怎样获取数组里的值？”,问的好。列表有一个叫做索引的概念。第一个元素的下表是索引0（0）。第二个的索引是1，以此类推，你应该明白的。,为了使它更加简洁，我们可以用它的索引代表数组元素。我画了出来：,用 Python 的语法，也很好去理解：,假如你不想存整数。你只想去存一些字符串，像你亲戚名字的列表。我的看起来是类似这样的：,它的原理跟存整数一样，很友好。,我们只学习了列表的索引是如何工作的，我还需要告诉你如何向列表的数据结构中添加一个元素（向列表中添加一个项目）。,最常用的向列表中添加新数据的方法是拼接。我们来看一下它是如何使用的："
http://python.jobbole.com/88896/,Python 内存优化,http://jbcdn2.b0.upaiyun.com/2017/11/f3b43c55d59635277f981c85325df4a5.png,2017-11-19,"实际项目中，pythoner更加关注的是Python的性能问题，之前也写过一篇文章《,》介绍Python性能优化的一些方法。而本文，关注的是Python的内存优化，一般说来，如果不发生内存泄露，运行在服务端的Python代码不用太关心内存，但是如果运行在客户端（比如移动平台上），那还是有优化的必要。具体而言，本文主要针对的Cpython，而且不涉及C扩展。,我们知道，Python使用引用技术和垃圾回收来管理内存，底层也有各种类型的内存池，那我们怎么得知一段代码使用的内存情况呢？工欲善其事必先利其器，直接看windows下的任务管理器或者linux下的top肯定是不准的。,对于基本类型，可以通过sys.getsizeof()来查看对象占用的内存大小。以下是在64位Linux下的一些结果：,可以看到，即使是一个int类型(1)也需要占用24个字节，远远高于C语言中int的范围。因为Python中一切都是对象，int也不例外（事实上是PyIntObject），除了真正存储的数值，还需要保存引用计数信息、类型信息，更具体的可以参见《Python源码剖析》。,而对于更复杂的组合类型，复杂的代码，使用getsizeof来查看就不准确了，因为在Python中变量仅仅指向一个对象，这个时候就需要更高级的工具，比如,，,，,，,。在这里重点介绍pytracemalloc。,在Python3.4中，已经支持了pytracemalloc，如果使用python2.7版本，则需要对源码打补丁，然后重新编译。pytracemalloc在,中提出，主要有以下几个特点：,简单来说，pytracemalloc hook住了python申请和释放内存的接口，从而能够追踪对象的分配和回收情况。对内存分配的统计数据可以精确到每个文件、每一行代码，也可以按照调用栈做聚合分析。而且还支持快照（snapshot）功能，比较两个快照之间的差异可以发现潜在的内存泄露。,下面通过一个例子来简单介绍pytracemalloc的用法和接口，关于更详细用法和API，可以参考这份详尽的,或者pytracemalloc的作者在pycon上的,。,在上面的代码中，用到了pytracemalloc几个核心的API：,pytracemalloc的一大好处就是可以随时启停，start函数即开始追踪内存分配，相应的stop会停止追踪。start函数有一个参数，nframes : 内存分配时记录的栈的深度，这个值越大，pytracemalloc本身消耗的内存越多，在计算cumulative数据的时候有用。,返回值是拥有两个元素的tuple，第一个元素是当前分配的内存，第二个元素是自内存追踪启动以来的内存峰值。,返回当前内存分配快照，返回值是Snapshot对象，该对象可以按照单个文件、单行、单个调用栈统计内存分配情况,运行环境：windows 64位python3.4,如果将第36行的“lineno“改成“filename”，那么结果如下,有了Profile结果之后，可以看出来在哪个文件中有大量的内存分配。与性能优化相同，造成瓶颈的有两种情况：单个对象占用了大量的内存；同时大量存在的小对象。对于前者，优化的手段并不多，惰性初始化属性可能有一些帮助；而对于后者，当同样类型的对象大量存在时，可以使用slots进行优化。,默认情况下，自定义的对象都使用dict来存储属性（通过obj.__dict__查看），而python中的dict大小一般比实际存储的元素个数要大（以此降低hash冲突概率），因此会浪费一定的空间。在新式类中使用__slots__，就是告诉Python虚拟机，这种类型的对象只会用到这些属性，因此虚拟机预留足够的空间就行了，如果声明了__slots__，那么对象就不会再有__dict__属性。,使用slots到底能带来多少内存优化呢，首先看看,，对于一个只有三个属性的Image类，使用__slots__之后内存从25.5G下降到16.2G，节省了9G的空间！,到底能省多少，取决于类自身有多少属性、属性的类型，以及同时存在多少个类的实例。下面通过一段简单代码测试一下：,上面的代码，主要是在每个实例的属性数目、并发存在的实例数目两个维度进行测试，并没有测试不同的属性类型。结果如下表：,百分比为内存优化百分比，计算公式为(b – a) / b， 其中b为没有使用__slots__时分配的内存， a为使用了__slots__时分配的内存。,关于__slots__，Python文档有非常详尽的介绍，这里只强调几点注意事项,：基类和子类都必须__slots__，即使基类或者子类没有属性,从上面的示例可以看到，子类的对象还是有__dict__属性，原因就在于基类没有声明__slots__。因此，可以通过看子类的实例有没有__dict__属性来判断slots的使用是否正确,：子类会继承基类的__slots__,更准确的说，如果访问属性的时候没有在子类的__slots__找到，会继续在基类的__slots__查找，因为Python使用descriptor在类这个层级实现__slots__的，具体可以参见《,》一文,在大型工程中，怎么排查有哪些大量存在的对象呢，毕竟同一个类型存在的对象越多，优化越有效果。除了直接看代码，最好使的就是使用objgraph.py的show_most_common_types(N)函数，该函数返回Python gc管理的所有对象中，数目前N多的对象，在排除掉python builtin对象之后，剩下的就是可优化的对象。比如在最上面的代码中：在最后加上这么两句：,输出如下：,前面介绍slots的时候，就提到Python自定义的对象中通过dict来管理属性。这种机制极大的提高了Python的灵活性 — 可以随时给对象增加属性，但是其实现机制也带来了内存上的浪费。不管是python源码，还是Python程序，都大量使用了dict，因此这部分内存浪费不容小视。,python中的dict使用的是散列表（类似C++中的std::unordered_map），当计算出的hash值冲突的时候，采用开放地址法解决冲突（另一种常见的冲突解决算法是链表法）。为了降低冲突概率，当装填因子（实际存储的元素与散列表长度的比值）超过2/3的时候就会对散列表进行扩容，因此散列表中一定会存在一些未使用的槽。,下面简单看看PyDictObject的数据结构（python2.7.3 dictobject.h）,从定义可以看出，除了固定的部分（几个Py_ssize_t），PyDictObject中主要是PyDictEntry对象，PyDictEntrty包含一个Py_ssize_t（int）和两个指针。上面源码中的注释（第26行）指出，当dict的元素比较少时，ma_table指向ma_smalltable，当元素增多时，ma_table会指向新申请的空间。ma_smalltable的作用在于Python（不管是源码还是代码）都大量使用dict，一般来说，存储的元素也不会太多，因此Python就先开辟好PyDict_MINSIZE(默认为8)个空间。,为什么说PyDictObject存在浪费呢，PyDictEntry在32位下也有12个字节，那么即使在ma_smalltable（ma_table）中大量的位置没有被使用时，也要占用这么多字节。用,中的例子：,假设有这么一个dict：,在Python源码中的视图就是这样的：,然而，完全可以这么存储：,indices的作用类似ma_smalltable，但只存储一个数组的索引值，数组只存储实际存在的元素（PyDictEntry），当dict中的元素越稀疏，相比上一种存储方式使用的内存越少。而且，这种实现， dict就是有序的（按插入时间排序）,这就是python3.6中新的dict实现，Compact dict! Stackoverflow上也有相关,。,本文中介绍了Python内存优化的Profile工具，最有效的优化方法：使用slots，也介绍了在python3.6中新的dict实现。,当然，还有一些良好的编码习惯。比如尽量使用immutable而不是mutable对象：使用tuple而不是list，使用frozenset而不是set；另外，就是尽量使用迭代器，比如python2.7中，使用xrange而不是range，dict的iterxx版本。"
http://python.jobbole.com/88912/,差评近一半，用 Python 分析胡歌的《猎场》到底值不值得看？,http://wx4.sinaimg.cn/mw690/63918611gy1fls2ib5qbij20hs0a0gmf.jpg,2017-11-23,"11 月 6 日，湖南卫视已经开播被称作年度压轴的大戏“猎场”，迅速占领各大榜单，成为一部高热度的电视剧。但是在豆瓣上却形成了两极分化。截止 11 月 8 日，该剧在豆瓣上的评分为 5.7 分。相比较胡歌之前《琅琊榜》的 9.1，《伪装者》的 8.3 等来说，这一评分确实不高。有趣的是，首页的评分比例与“短评”、“剧评”的比例存在非常大的差异！,首页总评分评分两级分化严重，“差评”占主 在目前 11463 个评价中两级分化严重，“1 星”占比最高为 28.6%，其次为“5 星”的 25.4%。“好评”（5 星、4 星）占比为 35.80%，“一般”（3 星）为 16.50%，“差评”（2 星、1 星）占比为 47.80%。很明显，“差评”占了接近一半的比例。,《猎场》豆瓣评分占比分布,在短评和剧评中的另一种景象 首页的豆瓣评分中“差评”占比很高，但是在豆瓣的短评和剧评中却是另一番景象。 在目前 5979 条短评中，“好评”占比 71%，“一般”为 5%，“差评”占比 24%。而在 392 条剧评中，“5 星”占了非常高的比例！84.7%的剧评给了“好评”。,《猎场》剧评评分分布,我们将三个位置的评分放在一起比较就会出现非常明显的差异。根据这个差异，我们可以大致判断：写出短评或者剧评的观众大部分给予了“好评”，但仍有大量观众直接给了差评，并没有说明任何原因。当然，我们并没有考虑那些不写评论，而只是点“有用”和“没用”观众。,才刚刚上映，剧情还在慢慢的铺，所以现在给整部剧下定论还太早。,《猎场》到底好不好看？我们还是想通过以 11 月 8 日为界，看看人们短评人的情绪，是积极，还是消息。利用词云看看大家都说了什么，希望能大家就是否建议观看给出建议。,同时建议在循环抓取的时候进行 sleep，例如：,《猎场》热门短评内容和时间爬取了 22440 条评论，代码如下：,样本数量：,对热门短评基于原有 SnowNLP 进行积极和消极情感分类，读取每段评论并依次进行情感值分析（代码：,），最后会计算出来一个 0-1 之间的值。,当值大于 0.5 时代表句子的情感极性偏向积极，当分值小于 0.5 时，情感极性偏向消极，当然越偏向两边，情绪越偏激。,2017-11-06 – 2017-11-08 分析：,从上图情感分析（代码：, ）来看，影评者还是还是非常积极的，对《猎场》的期望很高。,从词云（代码：, ）上来看：,2017-11-09 – 2017-11-17 分析,从上图情感分析（代码：, ）来看，积极的情绪已经远远超过消极的情绪，还是受到大家的好评。,从词云（代码：, ）上来看，出现好看、剧情、期待、喜欢等词。,词云的背景是胡歌，大家看出来了嘛？目前豆瓣的分数已经是 6.2 分，目前剧情过半，相信接下来会更精彩，个人认为分数会在 7.5 分以上。,抛开豆瓣的推荐分数，通过的热门短评的情感和词云分析，是一部不错的现实剧，剧情犀利、深刻、启迪，很多人期待。如果您有时间，不妨看一下，或许能收获一些意想不到的东西。"
http://python.jobbole.com/88915/,Pandas初学者代码优化指南,http://jbcdn2.b0.upaiyun.com/2017/11/0555f99614ede2b6f00917d386e27788.png,2017-11-23,"如果你用Python语言做过任何的数据分析，那么可能会用到,,一个由Wes McKinney写的奇妙的分析库。通过赋予Python数据帧以分析功能，Pandas已经有效地把Python和一些诸如R或者SAS这样比较成熟的分析工具置于相同的地位。,不幸的是，在早期，Pandas因“慢”而声名狼藉。的确，Pandas代码不可能达到如完全优化的原始C语言代码的计算速度。然而，好消息是，对于大多数应用程序来说，写的好的Pandas代码已,；Pandas强大的功能和友好的用户体验弥补了其速度的缺点。,在这篇文章中，我们将回顾应用于Pandas DataFrame函数的几种方法的效率，从最慢到最快：,1． 在用索引的DataFrame行上的Crude looping,
2． 用iterrows()循环,
3． 用 apply()循环,
4． Pandas Series矢量化,
5． NumPy数组矢量化,对于我们的实例函数，将使用,（半正矢）距离公式。函数取两点的经纬度，调整球面的曲率，计算它们之间的直线距离。这个函数看起来像这样：,为了在真实数据上测试函数，我们用一个包含纽约所有酒店坐标的数据集，该数据来自,。要计算每一个酒店和一个样本集坐标之间的距离（这恰好属于在纽约市名为,的一个梦幻般的小商店）,大家可以下载数据集，Jupyter notebook（是一个交互式笔记本，支持运行 40 多种编程语言）包含了用于这篇博客的函数，请点击,下载。,这篇文章基于我的PyCon访谈，大家可以在,观看。,首先，让我们快速回顾一下Pandas数据结构的基本原理。Pandas的基本结构有两种形式：,和,。一个DataFrame是一个二维,标记轴，很多功能与R中的data.frame类似，可以将DataFrame理解为Series的容器。换句话说，一个DataFrame是一个有行和列的矩阵，列有列名标签，行有索引标签。在Pandas DataFrame中一个单独的列或者行是一个Pandas Series—一个带有轴标签的一维数组。,几乎每一个与我合作过的Pandas初学者，都曾经试图通过一次一个的遍历DataFrame行去应用自定义函数。这种方法的优点是，它是Python对象之间交互的一致方式；例如，一种可以通过列表或数组循环的方式。反过来说，不利的一面是，在Pandas中，Crude loop是最慢的方法。与下面将要讨论的方法不同，Pandas中的Crude loop没有利用任何内置优化，通过比较，其效率极低（而且代码通常不那么具有可读性）,例如，有人可能会写像下面这样的代码：,为了了解执行上述函数所需要的时间，我们用,命令。,是一个“,”命令，专用于,（所有的魔法命令都以%标识开始，如果%命令只应用于一行，那么%%命令应用于整个Jupyter单元）。,命令将多次运行一个函数，并打印出获得的运行时间的平均值和标准差。当然，通过,命令获得的运行时间，运行该函数的每个系统都不尽相同。尽管如此，它可以提供一个有用的基准测试工具，用于比较同一系统和数据集上不同函数的运行时间。,结果是：,通过分析，crude looping函数运行了大约645ms,标准差是31ms。这似乎很快，但考虑到它仅需要处理大约1600行的代码，因此它实际上是很慢的。接下来看看如何改善这种不好的状况。,如果循环是必须的，找一个更好的方式去遍历行，比如用,方法。,是一个生成器，遍历DataFrame的所有行并返回每一行的索引，除了包含行自身的对象。, 是用Pandas DataFrame优化，尽管它是运行大多数标准函数最不高效的方式（稍后再谈），但相对于Crude looping，这是一个重大的改进。在我们的案例中，,解决同一个问题，几乎比手动遍历行快四倍。,一个比,更好的选择是用 , 方法，它应用一个函数，沿着DataFrame某一个特定的轴线（意思就是行或列）。虽然,也固有的通过行循环，但它通过采取一些内部优化比,更高效，例如在Cython中使用迭代器。我们使用一个匿名的lambda函数，每一行都用Haversine函数，它允许指向每一行中的特定单元格作为函数的输入。为了指定Pandas是否应该将函数应用于行（,）或列（,），Lambda函数包含最终的,参数。,方法用,方法替代后，大致可以将函数的运行时间减半。为了更深入地了解函数中的实际运行时间，可以运行一个,（Jupyter中神奇的命令,）,结果如下：,我们可以从这个信息中得到一些有用的见解。例如，进行三角计算的函数占了总运行时间的近一半。因此，如果想优化函数的各个组件，可以从这里入手。现在，特别值得注意的是每一行都被循环了1631次—apply（）遍历每一行的结果。如果可以减少重复的工作量，就可以降低整个运行时间。矢量化提供了一种更有效的替代方案。,要了解如何可以减少函数所执行的迭代数量，就要记得Pandas的基本单位，DataFrame和Series，它们都基于数组。基本单元的固有结构转换成内置的设计用于对整个数组进行操作的Pandas函数，而不是按各个值的顺序（简称,）。,是对整个数组执行操作的过程。,Pandas包含一个总体的矢量化函数集合，从数学运算到聚合和字符串函数（可用函数的扩展列表，查看,）。对Pandas Series和DataFrame的操作进行内置优化。结果，使用矢量Pandas函数几乎总是会用自定义的循环实现类似的功能。,到目前为止，我们仅传递标量给Haversine函数。所有的函数都应用在Haversine函数中，也可以在数组上操作。这使得距离矢量化函数的过程非常的简单：不是传递个别标量值的纬度和经度给它，而是把它传递给整个series（列）。这使得Pandas受益于可用于矢量函数的全套优化，特别是包括同时执行整个数组的所有计算。,通过使用,方法，要比用,方法改进50倍的效率，通过矢量化函数则改进了,方法100倍—除了改变输入类型，什么都不要做！,看一眼后台，看看函数到底在做什么：,注意，鉴于 apply() 执行函数1631次，矢量化版本仅执行一次，因为它同时应用于整个数组，这就是主要的时间节省来源。,Pandas series矢量化可以完成日常计算优化的绝大多数需要。然而，如果速度是最高优先级，那么可以以NumPy Python库的形式调用援军。,，将自己描述为一个“Python科学计算的基本包”，在后台执行优化操作，预编译C语言代码。跟Pandas一样，NumPy操作数组对象（简称ndarrays）；然而，它省去了Pandas series操作所带来的大量资源开销，如索引、数据类型检查等。因此，NumPy数组的操作可以明显快于pandas series的操作。,当Pandas series提供的额外功能不是很关键的时候，NumPy数组可以用于替代Pandas series。例如，Haversine函数矢量化实现不使用索引的经度和纬度系列，因此没有那些索引，也不会导致函数中断。通过比较，我们所做的操作如DataFrame的连接，它需要按索引来引用值，可能需要坚持使用Pandas对象。,仅仅是使用Pandas series 的,的方法，把纬度和经度数组从Pandas series转换到NumPy数组。就像series矢量化一样，通过NumPy数组直接进入函数将可以让Pandas对整个矢量应用函数。,NumPy数组操作运行取得了又一个四倍的改善。总之，通过looping改进了运行时间超过半秒，通过NumPy矢量化，运行时间改进到了三分之一毫秒级！,下面的表格总结了相关结果。用NumPy数组矢量化将会带来最快的运行时间，相对于Pandas series矢量化的效果而言，这是一个很小的改进，但对比最快的looping版本，NumPy数组矢量化带来了56倍的改进。,这给我们带来了一些关于优化Pandas代码的基本结论：,当然，以上并不是Pandas所有可能优化的全面清单。更爱冒险的用户或许可以考虑进一步用,改写函数，或者尝试优化函数的各个组件。然而，这些话题超出了这篇文章的范围。,关键的是，在开始一次宏大的优化冒险之前，要确保正在优化的函数实际上是你希望在长期运行中使用的函数。引用XKCD不朽的名言：“,”。"
http://python.jobbole.com/88892/,曲线点抽稀算法- Python 实现,http://jbcdn2.b0.upaiyun.com/2017/11/3be8f2c50649ea9862264793b74bdc66.png,2017-11-19,"通俗的讲就是对曲线进行采样简化，即在曲线上取有限个点，将其变为折线，并且能够在一定程度保持原有形状。比较常用的两种抽稀算法是：道格拉斯-普克(Douglas-Peuker)算法和垂距限值法。,Douglas-Peuker算法(DP算法)过程如下:,这种算法的抽稀精度与阈值有很大关系，阈值越大，简化程度越大，点减少的越多；反之简化程度越低，点保留的越多，形状也越趋于原曲线。,下面是Python代码实现:,垂距限值法其实和DP算法原理一样，但是垂距限值不是从整体角度考虑，而是依次扫描每一个点，检查是否符合要求。,算法过程如下:,下面是Python代码实现：,其实DP算法和垂距限值法原理一样，DP算法是从整体上考虑一条完整的曲线，实现时较垂距限值法复杂，但垂距限值法可能会在某些情况下导致局部最优。另外在实际使用中发现采用点到另外两点所在直线距离的方法来判断偏离，在曲线弧度比较大的情况下比较准确。如果在曲线弧度比较小，弯曲程度不明显时，这种方法抽稀效果不是很理想，建议使用三点所围成的三角形面积作为判断标准。下面是抽稀效果:,
, "
http://python.jobbole.com/88842/,使用 Python 在 Linux 上实现一键回归测试,http://jbcdn2.b0.upaiyun.com/2015/02/edecceebedd0d04aa17bccba430ddcaf.jpg,2017-11-10,"测试人员从代码库（例如 CVS ）迁出代码的过程中，需要手动输入访问密码，而 Python 提供了 Pexpect 模块则能够将手动输入密码这一过程自动化。当然 Pexpect 也可以用来和 ssh、ftp、passwd、telnet 等命令行进行自动化交互。这里我们以 CVS 为例展示如何利用 Pexpect 从代码库迁出代码。,在清单 1 中，我们用命令”cvs co project_code”从代码库中迁出了 project_code 的内容，我们也可以用该命令来更新已经迁出的代码。只需要将命令”cvs update” 传给类 pexpect.spawn()即可，详细的实现请参考代码文件。这里 interact()函数是必须的，用来在交互的方式下控制该子进程。有时代码库中会存在目录不一致行情况，迁出代码会因报错终止，所以需要异常处理(try … execpt)来忽略该错误。,测试人员获取最新的代码之后，就要对源码进行编译，并且运行测试用例。Python 语言提供了多种方法如 os.system()/os.popen()来执行一条命令，这里我们推荐用 subprocess 模块来创建子进程，完成代码编译和运行测试用例。因为 subprocess 支持主进程和子进程的交互，同时也支持主进程和子进程是同步执行还是异步执行。由于本文中的各个功能模块有都先后依赖关系，所以全部采用的是主进程和子进程同步模式执行。,在一些系统中我们编译代码采用的是脚本文件（如 shell 脚本），那么我们仍然可以如下命令来完成代码编译工作。,在编译完成代码之后，我们同样可以调用 subprocess.Popen 来创建子进程运行测试用例。如果测试人员的测试用例已经写成了测试例脚本，我们则可以用 subprocess.call()来执行测试例脚本文件，代码实现就不再赘述。有些系统会直接把详细日志输出到屏幕上，那么我们可以用重定向命令”2>&1″把屏幕输出写文件。,我们的项目采用敏捷开发，为了更好的反应敏捷开发周期，我们希望存储日志的目录名不但能够指明的具体日期，同时也能反映敏捷（迭代）开发阶段，这样相关人员在查看相应目录中的日志时，能够清楚的明白日志实在在哪个迭代周期的哪一天产生的。本文使用文件 summary 作为运行测试用例后生成的汇总日志，用文件 log.txt 用来存储详细日志。如下图所示，在共享目录 SharedFiles 中存储了一些列迭代周期中的日志。,为了能够让目录名反映敏捷开发周期，我们需要自己定义一个配置文件（txt 或 xml 均可）。由于 Python 已经很好的支持了 XML 解析，并且 XML 文件作为配置也是当前的流行趋势。本文就以 XML 解析为例进行说明。本文使用的 XML 文件名是 Sprint.xml，清单 6 是该 xml 的概要内容,关于 xml 解析 Python 提供了多种方法。本文采用 minidom 对 xml 文件进行解析，清单 7 是相关处理代码。,这样 cur_num 就指向了当前的迭代开发周期。然后，我们就可以根据当前日期和开发阶段创建对应的日志目录名了，最后把运行结果存储到该目录下，参见清单 8 实现。,关于测试结果的发布，本文并没有把测试结果以自动化的形式发送邮件，而是手动在每个开发周期结束时，群发邮件给相关人员。或者在验证失败后，通知相关的开发人员，这是由于作者所在团队项目代码提交频率不是很高。在更大型的项目中，往往需要增加自动发送邮件的功能，相关实现本文不再赘述。,在日常的测试过程中，我们并不是每次都要迁出代码，编译代码，运行测试用例和收集测试结果。这样就需要我们能够有选择的运行部分程序功能，例如只运行测试用例和收集结果。这里我们提供了 4 个运行选泽：,选项 1：迁出代码–>编译版本–>运行测试用例–>收集测试结果,选项 2：更新代码–>编译版本–>运行测试用例–>收集测试结果,选项 3：编译版本–>运行测试用例–>收集测试结果,选项 4：运行测试用例–>收集测试结果,当然我们还需要提供帮助信息，以方便不熟悉该脚本实现的人员使用。python 也提供了 getopt 模块让我们轻松实现上述功能。实现代码参见清单 9,如果我们在运行的过程中想中断（如利用 Ctrl+C）一键回归测试进程的执行时，有时我们会发现虽然主进程已经被终止，但子进程仍在运行。我们能否在中断主进程的同时也中断子进程呢？答案当然是肯定的，我们可以用信号处理函数捕获信号（如捕获 Ctrl+C 产生的中断信号），然后在显式终止对应的子进程。这里就需要我们在创建子进程的时候，先保存子进程 ID，当然把子进程 ID 保存到初始化函数中，是个不错的选择，清单 10 是相关实现。,这里我们需要在初始化函数中注册要捕获的信号，并且创建成员变量用来保存子进程的 ID，详细实现请参见清单 11。,最后终于轮到 class 登场了，提到 class 我们就不能不谈构造函数（初始化函数）和析构函数。之前我们多次提到初始化函数，初始化函数允许我们定义一些变量，这些变量在整个类对象的生存周期内均有效。由于本文没有向系统申请资源，就再不定义析构函数了。,通常我们不需要太关注设计风格，只要 Python 脚本能完成我们的测试要求即可。对于较小的脚本，几条 Python 指令顺序执行即可。为了模块功能复用和可读性，我们通常会把功能模块封装成函数。本文将实现的所有函数都封装到一个类中，使得该脚本更加一体化。,Python 语言是一个易学易用的脚本语言，笔者没有多久的 Python 开发经验，不过其他语言有的功能在 Python 中大都可以找到对应的实现，这也是笔者能够在很短的时间内完成该测试脚本的原因。因此，笔者把该语言和使用该语言完成一键回归测试介绍给大家，希望对大家有所帮助。正像笔者说的其他语言有的功能在 Python 中大都可以找到对应的实现，同样，如果大家对某一种特定的脚本语言或者开发语言特别熟悉，也完全可以采用所熟悉的语言来完成一键回归测试的工作。"
http://python.jobbole.com/88850/,走近 Python (类比 JS ),http://jbcdn2.b0.upaiyun.com/2017/11/c60f2447af38c6a464404d473257881e.jpg,2017-11-11,"Python 是一门运用很广泛的语言，自动化脚本、爬虫，甚至在深度学习领域也都有 Python 的身影。作为一名前端开发者，也了解 ES6 中的很多特性借鉴自 Python (比如默认参数、解构赋值、Decorator等)，同时本文会对 Python 的一些用法与 JS 进行类比。不管是提升自己的知识广度，还是更好地迎接 AI 时代，Python 都是一门值得学习的语言。,在 Python 中，最常用的能够直接处理的数据类型有以下几种：,除此之外，Python 还提供了列表（list）、字典（dict）等多种数据类型，这在下文中会介绍。,与 JS 十分类似，python 也能实现不同数据类型间的强制与隐式转换，例子如下：,强制类型转换:,隐式类型转换:,此外写代码的时候经常会需要判断值的类型，可以 使用 python 提供的 type() 函数获取变量的类型，或者使用 isinstance(x, type) 来判断 x 是否属于相应的 type 类型。,集合是指包含一组元素的数据结构，有序集合即集合里面的元素是是按照顺序排列的，Python 中的有序集合大概有以下几类：list, tuple, str, unicode。,Python 中 List 类型类似于 JS 中的 Array,,tuple 类型是另一种有序的列表，中文翻译为“ 元组 ”。tuple 和 list 非常类似，但是，tuple 一旦创建完毕，就不能修改了。,Python 中的 dict 类型类似于 JS 中的 {} (最大的不同是它是没有顺序的), 它有如下特点:,有的时候，我们只想要 dict 的 key，不关心 key 对应的 value，而且要保证这个集合的元素不会重复，这时，set 类型就派上用场了。set 类型有如下特点：,在介绍完 Python 中的有序集合和无序集合类型后，必然存在遍历集合的 for 循环。但是和其它语言的标准 for 循环不同，Python 中的所有迭代是通过 for … in 来完成的。以下给出一些常用的迭代 demos:,索引迭代：,迭代 dict 的 value:,迭代 dict 的 key 和 value:,Python 提供的切片操作符类似于 JS 提供的原生函数 slice()。有了切片操作符，大大简化了一些原来得用循环的操作。,如果要生成 [1×1, 2×2, 3×3, …, 10×10] 怎么做？方法一是循环：,但是循环太繁琐，而列表生成式则可以用一行语句代替循环生成上面的 list：,列表生成式的 for 循环后面还可以加上 if 判断(类似于 JS 中的 filter() 函数)，示例如下：,for 循环可以嵌套，因此，在列表生成式中，也可以用多层 for 循环来生成列表。,JS 中 ES6 的 默认参数正是借鉴于 Python，用法如下：,类似于 JS 函数中自动识别传入参数的个数，Python 也提供了定义可变参数，即在可变参数的名字前面带上个 , 号。,Python 解释器会把传入的一组参数组装成一个 tuple 传递给可变参数，因此，在函数内部，直接把变量 args 看成一个 tuple 就好了。,Python 中常用的函数 (map、reduce、filter) 的作用和 JS 中一致，只是用法稍微不同。,和 JS 的匿名函数不同的地方是，Python 的匿名函数中只能有一个表达式，且不能写 return。拿 map() 函数为例：,关键词 lambda 表示匿名函数，冒号前面的 x 表示函数参数，可以看出匿名函数 , 实际上就是:,之前写过一些关于 JS 闭包的文章，比如 ,、以及 ,，Python 中闭包的定义和 JS 中的是一致的即：内层函数引用了外层函数的变量，然后返回内层函数。下面来看下 Py 中闭包之 for 循环经典问题：,老问题了，f1(), f2(), f3() 结果不应该是 1, 4, 9 吗，实际结果为什么都是 9 呢？,原因就是当 count() 函数返回了 3 个函数时，这 3 个函数所引用的变量 i 的值已经变成了 3。由于 f1、f2、f3 并没有被调用，所以，此时他们并未计算 i*i，当 f1 被调用时，i 已经变为 3 了。,要正确使用闭包，就要确保引用的局部变量在函数返回后不能变。代码修改如下:,方法一: 可以理解为创建了一个封闭的作用域，i 的 值传给 j 之后，就和 i 没任何关系了。每次循环形成的闭包都存进了内存中。,方法二：思路比较巧妙，用到了默认参数 j 在函数定义时可以获取到 i 的值，虽然没有用到闭包，但是和方法一有异曲同工之处。,ES6 的语法中的 decorator 正是借鉴了 Python 的 decorator。decorator 本质上就是,那装饰器的作用在哪呢？先上一段日常项目中用 ts 写的网关代码：,可以看出使用装饰器可以极大地简化代码，避免每个函数(比如日志、路由、性能检测)编写重复性代码。,回到 Python 上，Python 提供的 @ 语法来使用 decorator，@ 等价于f=decorate(f)。下面来看看 @log() 在 Python 中的实现:,面向对象编程是一种程序设计范式，基本思想是：用类定义抽象类型，然后根据类的定义创建出实例。在掌握其它语言的基础上，还是比较容易理解这块知识点的，比如从下面两种写法可以看出不同语言的语言特性间竟然有如此多的共性。,es6: (附：本文的主题是 python，所以只是初略展示下 js 中类的定义以及实例的创建，为了说明写法的相似性),Python: (核心要点写在注释中),child 属于 Student 类，Student 类属于 People 类，这就引出了继承: 即获得了父类的方法属性后又能添加自己的方法属性。,可以看到子类在父类的基础上又增加了 grade 属性。我们可以再来看看 s 的类型。,可以看出，Python 中在一条继承链上，一个实例可以看成它本身的类型，也可以看成它父类的类型。"
http://python.jobbole.com/88845/,Perl 与 Python 之间的一些异同,http://jbcdn2.b0.upaiyun.com/2015/10/bfa0d07e7eb2fac2eb80cd5df9567931.jpg,2017-11-10,"Perl 是 Practical Extraction and Report Language 的简称，由 1987 年 Larry Wall 创建，最初的目的是为了在 UNIX 上方便处理报表，经过长期的发展已经成为一种全功能的程序设计语言，当前最新的版本为 Perl5.14.1，Perl 作为一种自由而强大的编程语言，其中心思想是： There’s More Than One Way To Do It。（不只一种方法來做这件事 )，即「 Tim Toady 」。作为一种“胶水型”语言，它具有强大的正则表达式和模式匹配功能以及灵活的数据结构，如动态数组、Hash 等，在语法规则上借鉴了 C/C++、Basic、Pascal 等语言，其不足之处在于存在一些冗余语法，代码的可读性较差。,Python 是一种基于面向对象的解析性交互式的开源编程语言，它起源于 1989 年末由 CWI（阿姆斯特丹国家数学和计算机科学研究所）的研究员 Guido van Rossum 创立，1991 年初公开发行，其开源式的发行方式促进了 Python 的较快发展，目前已经形成了一个强大的社区力量。Python 开发者的哲学是“用一种方法，最好是只有一种方法来做一件事”。Python 具有简单易学、代码规范、语法简单、可移植性强、支持多平台、类库丰富等优点。,
Perl 和 Python 都是开源的，但其哲学理念却刚好相反，因此常被人们将这两种语言放在一起进行比较。下面的篇章将从基本数据类型、控制流、函数、面向对象、文本处理等方面对这两种语言进行简单的比较和鉴别。,脚本语言支持多种数据类型，变量无需事先申明，类型根据值来动态确定，一个变量在程序中可以根据上下文环境的不同存储不同类型的值。,Perl 支持的基本数据类型包括：标量、数组、哈希。在定义的时分别用 $、@、% 表示。,Python 支持五种基本数据类型：数字 (Numbers)、字符串 (String)、列表 (List)、元组 (Tuple) 和字典 (Dictionary)。其中数字和字符串和 perl 中的标量对应，列表和数组对应，元组可以看做是不可变的列表，字典和 hash 对应。,在控制结果方面，Perl 较 Python 丰富，除了支持传统的 if 、while 、for 控制结构，还支持 until 、unless 、foreach 等，Python 的控制结构相对要少一些，但已经能够满足语言的要求。本节对这些控制结构进行详细比较。,Perl 与 Python 都支持 if 、if-else 、if-else if- else 三种结构，两者在语法上基本类似，但与 Python 不同的是 Perl 中没有 boolean 类型，零和空表示 False，其余表示 True，而 Python 中除了”、””、0、()、[]、{}、None 为 False 之外，其他的都是 True。同时 Python 直接用缩进表示 block 块。,Perl 中还支持 unless 条件控制语句，基本语法如下：,unless 和 if 不同之处在于当条件表达式的值为假的时候才执行，同时 unless 后面还能跟 else 语句。如：,Perl 中的 for 循环除了支持传统的 for 循环，即 for ( 表达式 1; 表达式 2; 表达式 3) ，还支持 foreach 语句，基本语法为：,python 不支持传统的 for 循环，但是提供了强大的循环结构可以遍历序列成员，同时 for 循环后面也可以接 else 语句，基本语法如下：,Perl 循环控制结果还支持 while 和 do-while 以及 until 形式，until 与 while 结构相似，区别在于 unitl 会在条件为假的时候重复执行。until 语法如下：,而 python 只支持 while 形式，但 python 可以在 while 后面接 else 语句。语法如下：,Perl 有三个循环控制操作符，分别为 Last 、next 、redo。,Python 也有三个循环控制操作符，分别为 break 、continue 、pass 语句。,Perl 和 Python 都支持函数，可以传递参数以及在程序中对函数进行调用等。下面从函数的定义，调用，返回值以及参数传递等方面对这两者进行比较。,
,Perl 程序把变量和子程序的名称存贮到符号表中，Perl 的符号表中名字的集合就称为 Perl 包 (package)。定义语法为：package mypack；每个符号表有其自己的一组变量、子程序名，各组名字是不相关的，因此可以在不同的 Perl 包中使用相同的变量名，而代表的是不同的变量。Perl 模块有两种来源，一种是随 Perl 发行版本一同打包的，另外就是用 CPAN 中下载的。Perl 模块和包的概念并不清晰，两者有时可以混用。在程序中使用模块的操作称为导入模块；导入模块关键字 use；如：use ModuleName；模块被导入后，其中的子程序和变量就可以直接使用了；要取消一个已经导入了的模块，可以使用关键字 no；如：no ModuleName。,一个 .py 文件就是一个 python 模块。把一堆相关的 python 模块放在一个目录下，再加上一个 __init__.py 文件就构成了一个 python 包。在 Python 另一个程序中导入模块用 import module 或者 from module import *，两者的区别在于：import module 会导入 module 这个模块里的所有标识，但是这些标识现在都在 module 名字空间下。from module import * 也会导入 module 中所有标识，但是标识放到在当前名字空间里。,导入模块或包按下面顺序进行路径查找：,
1. 当前目录,
2. 环境变量 PYTHONPATH 所指的目录列表 3.python 解释器的安装目录,在 Perl 中，类是 Perl 包，含有提供对象方法的类，而方法是 Perl 的子程序，类名是其第一个参数，对象是对类中数据项的引用。在 Perl 中创建一个新类，首先要创建一个包，扩展名为 .pm, 在创建 perl 包的时候程序的最后一个必须为”1;”；否则该包不会被 Perl 处理。,其中 new() 方法是对象的构造函数，是创建该类的对象实例必须被调用的，它返回该对象的引用。将类名与引用相结合称为”bless”一个对象，其语法为：bless YeReference [,classname],YeReference 是对被”祝福”的对象的引用，classname 是可选项，指定对象获取方法的包名，其缺省值为当前包名。也可以通过函数 bless 来声明一个构造函数。,创建一个对象可以直接使用 new 关键字。$object = new Person( “mohand”, “sam”, 345);,Perl 类中的方法就 Perl 的子函数，规定第一个参数为对象或者被引用的包，分为静态方法和虚方法。 虚方法通常首先把第一个参数 shift 到变量 self 或 this 中，然后将该值作普通的引用使用。一是通过该对象的引用 ( 虚方法 )，一是直接使用类名 ( 静态方法 )。如上例中如果类 Person 中有 getContactList 则可以直接使用 $object->getContactList() 来调用该方法。,Perl 支持重载，当两个不同的类中含有相同的方法名称的时候，可以用 :: 操作符指定使用哪个类中的方法。,由于 Perl 采用了简单的、基于引用的垃圾回收系统。Perl 跟踪对象的链接数目，当某对象的最后一个应用释放到内存池时，该对象就自动销毁。因此一般不需要定义类的析构函数。,Perl 通过数组 , 支持继承。,当子类继承父类的时候，继承了父类的所有方法，但子类也可以覆盖父类的方法。如加入 Employee 想覆盖父类的 getFirstName：,调用直接使用 $firstName = $object->getFirstName(); 如果要调用父类的 getFirstName，则可以使用 $object->Person::getFirstName();,在 Python 中创建一个类的基本语法为 :,参数 base 可以是一个单继承或者多继承的父类，object 是所有类的父类，位于类继承结构的最上层。类的构造函数为 __init__()，其中构造函数中 self 会作为第一个默认的参数。而类的析构函数则是 __del__()，访问类的方法和属性可以直接使用 . 访问符。,Python 不支持纯虚函数或抽象方法，并且声明和定义没有本质区别。一般或者 Python 类的属性可以通过 __dict__ 或者 dict（）访问。常见属性有 __name__ ，__doc__，__base__，__dict__。Python 中创建一个类的实例，不需要关键之 new，直接使用类名 () 即可。如 c=myclass()。,Python 不仅仅支持单继承和多继承，同时还支持方法的覆盖 .,现在创建 C 类 , 继承于 P,当从一个带构造器 __init()_ 的类派生，如果在子类中覆盖了 __init__()，当子类被实例化时，基类的 __init__() 方法不会被自动调用。如果必须调用基类的构造方法，可以使用父类名 .__init__(self) 方法或者 super( 子类名，self).__init__()。 如,Python 类和实例支持一些内建函数，如,Issubclass(sub,sup)：判断一个类是另一个类的子类或子孙类；,isinstance(obj1,obj2)：判定一个对象是否是另一个给定类的实例；,正则表达式是 perl 比较突出的一大特色，perl 中正则表达式有三种形式：,
匹配：m// （还可以简写为 /;/ ，略去 m） 替换：s/// ，为了语法的简化用 /// 表示，略去 s,转换：tr/// 这种形式包含一系列的字符— / —同时把它们替换为 。,Python 语言本身不支持正则表达式，依赖 re 模块（python1.5 版本被引入）支持正则表达式。有搜索和匹配两种方法完成匹配模式。re 模块常用的函数和方法有 complie、match、search、find 与 findall 等。在利用 re 进行匹配之前，模式必须被编译成 regex 对象。,线程是一个单一的执行流程，它是所有程序执行过程中最小的控制单位，即能被 CPU 所调度的最小任务单元。在 Perl 中一个线程的生命周期包括创建，运行与退出这三个阶段。线程的运行过程与普通函数的执行类似，但新建线程的执行与当前线程的执行是并行的。,在 Perl 中创建线程有两种方法：,对于线程的执行控制，有两种方式，一种是 join()，一种是 detach()。所谓 join() 就是在主线程中等待子线程的执行返回值，然后再继续执行后续代码，而在调用线程的 join() 方法之前，子线程与主线程的执行是分开的。而 detach() 则是告诉解释器主线程不关心子线程的执行结果，所以该子线程在完成任务之后就是自动退出，同时释放自己所占有的资源，而不用主线程再操心。,Perl 默认任何数据结构都不是共享的，任何新创建的线程都有当前数据的私有拷贝。如果要共享数据，必须使用 threads::shard 进行显示声明。,如：,同时 Perl 线程还支持锁机制，可以使用 lock 方法实现线程间共享数据的锁机制。Perl 中的 Thread::Semaphore 包为线程提供了信号量的支持，Thread::Queue 包为线程提供了线程安全的队列支持。更多使用读者可以自行查阅相关文档。,Python 提供了几个用于多线程编程的模块，包括 thread, threading 和 Queue 等。thread 和 threading 模块允许程序员创建和管理线程。thread 模块提供了基本的线程和锁的支持，而 threading 提供了更高级别，功能更强的线程管理的功能。Queue 模块允许用户创建一个可以用于多个线程之间共享数据的队列数据结构。,Python 的线程创建也有两种方式，一是利用 thread 模块的 start_new_thread() 函数来产生新线程。,另一种是创建 threading.Thread 的子类来包装一个线程对象。,Python 线程中也提供同步机制，可以利用 thrading 模块的 threading.RLock 和 hreading.Condition 可以分别实现锁机制和条件变量。,其中 acquire() 和 release() 方法分别获取和释放锁。,更多关于线程的内容，读者可查阅相关文档。,本文从 Perl 和 Python 的起源，基本数据类型、控制结构、函数、包与模块、面向对象、正则表达式以及线程等方面进行了比较，从而给需要同时掌握这两种脚本语言的开发人员一定参考，以便更好的理解与应用。"
http://python.jobbole.com/88827/,使用 GC、Objgraph 干掉 Python 内存泄露与循环引用！,http://jbcdn2.b0.upaiyun.com/2017/11/92f71271d02d70372302b5e0886d112d.png,2017-11-06,"Python使用引用计数和垃圾回收来做内存管理，前面也写过一遍文章《,》，介绍了在python中，如何profile内存使用情况，并做出相应的优化。本文介绍两个更致命的问题：内存泄露与循环引用。内存泄露是让所有程序员都闻风丧胆的问题，轻则导致程序运行速度减慢，重则导致程序崩溃；而循环引用是使用了引用计数的数据结构、编程语言都需要解决的问题。本文揭晓这两个问题在python语言中是如何存在的，然后试图利用gc模块和objgraph来解决这两个问题。,注意：本文的目标是Cpython，测试代码都是运行在Python2.7。另外，本文不考虑C扩展造成的内存泄露，这是另一个复杂且头疼的问题。,Python中，一切都是对象，又分为mutable和immutable对象。二者区分的标准在于是否可以原地修改，“原地“”可以理解为相同的地址。可以通过id()查看一个对象的“地址”，如果通过变量修改对象的值，但id没发生变化，那么就是mutable，否则就是immutable。比如：,判断两个变量是否相等（值相同）使用==， 而判断两个变量是否指向同一个对象使用 is。比如下面a1 a2这两个变量指向的都是空的列表，值相同，但是不是同一个对象。,为了避免频繁的申请、释放内存，避免大量使用的小对象的构造析构，python有一套自己的内存管理机制。在巨著《Python源码剖析》中有详细介绍，在python源码obmalloc.h中也有详细的描述。如下所示：,可以看到，python会有自己的内存缓冲池（layer2）以及对象缓冲池（layer3）。在Linux上运行过Python服务器的程序都知道，python不会立即将释放的内存归还给操作系统，这就是内存缓冲池的原因。而对于可能被经常使用、而且是,的对象，比如较小的整数、长度较短的字符串，python会缓存在layer3，避免频繁创建和销毁。例如：,本文并不关心python是如何管理内存块、如何管理小对象，感兴趣的读者可以参考,和,上的这两篇文章。,本文关心的是，一个普通的对象的生命周期，更明确的说，对象是什么时候被释放的。当一个对象理论上（或者逻辑上）不再被使用了，但事实上没有被释放，那么就存在内存泄露；当一个对象事实上已经不可达（unreachable），即不能通过任何变量找到这个对象，但这个对象没有立即被释放，那么则可能存在循环引用。,引用计数（References count），指的是每个Python对象都有一个计数器，记录着当前有多少个变量指向这个对象。,将一个对象直接或者间接赋值给一个变量时，对象的计数器会加1；当变量被del删除，或者离开变量所在作用域时，对象的引用计数器会减1。当计数器归零的时候，代表这个对象再也没有地方可能使用了，因此可以将对象安全的销毁。Python源码中，通过Py_INCREF和Py_DECREF两个宏来管理对象的引用计数，代码在object.h,通过sys.getrefcount(obj)对象可以获得一个对象的引用数目，返回值是真实引用数目加1（加1的原因是obj被当做参数传入了getrefcount函数），例如：,从对象1的引用计数信息也可以看到，python的对象缓冲池会缓存十分常用的immutable对象，比如这里的整数1。,引用计数的优点在于原理通俗易懂；且将对象的回收分布在代码运行时：一旦对象不再被引用，就会被释放掉（be freed），不会造成卡顿。但也有缺点：额外的字段（ob_refcnt）；频繁的加减ob_refcnt，而且可能造成连锁反应。但这些缺点跟,比起来都不算事儿。,什么是循环引用，就是一个对象直接或者间接引用自己本身，引用链形成一个环。且看下面的例子：,运行上面的代码，使用,工具集（本文使用的是dotty）打开生成的两个文件，direct.dot 和 indirect.dot，得到下面两个图,通过属性名(attr, attr_a, attr_b）可以很清晰的看出循环引用是怎么产生的,前面已经提到，对于一个对象，当没有任何变量指向自己时，引用计数降到0，就会被释放掉。我们以上面左边那个图为例，可以看到，红框里面的OBJ对象想在有两个引用（两个入度），分别来自帧对象frame（代码中，函数局部空间持有对OBJ实例的引用）、attr变量。我们再改一下代码，在函数运行技术之后看看是否还有OBJ类的实例存在，引用关系是怎么样的：,修改后的代码，OBJ实例(a)存在于函数的local作用域。因此，当函数调用结束之后，来自帧对象frame的引用被解除。从图中可以看到，当前对象的计数器（入度）为1，按照引用计数的原理，是不应该被释放的，但这个对象在函数调用结束之后就是事实上的垃圾，这个时候就需要另外的机制来处理这种情况了。,python的世界，很容易就会出现循环引用，比如标准库Collections中OrderedDict的实现（已去掉无关注释）：,注意第8、9行，root是一个列表，列表里面的元素之自己本身！,这里强调一下，,在python中，使用标记-清除算法（mark-sweep）和分代（generational）算法来垃圾回收。在《,》一文中有对标记回收算法，然后在《,》一文中，有对前文的翻译，并且有分代回收的介绍。在这里，引用后面一篇文章：,关于分代回收：,！,为什么要分代呢，这个算法的根源来自于weak generational hypothesis。这个假说由两个观点构成：首先是年亲的对象通常死得也快，比如大量的对象都存在于local作用域；而老对象则很有可能存活更长的时间，比如全局对象，module， class。,垃圾回收的原理就如上面提示，详细的可以看Python源码，只不过事实上垃圾回收器还要考虑__del__，弱引用等情况，会略微复杂一些。,什么时候会触发垃圾回收呢，有三种情况：,对于垃圾回收，有两个非常重要的术语，那就是,（当然还有与之对应的unreachable与uncollectable），后文也会大量提及。,reachable是针对python对象而言，如果从根集（root）能到找到对象，那么这个对象就是reachable，与之相反就是unreachable，事实上就是只存在于循环引用中的对象，Python的垃圾回收就是针对unreachable对象。,而collectable是针对unreachable对象而言，如果这种对象能被回收，那么是collectable；如果不能被回收，即循环引用中的对象定义了__del__， 那么就是uncollectable。Python垃圾回收对uncollectable对象无能为力，会造成事实上的内存泄露。,这里的gc（garbage collector）是Python 标准库，该module提供了与上一节“垃圾回收”内容相对应的接口。通过这个module，可以开关gc、调整垃圾回收的频率、输出调试信息。gc模块是很多其他模块（比如objgraph）封装的基础，在这里先介绍gc的核心API。,开启gc（默认情况下是开启的）；关闭gc；判断gc是否开启,执行一次垃圾回收，不管gc是否处于开启状态都能使用,设置垃圾回收阈值； 获得当前的垃圾回收阈值,注意：gc.set_threshold(0)也有禁用gc的效果,返回所有被垃圾回收器（collector）管理的对象。这个函数非常基础！只要python解释器运行起来，就有大量的对象被collector管理，因此，该函数的调用比较耗时！,比如，命令行启动python,返回obj对象直接指向的对象,返回所有直接指向obj的对象,下面的实例展示了get_referents与get_referrers两个函数,a, b都是类OBJ的实例，执行”a.attr = b”之后，a就通过‘’attr“这个属性指向了b。,设置调试选项，非常有用，常用的flag组合包含以下,既然Python中通过引用计数和垃圾回收来管理内存，那么什么情况下还会产生内存泄露呢？有两种情况：,，比如网络服务器，可能存在一个全局的单例ConnectionManager，管理所有的连接Connection，如果当Connection理论上不再被使用的时候，没有从ConnectionManager中删除，那么就造成了内存泄露。,，这个在《,》一文中有详细介绍，简而言之，如果定义了__del__函数，那么在循环引用中Python解释器无法判断析构对象的顺序，因此就不错处理。,在任何环境，不管是服务器，客户端，内存泄露都是非常严重的事情。,如果是线上服务器，那么一定得有监控，如果发现内存使用率超过设置的阈值则立即报警，尽早发现些许还有救。当然，谁也不希望在线上修复内存泄露，这无疑是给行驶的汽车换轮子，因此尽量在开发环境或者压力测试环境发现并解决潜在的内存泄露。在这里，发现问题最为关键，只要发现了问题，解决问题就非常容易了，因为按照前面的说法，出现内存泄露只有两种情况，在第一种情况下，只要在适当的时机解除引用就可以了；在第二种情况下，要么不再使用__del__函数，换一种实现方式，要么解决循环引用。,那么怎么查找哪里存在内存泄露呢？武器就是两个库：gc、objgraph,在上面已经介绍了gc这个模块，理论上，通过gc模块能够拿到所有的被garbage collector管理的对象，也能知道对象之间的引用和被引用关系，就可以画出对象之间完整的引用关系图。但事实上还是比较复杂的，因为在这个过程中一不小心又会引入新的引用关系，所以，有好的轮子就直接用吧，那就是,。,objgraph的实现调用了gc的这几个函数：gc.get_objects(), gc.get_referents(), gc.get_referers()，然后构造出对象之间的引用关系。objgraph的代码和文档都写得比较好，建议一读。,下面先介绍几个十分实用的API,返回该类型对象的数目，其实就是通过gc.get_objects()拿到所用的对象，然后统计指定类型的数目。,返回该类型的对象列表。线上项目，可以用这个函数很方便找到一个单例对象,打印实例最多的前N（limits）个对象，这个函数非常有用。在《Python内存优化》一文中也提到，该函数能发现可以用slots进行内存优化的对象,统计自上次调用以来增加得最多的对象，这个函数非常有利于发现潜在的内存泄露。,，因此即使有循环引用也不会对判断造成影响。,值得一提，该函数的实现非常有意思，简化后的代码如下：,注意形参peak_stats使用了可变参数作为默认形参，这样很方便记录上一次的运行结果。在《,》中提到，使用可变对象做默认形参是最为常见的python陷阱，但在这里，却成为了方便的利器！,生产一张有关objs的引用图，看出看出对象为什么不释放，后面会利用这个API来查内存泄露。,该API有很多有用的参数，比如层数限制(max_depth)、宽度限制(too_many)、输出格式控制(filename output)、节点过滤(filter, extra_ignore)，建议使用之间看一些document。,找到一条指向obj对象的最短路径，且路径的头部节点需要满足predicate函数 （返回值为True）,可以快捷、清晰指出 对象的被引用的情况，后面会展示这个函数的威力,将find_backref_chain 找到的路径画出来, 该函数事实上调用show_backrefs，只是排除了所有不在路径中的节点。,在这一节，介绍如何利用objgraph来查找内存是怎么泄露的,如果我们怀疑一段代码、一个模块可能会导致内存泄露，那么首先调用一次obj.show_growth()，然后调用相应的函数，最后再次调用obj.show_growth()，看看是否有增加的对象。比如下面这个简单的例子：,运行结果（我们只关心后一次show_growth的结果）如下,代码很简单，函数开始的时候讲对象加入了global作用域的_cache列表，然后期望是在函数退出之前从_cache删除，但是由于提前返回或者异常，并没有执行到最后的remove语句。从运行结果可以发现，调用函数之后，增加了一个类OBJ的实例，然而理论上函数调用结束之后，所有在函数作用域（local）中声明的对象都改被销毁，因此这里就存在内存泄露。,当然，在实际的项目中，我们也不清楚泄露是在哪段代码、哪个模块中发生的，而且往往是发生了内存泄露之后再去排查，这个时候使用obj.show_most_common_types就比较合适了，如果一个自定义的类的实例数目特别多，那么就可能存在内存泄露。如果在压力测试环境，停止压测，调用gc.collet，然后再用obj.show_most_common_types查看，如果对象的数目没有相应的减少，那么肯定就是存在泄露。,当我们定位了哪个对象发生了内存泄露，那么接下来就是分析怎么泄露的，引用链是怎么样的，这个时候就该show_backrefs出马了，还是以之前的代码为例，稍加修改：,show_backrefs查看内存泄露,注意，上面的代码中，max_depth参数非常关键，如果这个参数太小，那么看不到完整的引用链，如果这个参数太大，运行的时候又非常耗时间。,然后打开dot文件，结果如下,可以看到泄露的对象（红框表示），是被一个叫_cache的list所引用，而_cache又是被__main__这个module所引用。,对于示例代码，dot文件的结果已经非常清晰，但是对于真实项目，引用链中的节点可能成百上千，看起来非常头大，下面用tornado起一个最最简单的web服务器（代码不知道来自哪里，且没有内存泄露，这里只是为了显示引用关系），然后绘制socket的引用关关系图，代码和引用关系图如下：,可见，代码越复杂，相互之间的引用关系越多，show_backrefs越难以看懂。这个时候就使用show_chain和find_backref_chain吧，这种方法，在官方文档也是推荐的，我们稍微改改代码，结果如下：,上面介绍了内存泄露的第一种情况，对象被“非期望”地引用着。下面看看第二种情况，循环引用中的__del__， 看下面的代码：,上面的代码存在循环引用，而且OBJ类定义了__del__函数。如果没有定义__del__函数，那么上述的代码会报错， 因为gc.collect会将循环引用删除，objgraph.by_type(‘OBJ’)返回空列表。而因为定义了__del__函数，gc.collect也无能为力，结果如下：,从图中可以看到，对于这种情况，还是比较好辨识的，因为objgraph将__del__函数用特殊颜色标志出来，一眼就看见了。另外，可以看见gc.garbage（类型是list）也引用了这两个对象，原因在document中有描述，当执行垃圾回收的时候，会将定义了__del__函数的类实例（被称为uncollectable object）放到gc.garbage列表，因此，,。在这里，通过增加extra_ignore来排除gc.garbage的影响：,将上述代码的最后一行改成：,另外，也可以设置DEBUG_UNCOLLECTABLE 选项，直接将uncollectable对象输出到标准输出，而不是放到gc.garbage,除非定义了__del__方法，那么循环引用也不是什么万恶不赦的东西，因为垃圾回收器可以处理循环引用，而且不准是python标准库还是大量使用的第三方库，都可能存在循环引用。如果存在循环引用，那么Python的gc就必须开启（gc.isenabled()返回True），否则就会内存泄露。但是在某些情况下，我们还是不希望有gc，比如对内存和性能比较敏感的应用场景，在,中，提到instagram通过禁用gc，性能提升了10%；另外，在一些应用场景，垃圾回收带来的卡顿也是不能接受的，比如RPG游戏。从前面对垃圾回收的描述可以看到，执行一次垃圾回收是很耗费时间的，因为需要遍历所有被collector管理的对象（即使很多对象不属于垃圾）。因此，要想禁用GC，就得先彻底干掉循环引用。,同内存泄露一样，解除循环引用的前提是定位哪里出现了循环引用。而且，如果需要在线上应用关闭gc，那么需要自动、持久化的进行检测。下面介绍如何定位循环引用，以及如何解决循环引用。,这里还是是用GC模块和objgraph来定位循环引用。需要注意的事，,（调用gc.disable()）， 防止误差。,这里利用之前介绍循环引用时使用过的例子： a， b两个OBJ对象形成循环引用,运行结果（部分）：,上面的代码中使用的是show_most_common_types，而没有使用show_growth（因为growth会手动调用gc.collect()），通过结果可以看到，内存中现在有100个OBJ对象，符合预期。当然这些OBJ对象没有在函数调用后被销毁，不一定是循环引用的问题，也可能是内存泄露，比如前面OBJ对象被global作用域中的_cache引用的情况。怎么排除是否是被global作用域的变量引用的情况呢，方法还是objgraph.find_backref_chain(obj)，在__doc__中指出，如果找不到符合条件的应用链（chain），那么返回[obj]，稍微修改上面的代码：,上面的代码输出：,验证了我们的想法，OBJ对象不是被global作用域的变量所引用。,在实际项目中，不大可能到处用objgraph.show_most_common_types或者objgraph.by_type来排查循环引用，效率太低。有没有更好的办法呢，有的，那就是使用gc模块的debug 选项。在前面介绍gc模块的时候，就介绍了gc.DEBUG_COLLECTABLE 选项，我们来试试：,上面代码第13行设置了debug flag，可以打印出collectable对象。另外，只用调用一次show_cycle_reference函数就足够了（这也比objgraph.show_most_common_types方便一点）。在第16行手动调用gc.collect()，输出如下：,注意：只有当对象是unreachable且collectable的时候，在collect的时候才会被输出，也就是说，如果是reachable，比如被global作用域的变量引用，那么也是不会输出的。,通过上面的输出，我们已经知道OBJ类的实例存在循环引用，但是这个时候，obj实例已经被回收了。那么如果我想通过show_backrefs找出这个引用关系，需要重新调用show_cycle_reference函数，然后不调用gc.collect，通过show_backrefs 和 by_type绘制。有没有更好的办法呢，可以让我在一次运行中发现循环引用，并找出引用链？答案就是使用DEBUG_SAVEALL，下面为了展示方便，直接在命令行中操作（当然，使用ipython更好）,上面在调用gc.collect之前，gc.garbage里面是空的，由于设置了DEBUG_SAVEALL，那么调用gc.collect时，会将collectable对象放到gc.garbage。此时，对象没有被释放，我们就可以直接绘制出引用关系，这里使用了objgraph.at，当然也可以使用objgraph.by_type， 或者直接从gc.garbage取对象，结果如下：,出了循环引用，可以看见还有两个引用，gc.garbage与局部变量o，相信大家也能理解。,找到循环引用关系之后，解除循环引用就不是太难的事情，总的来说，有两种办法：手动解除与使用weakref。,手动解除很好理解，就是在合适的时机，解除引用关系。比如，前面提到的collections.OrderedDict：,更常见的情况，是我们自定义的对象之间存在循环引用：要么是单个对象内的循环引用，要么是多个对象间的循环引用，我们看一个单个对象内循环引用的例子：,上面的代码非常常见，代码也很简单，初始化函数中为每种消息类型定义响应的处理函数，当消息到达(on_msg)时根据消息类型取出处理函数。但这样的代码是存在循环引用的，感兴趣的读者可以用objgraph看看引用图。如何手动解决呢，为Connection增加一个destroy（或者叫clear）函数，该函数将 self.msg_handlers 清空（self.msg_handlers.clear()）。当Connection理论上不在被使用的时候调用destroy函数即可。,对于多个对象间的循环引用，处理方法也是一样的，就是在“适当的时机”调用destroy函数，难点在于什么是,。,另外一种更方便的方法，就是使用弱引用,， weakref是Python提供的标准库，旨在解决循环引用。,weakref模块提供了以下一些有用的API：,（1）weakref.ref(object, callback = None),创建一个对object的弱引用，返回值为weakref对象，callback: 当object被删除的时候，会调用callback函数，在标准库logging （__init__.py）中有使用范例。使用的时候要用()解引用，如果referant已经被删除，那么返回None。比如下面的例子,运行上面的代码，第12行会抛出异常：AttributeError: ‘NoneType’ object has no attribute ‘f’。因为这个时候被引用的对象已经被删除了,（2）weakref.proxy(object, callback = None),创建一个代理，返回值是一个weakproxy对象，callback的作用同上。使用的时候直接用 和object一样，如果object已经被删除 那么跑出异常   ReferenceError: weakly-referenced object no longer exists。,注意第10行 12行与weakref.ref示例代码的区别,（3）weakref.WeakSet,这个是一个弱引用集合，当WeakSet中的元素被回收的时候，会自动从WeakSet中删除。WeakSet的实现使用了weakref.ref，当对象加入WeakSet的时候，使用weakref.ref封装，指定的callback函数就是从WeakSet中删除。感兴趣的话可以直接看源码（_weakrefset.py），下面给出一个参考例子：,（4）weakref.WeakValueDictionary， weakref.WeakKeyDictionary,实现原理和使用方法基本同WeakSet,本文的篇幅略长，首选是简单介绍了python的内存管理，重点介绍了引用计数与垃圾回收，然后阐述Python中内存泄露与循环引用产生的原因与危害，最后是利用gc、objgraph、weakref等工具来分析并解决内存泄露、循环引用问题。"
http://python.jobbole.com/88822/,机器学习算法实践-树回归,http://pytlab.org/assets/images/blog_img/2017-11-03-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5-%E6%A0%91%E5%9B%9E%E5%BD%92/feature.png,2017-11-04,"最近由于开始要把精力集中在课题的应用上面了，这篇总结之后算法原理的学习先告一段落。本文主要介绍决策树用于回归问题的相关算法实现，其中包括回归树(regression tree)和模型树(model tree)的实现，并介绍了预剪枝(preprune)和后剪枝(postprune)的防止树过拟合的技术以及实现。最后对回归树和标准线性回归进行了对比。,在之前的文章中我总结了通过使用构建决策树来进行类型预测。直观来看树结构最容易对分类问题进行处理，通过递归我们在数据中选取最佳分割特征对训练数据进行分割并进行树分裂最终到达触底条件获得训练出来决策树，可以通过可视化的方式直观的查看训练模型并对数据进行分类。,通常决策树树分裂选择特征的方法有ID3, C4.5算法, C5.0算法和CART树。在《,》中对ID3以及C4.5算法进行了介绍并使用ID3算法处理了分类问题。本文主要使用决策树解决回归问题，使用CART(Classification And Regression Trees)算法。,CART是一种二分递归分割的技术，分割方法采用基于最小距离的基尼指数估计函数，将当前的样本集分为两个子样本集，使得生成的的每个非叶子节点都有两个分支。因此，CART算法生成的决策树是结构简洁的二叉树。,分类树是针对目标变量是离散型变量，通过二叉树将数据进行分割成离散类的方法。而回归树则是针对目标变量是连续性的变量，通过选取最优分割特征的某个值，然后数据根据大于或者小于这个值进行划分进行树分裂最终生成回归树。,在使用决策树解决回归问题中我们需要不断的选取某一特征的一个值作为分割点来生成子树。选取的标准就是使得被分割的两部分数据能有最好的纯度。,有了选取分割特征和最佳分割点的方法，树便可以依此进行分裂，但是分裂的终止条件是什么呢?,本部分使用Python实现简单的回归树，并对给定的数据进行回归并可视化回归曲线和树结构。完整代码详见: ,首先是加载数据的部分，这里的所有测试数据我均使用的《Machine Learning in Action》中的数据，格式比较规整加载方式也比较一致, 这里由于做树回归，自变量和因变量都放在同一个二维数组中:,树回归中再找到分割特征和分割值之后需要将数据进行划分以便构建子树或者叶子节点:,然后就是重要的选取最佳分割特征和分割值了，这里我们通过找打使得分割后的方差最小的分割点最为最佳分割点:,其中，停止选取的条件有两个: 一个是当分割的子数据集的大小小于一定值；一个是当选取的最佳分割点分割的数据的方差减小量小于一定的值。,是创建叶子节点的函数引用，不同的树结构此函数也是不同的，例如本部分的回归树，创建叶子节点就是根据分割后的数据集平均值，而对于模型树来说，此函数返回值是根据数据集得到的回归系数。,是计算数据集不纯度的函数，不同的树模型该函数也会不同，对于回归树，此函数计算数据集的方差来判定数据集的纯度，而对于模型树来说我们需要计算线性模型拟合程度也就是线性模型的残差平方和。,然后就是最主要的回归树的生成函数了，树结构肯定需要通过递归创建的，选不出新的分割点的时候就触底：,这里使用了现成的分段数据作为训练数据生成回归树，本文所有使用的数据详见: ,看到这种分段的数据，回归树拟合它可是最合适不过了，我们创建回归树:,通过Python字典表示的回归树结构:,这里我还是使用Graphviz来可视化回归树，类似之前决策树做分类的文章中的,函数，这里稍微修改下叶子节点的label，我们便可以递归得到决策树对应的dot文件, ,函数的实现见:,
然后获取树结构图:,生成回归树图片:,其中节点上数字代表:,有了回归树，我们便可以绘制回归树回归曲线，看看它对于分段数据是否能有较好的回归效果：,在介绍树剪枝之前先使用上一部分的代码对两组类似的数据进行回归，可视化后的数据以及回归曲线如下(,&,):,左右两边的数据的分布基本相同但是使用相同的参数得到的回归树却完全不同左边的回归树只有两个分支，而右边的分支则有很多，甚至有时候会为所有的数据点得到一个分支，这样回归树将会非常的庞大, 如下是可视化得到的两个回归树:,如果一棵树的节点过多则表明该模型可能对数据进行了“过拟合”。那么我们需要降低决策树的复杂度来避免过拟合，此过程就是,。剪枝技术又分为,和,。,预剪枝是在生成决策树之前通过改变参数然后在树生成的过程中进行的。比如在上文中我们创建回归树的函数中有个,参数，其中包含,和,，他们可以控制何时停止树的分裂，当增大叶子节点的最小数据量以及增大误差容忍度，树的分裂也会越提前的终止。当我们把误差变化容忍度增加到2000的时候得到的回归树以及回归曲线可视化如下:,预剪枝技术需要用于预先指定参数，但是后剪枝技术则是通过测试数据来自动进行剪枝不需要用户干预因此是一种更理想的剪枝技术，但是我们需要写剪枝函数来处理。,对树进行塌陷处理: 我们对一棵树进行塌陷处理，就是递归将这棵树进行合并返回这棵树的平均值。,后剪枝的Python实现:,我们看一下不对刚才的树进行预剪枝而是使用测试数据进行后剪枝的效果:,通过输出可以看到总共进行了8次剪枝操作，通过把剪枝前和剪枝后的树可视化对比下看看:,树的规模的确是减小了。,上一部分叶子节点上放的是分割后数据的平均值并以他作为满足条件的样本的预测值，本部分我们将在叶子节点上放一个线性模型来做预测。也就是指我们的树是由多个线性模型组成的，显然会比强行用平均值来建模更有优势。,模型树和回归树的思想是完全一致的，只是在生成叶子节点的方法以及计算数据误差(不纯度)的方式不同。在模型树里针对一个叶子节点我们需要使用分割到的数据进行线性回归得到线性回归系数而不是简单的计算数据的平均值。不纯度的计算也不是简单的计算数据的方差，而是计算线性模型的残差平方和。,为了能为叶子节点计算线性模型，我们还需要实现一个标准线性回归函数,, 相应模型树的,和,的Python实现,本部分使用了事先准备好的分段线性数据来构建模型树，数据点可视化如下:,现在我们使用这些数据构建一个模型树:,得到的树结构：,可视化:,绘制回归曲线:,可以通过模型树看到对于此数据只需要两个分支，数的深度也只有2层。,本部分我们使用标准线性回归和回归树分别对同一组数据进行回归，并使用同一组测试数据计算相关系数(Correlation Coefficient)对两种模型的回归效果进行对比。,数据我还是使用《Machinie Learning in Action》中的现成数据，数据可视化如下:,现在我们分别使用标准线性回归和回归树对该数据进行回归，并计算模型预测值和测试样本的相关系数,(完整代码见:,),相关系数计算:,获得的相关系数:,绘制线性回归和树回归的回归曲线(黄色会树回归曲线，红色会线性回归):,可见树回归方法在预测复杂数据的时候会比简单的线性模型更有效。,本文对决策树用于连续数值的回归预测进行了介绍，并实现了回归树, 剪枝和模型树以及相应的树结构输出可视化等。对于模型树也给予了相应的Python实现并针对分段线性数据进行了回归测试。最后并对回归树模型和简单的标准线性回归模型进行了对比。"
http://python.jobbole.com/88860/,Numpy 小结,http://jbcdn2.b0.upaiyun.com/2014/12/6da94dec8f6f96417f14c8291e6345801.png,2017-11-15,"，其中传入的参数依次为：,
如果不想看 API 可以启动一个程序用 help 查看指令的详细用法,中传入数组参数，可以是一维的也可以是二维三维的。numpy 会将其转变成 ndarray 的结构。,能够了解 array 的结构，debug 时通过查看结构能够更好地了解程序运行的过程。,一维,二维,numpy 能够依次比较 vector 和元素之间是否相同,根据返回值获取元素,进行运算之后获取,将整体类型进行转换,sum() 能够对 ndarray 进行各种求和操作，比如分别按行按列进行求和,生成从 0-14 的 15 个数字，使用 reshape(3,5) 将其构造成一个三行五列的 array。,生成指定结构的默认为 0. 的 array,生成一个三维的 array,通过 dtype 指定类型,指定范围和数值间的间隔生成 array，,生成指定结构的随机数，可以用于生成随机权重,元素之间依次相减相减,乘方,开根号,e 求方,向下取整,行列变换,变换结构,矩阵之间的运算,对应位置一次相乘,矩阵乘法,横向相加,纵向相加,矩阵分割,通过 b = a 复制 a 的值，b 与 a 指向同一地址，改变 b 同时也改变 a。,通过 a.view() 仅复制值，当对 c 值进行改变会改变 a 的对应的值，而改变 c 的 shape 不改变 a 的 shape,a.copy() 进行的完整的拷贝，产生一份完全相同的独立的复制"
http://python.jobbole.com/88799/,机器学习算法实践-岭回归和LASSO,http://pytlab.org/assets/images/blog_img/2017-10-27-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5-%E5%B2%AD%E5%9B%9E%E5%BD%92%E5%92%8CLASSO%E5%9B%9E%E5%BD%92/bias_var.png,2017-10-29,"继续线性回归的总结, 本文主要介绍两种线性回归的缩减(shrinkage)方法的基础知识: 岭回归(Ridge Regression)和LASSO(Least Absolute Shrinkage and Selection Operator)并对其进行了Python实现。同时也对一种更为简单的向前逐步回归计算回归系数的方法进行了相应的实现。,通过上一篇《,》中标准线性回归的公式w=(X^T*X)^(-1)X^T*y中可以看出在计算回归系数的时候我们需要计算矩阵X^TX的逆，但是如果该矩阵是个奇异矩阵，则无法对其进行求解。那么什么情况下该矩阵会有奇异性呢?,对于上面的两种情况，我们需要对最初的标准线性回归做一定的变化使原先无法求逆的矩阵变得非奇异，使得问题可以稳定求解。我们可以通过缩减的方式来处理这些问题例如岭回归和LASSO.,这里先介绍下数据的中心化和标准化，在回归问题和一些机器学习算法中通常要对原始数据进行中心化和标准化处理，也就是需要将数据的均值调整到0，标准差调整为1, 计算过程很简单就是将所有数据减去平均值后再除以标准差:,这样调整后的均值:,调整后的标准差:,之所以需要进行中心化其实就是个平移过程，将所有数据的中心平移到原点。而标准化则是使得所有数据的不同特征都有相同的尺度Scale, 这样在使用梯度下降法以及其他方法优化的时候不同特征参数的影响程度就会一致了。,如下图所示，可以看出得到的标准化数据在每个维度上的尺度是一致的(图片来自网络，侵删),标准最小二乘法优化问题:,也可以通过矩阵表示:,得到的回归系数为:,这个问题解存在且唯一的条件就是,列满秩:,.,即使,列满秩，但是当数据特征中存在共线性，即相关性比较大的时候，会使得标准最小二乘求解不稳定, ,的行列式接近零，计算,的时候误差会很大。这个时候我们需要在cost function上添加一个惩罚项,，称为L2正则化。,这个时候的cost function的形式就为:,通过加入此惩罚项进行优化后，限制了回归系数,的绝对值，数学上可以证明上式的等价形式如下:,其中t为某个阈值。,将岭回归系数用矩阵的形式表示:,可以看到，就是通过将,加上一个单位矩阵是的矩阵变成非奇异矩阵并可以进行求你运算。,以两个变量为例, 残差平方和可以表示为,的一个二次函数，是一个在三维空间中的抛物面，可以用等值线来表示。而限制条件,， 相当于在二维平面的一个圆。这个时候等值线与圆相切的点便是在约束条件下的最优点，如下图所示，,通过矩阵的形式计算,, 可以很简单的实现,可以知道求得的岭系数,是岭参数,的函数，不同的,得到不同的岭参数,, 因此我们可以增大,的值来得到岭回归系数的变化，以及岭参数的变化轨迹图(岭迹图), 不存在奇异性时，岭迹图应稳定的逐渐趋向于0。,通过岭迹图我们可以:,上面我们通过函数,实现了计算岭回归系数的计算，我们使用《机器学习实战》中的鲍鱼年龄的数据来进行计算并绘制不同,的岭参数变化的轨迹图。数据以及完整代码详见 ,选取30组不同的,来获取岭系数矩阵包含30个不同的岭系数。,绘制岭轨迹图,上图绘制了回归系数,与,的关系，在最左边,系数最小时，可以得到所有系数的原始值(与标准线性回归相同); 而在右边，系数全部缩减为0, 从不稳定趋于稳定；为了定量的找到最佳参数值，还需要进行交叉验证。要判断哪些变量对结果的预测最具影响力，可以观察他们的系数大小即可。,岭回归限定了所有回归系数的平方和不大于,, 在使用普通最小二乘法回归的时候当两个变量具有相关性的时候，可能会使得其中一个系数是个很大正数，另一个系数是很大的负数。通过岭回归正则项的限制，可以避免这个问题。,LASSO(The Least Absolute Shrinkage and Selection Operator)是另一种缩减方法，将回归系数收缩在一定的区域内。LASSO的主要思想是构造一个一阶惩罚函数获得一个精炼的模型, 通过最终确定一些变量的系数为0进行特征筛选。,LASSO的惩罚项为:,与岭回归的不同在于，此约束条件使用了绝对值的一阶惩罚函数代替了平方和的二阶函数。虽然只是形式稍有不同，但是得到的结果却又很大差别。在LASSO中，当,很小的时候，一些系数会随着变为0而岭回归却很难使得某个系数,缩减为0. 我们可以通过几何解释看到LASSO与岭回归之间的不同。,同样以两个变量为例，标准线性回归的cost function还是可以用二维平面的等值线表示，而约束条件则与岭回归的圆不同，LASSO的约束条件可以用方形表示，如下图:,相比圆，方形的顶点更容易与抛物面相交，顶点就意味着对应的很多系数为0，而岭回归中的圆上的任意一点都很容易与抛物面相交很难得到正好等于0的系数。这也就意味着，lasso起到了很好的筛选变量的作用。,虽然惩罚函数只是做了细微的变化，但是相比岭回归可以直接通过矩阵运算得到回归系数相比，LASSO的计算变得相对复杂。由于惩罚项中含有绝对值，此函数的导数是连续不光滑的，所以无法进行求导并使用梯度下降优化。本部分使用坐标下降发对LASSO回归系数进行计算。,坐标下降法是每次选择一个维度的参数进行一维优化，然后不断的迭代对多个维度进行更新直到函数收敛。SVM对偶问题的优化算法SMO也是类似的原理，这部分的详细介绍我在之前的一篇博客中进行了整理，参考《,》。,下面我们分别对LASSO的cost function的两部分求解：,1）RSS部分,求导:,2）正则项,关于惩罚项的求导我们需要使用subgradient，可以参考,通过上面的公式我们便可以每次选取一维进行优化并不断跌打得到最优回归系数。,根据上面代码我们实现梯度下降法并使用其获取LASSO回归系数。,我们选取,, 收敛阈值为0.1来获取回归系数,迭代了150步收敛到0.1，计算相对比较耗时:,类似岭轨迹，我们也可以改变,的值得到不同的回归系数，通过作图可以看到回归系数的轨迹,得到的轨迹图如下:,通过与岭轨迹图进行对比发现，随着,的增大，系数逐渐趋近于0，但是岭回归没有系数真正为0，而lasso中不断有系数变为0.,LASSO计算复杂度相对较高，本部分稍微介绍一下逐步向前回归，他属于一种贪心算法，给定初始系数向量，然后不断迭代遍历每个系数，增加或减小一个很小的数，看看代价函数是否变小，如果变小就保留，如果变大就舍弃，然后不断迭代直到回归系数达到稳定。,下面给出实现,我们去变化量为0.005，迭代步数为1000次，得到回归系数随着迭代次数的变化曲线:,逐步回归算法的主要有点在于他可以帮助人们理解现有的模型并作出改进。当构建了一个模型后，可以运行逐步回归算法找出重要的特征，即使停止那些不重要特征的收集。,本文介绍了两种回归中的缩减方法，岭回归和LASSO。两种回归均是在标准线性回归的基础上加上正则项来减小模型的方差。这里其实便涉及到了权衡偏差(Bias)和方差(Variance)的问题。方差针对的是模型之间的差异，即不同的训练数据得到模型的区别越大说明模型的方差越大。而偏差指的是模型预测值与样本数据之间的差异。所以为了在过拟合和欠拟合之前进行权衡，我们需要确定适当的模型复杂度来使得总误差最小。"
http://python.jobbole.com/88858/,三生万物：决策树,http://img.blog.csdn.net/20171111215334992,2017-11-16,"不知怎么回事，提到决策树我就想起”道生一，一生二，二生三，三生万物“这句话，大概是因为决策树从一个根节点慢慢“长”成一棵树，也要经历“一生二，二生三”的过程。决策树本质上就是一种二叉树，根据特定的标准不停的分成左右两个子树，直到符合某种条件停止。树算法解释性强、简单直观以及接近人的决策方式使它成为流行的机器学习算法之一。当决策树与装袋法(Bag)、提升法(Boosting)结合之后，可以成为更强大的算法。,决策树按响应值的类型大致分为分类树和回归树，实现决策树的方法也很多，比如CART、ID3、C4.5等等，本文将对CART这种算法进行介绍。,一棵树要长成要解决两方面的问题，一是如何分，二是何时停。这两点对于分类和回归略有区别，先说如何分，对于定量变量一般是将小于某个值的数据划分为左子树，大于等于某个值的划分为右子树；对于定性变量一般是将等于某个值的划分为左子树，不等于某个值的划分为右子树。那么什么才是一个好的划分呢？分类树大致分为两种，一种是按,，纯度是通过,进行定义的，基尼系数越小，纯度越大，那么划分效果越好。基尼系数的计算方法如下式所示：, ,代表第,类所占比例，当,接近0或1时，基尼系数会很小。,另一种标准是,，互熵的定义如下：, ,由定义可以看到，和基尼系数类似，当,接近0或1时，互熵也很小，划分的效果也越好。,回归树则根据残差平方和RSS：, ,代表平均响应值，可以看到这实际上就是方差，我们都知道方差是衡量数据变异性的量，因此RSS越小表示回归模型效果越好。,注意上面的纯度、互熵以及残差平方和均是树的一个分枝上的值，总的值要对左右分枝进行加权平均，例如基尼系数的最终值应该这样计算，, ,表示总的样本数，,，,分别代表左分枝和右分枝的样本数，互熵和残差平方和的计算方式类似。,说了如何分，那什么时候停呢？一般的惯例是子树中的预测变量或响应值都一样了就可以停止分裂了。有时候这个条件可能有些苛刻，这时候可以设置一个Node Size值，表示叶子节点包含的最小的样本数。分裂过程中如果一个子树的样本数小于等于这个值就停止分裂，分类数取数目最多的那个类，回归树取响应的均值。,说了这么多，下面举个例子，来演示下决策树算法，比如这里有一份城市和农村儿童身高数据，注意这里的数据都是我杜撰的，只是为了演示决策树的算法。如果已知一个儿童身高和性别，如何判断所处的区域？,下面尝试根据基尼系数来构造一个分类树，,
第一次分裂：,身高,身高,身高,性别=男：2/4 x (1/2 x 1/2 + 1/2 x 1/2) + 2/4 x (1/2 x 1/2 + 1/2 x 1/2) = 1/2,性别=女：2/4 x (1/2 x 1/2 + 1/2 x 1/2) + 2/4 x (1/2 x 1/2 + 1/2 x 1/2) = 1/2,可以看到前面两个都是1/3，选择哪一个都行，这里我选择第一个最小值：“身高 左子树,右子树,第二次分裂：,由于右面的子树只有一条数据，因此只需计算左边子树的基尼系数，,身高,身高,性别=女：2/3 x (1/2 x 1/2 + 1/2 x 1/2) + 1/3 x (1 x 0) = 1/3,性别=男：1/3 x (1 x 0) + 2/3 x (1/2 x 1/2 + 1/2 x 1/2) = 1/3,同上选择第一个最低值“身高 左子树,右子树,第三次分裂：,同理，左边子树只有一条数据，只需计算右子树,身高,性别=女：1/2 x (1 x 0) + 1/2 x (1 x 0) = 0,性别=男：1/2 x (1 x 0) + 1/2 x (1 x 0) = 0,选择“性别=女”这个条件，至此所有的子树的响应值都是唯一的，停止分裂。,最终这个分类树的样子大概如下，,其实树的剪枝就是正则化，剪枝一般分为两种：一种称为预剪枝，通过设置Node Size的大小来达到控制树的分枝个数的目的，这种方式简单易用，但有短视的风险；另一种称为后剪枝，原理是让树充分“生长”，然后尝试合并树的分枝，通过对比合并前后错误率是否降低来决定是否真得合并，这种方式效果较前一种好，但是实现稍微复杂一些。,俗话说，光说不练假把式，下面我用R语言实现一个决策树，并尝试分析两个实际的数据集。,1、,数据集，这个数据集包括五个变量：花萼长度(Sepal.Length)，花萼宽度(Sepal.Width)，花瓣长度(Petal.Length)，花瓣宽度(Petal.Width)，种类(Species)，下面尝试使用花萼长度(Sepal.Length)和花萼宽度(Sepal.Width)这两个变量来预测鸢尾花的种类(Species)。,为了简便，我采用的是预剪枝的方式。那么选择多大的Node Size合适呢？关于这个问题通常的方法就是,。下图是采用10折交叉验证(k-fold cross-validation)得到的错误率,,可以看到，当Node Size为40的时候测试集的错误率Eout最低，从另一个方面也可以看到如果不进行剪枝，Eout约为0.4，比剪枝后的错误率高了将近0.2。从下面的第一张图也可以直观的看到当Node Size从小到大增加时，分类边界(Decision Boundary)从过拟合(Overfit)到欠拟合(Underfit)的变化趋势。第二张图是根据交叉验证得到的最佳分类边界，它和Node Size为30的分类边界非常相似。,最终的错误率约为0.2，从上面第二张图可以看到versicolor和virginica这两类的鸢尾花有些数据在二维空间完全重合在了一起，仅仅依靠花萼长度(Sepal.Length)，花萼宽度(Sepal.Width)这两个变量是无法把它们分开的，这个时候单纯的增加样本数无法进一步提高模型的质量，这个时候最好去寻找新的变量，事实上，当加上花瓣长度(Petal.Length)，花瓣宽度(Petal.Width)这两个变量时，预测的错误率可以降低到0.06左右。,树的样子如下，,[L]和[R]分别代表左右分枝。,2、上面是个分类问题，那么再看一个回归问题。,这个数据集有13个特征，下面使用决策树根据房子的区域(area)、是否学区(school)、是否有地铁(subway)、总价(num)这四个变量来预测房价(price)。,同样，祭出我们的法宝交叉验证得到一个合适的Node Size，如下所示，,对于回归,我采用了,作为衡量模型效果的标准，由于R2是越大越好，且0,得到的决策系数R2约为0.7，也就是区域、是否学区、是否有地铁、总价这四个变量解释了70%房价变异。由这个相对误差图可以看出大部分的数据都落在了0附近，实际上有20275条数据落在[-0.2,0.2]，28379条数据落在[-0.5,0.5]。那么，那些误差比较大的都是些什么数据呢？,感觉这些数据好像异常数据，北京还有低于1万的房价？！,当一个小小的种子慢慢成长为一颗参天大树，独霸森林一方，常常让人感受生命的强大，而决策树算法同样让人惊叹，易于实现又足够灵活，既能用于分类又能用于回归，也在机器学习领域赢得了一席之地。本文简单介绍了决策树的算法和剪枝，在此基础上用R实现了一个决策树，并在两个数据集上进行了测验，证实了决策树的能力。"
http://python.jobbole.com/88862/,Jupyter 常见可视化框架选择,http://jbcdn2.b0.upaiyun.com/2017/11/cf07224a24a4f2e382a74152a82bbce6.png,2017-11-15,"对于以Python作为技术栈的数据科学工作者，,是不得不提的数据报告工具。可能对于R社区而言，鼎鼎大名的,是常见的可视化框架，而大家对于Python，以及,为核心的交互式报告的可个视化方案就并没有那么熟悉。本文试图比较几个常用的解决方案，方便大家选择。,数据工作者使用的图的类别，常见的就三类：GIS可视化、网络可视化和统计图。因此，大多数场景下，我们并不想接触非常底层的基于点、线、面的命令，所以，选择一个好的封装的框架相当重要。,当然，公认较好的封装是基于,一书，R中的,基本上就是一个很好的实现。我们基本上可以像用「自然语言」（Natural Language）一样使用这些绘图命令。我们姑且采用计算机科学领域的「陈述式」来表达这种绘图方式。,相反，有时候，以下情形时，我们可能对于这种绘图命令可能并不在意：,这些情况下，显然，简单操作式并提供底层绘制命令的框架更让人愉快，与上面类似，我们借用「命令式」描述这类框架。,与传统的交付静态图标不同，基于Web端的,的一大好处就是可以绘制交互的图标（最近的,也有实现），因此，是否选择交互式，也是一个需要权衡的地方。,交互图的优势：,非交互图的优势：,上大多数命令通过以下方式获取数据，而大多数绘图方式事实上只是通过Notebook内的代码在Notebook与内核交互后展示出输出结果。但,框架则可以实现Code Cell中的代码与Notebook中的前端控件（比如按钮等）绑定来进行操作内核，提供不同的绘图结果，甚至某些绘图框架的每个元素都可以直接和内核进行交互。, ,用这些框架，可以搭建更复杂的Notebook的可视化应用，但缺点是因为基于内核，所以在呈递、展示报告时如果使用离线文件时，这些交互就会无效。,最家喻户晓的绘图框架是,，它提供了几乎所有python内静态绘图框架的底层命令。如果按照上面对可视化框架的分法，,属于非交互式的的「命令式」作图框架。,优点是相对较快，底层操作较多。缺点是语言繁琐，内置默认风格不够美观。,值得一说，对于R迁移过来的人来说，,和,简直是福音，基本克隆了,所有语法。,。这两个绘图包的底层依旧是,，因此，在引用时别忘了使用,语句。值得一说的是,也移植了,中良好的配置语法和逻辑。,准确上说属于,的扩展包，在其上做了许多非常有用的封装，基本上可以满足大部分统计作图的需求，以,+,基本可以满足大部分业务场景，语法也更加「陈述式」。,缺点是封装较高，基本上API不提供的图就完全不可绘制，对于各类图的拼合也不适合；此外配置语句语法又回归「命令式」，相对复杂且不一致。,是跨平台JavaScript交互式绘图包，由于开发者的核心是javascript，所以整个语法类似于写json配置，语法特质也介于「陈述式」和「命令式」之间，无服务版本是免费的。,有点是学习成本不高，可以很快将语句移植到javascript版本；缺点是语言相对繁琐。,注意：此框架在jupyter中使用需要使用init_notebook_mode()加载JavaScript框架。,是,维护的比较具有潜力的开源交互可视化框架。,值得一说的是，该框架同时提供底层语句和「陈述式」绘图命令。相对来说语法也比较清楚，但其配置语句依旧有很多可视化框架的问题，就是与「陈述式」命令不符，没有合理的结构。此外，一些常见的交互效果都是以底层命令的方式使用的，因此如果要快速实现Dashboard或者作图时就显得较为不便了。,是基于,和,组合发展的内核交互式的可视化框架。语法上采用了和,大致一致的语法已经相对封装较高的「陈述式语法」。优点是直接和内核交互，可以使用大量控件来实现更多的图像处理，缺点也是直接的，离线文档则不会显示任何图案、控件也都失效。,除了统计作图，网络可视化和GIS可视化也是很常用的，在此只做一个简单的罗列：,GIS类：,网络类："
http://python.jobbole.com/88874/,Python NLP入门教程,http://jbcdn2.b0.upaiyun.com/2017/11/eefc6b90a73fee96a70b63f207f9a302.png,2017-11-19,"本文简要介绍Python自然语言处理(NLP)，使用Python的NLTK库。NLTK是Python的自然语言处理工具包，在NLP领域中，最常使用的一个Python库。,简单来说，自然语言处理(NLP)就是开发能够理解人类语言的应用程序或服务。,这里讨论一些自然语言处理(NLP)的实际应用例子，如语音识别、语音翻译、理解完整的句子、理解匹配词的同义词，以及生成语法正确完整句子和段落。,这并不是NLP能做的所有事情。,: 比如谷歌，Yahoo等。谷歌搜索引擎知道你是一个技术人员，所以它显示与技术相关的结果；,:比如Facebook News Feed。如果News Feed算法知道你的兴趣是自然语言处理，就会显示相关的广告和帖子。,:比如Apple的Siri。,:如谷歌垃圾邮件过滤器。和普通垃圾邮件过滤不同，它通过了解邮件内容里面的的深层意义，来判断是不是垃圾邮件。,下面是一些开源的自然语言处理库(NLP)：,其中自然语言工具包(NLTK)是最受欢迎的自然语言处理库(NLP)，它是用Python编写的，而且背后有非常强大的社区支持。,NLTK也很容易上手，实际上，它是最简单的自然语言处理(NLP)库。,在这个NLP教程中，我们将使用Python NLTK库。,如果您使用的是Windows/Linux/Mac，您可以使用pip安装NLTK:,打开python终端导入NLTK检查NLTK是否正确安装：,如果一切顺利，这意味着您已经成功地安装了NLTK库。首次安装了NLTK，需要通过运行以下代码来安装NLTK扩展包:,这将弹出NLTK 下载窗口来选择需要安装哪些包:,您可以安装所有的包，因为它们的大小都很小，所以没有什么问题。,首先，我们将抓取一个web页面内容，然后分析文本了解页面的内容。,我们将使用urllib模块来抓取web页面:,从打印结果中可以看到，结果包含许多需要清理的HTML标签。,
然后BeautifulSoup模块来清洗这样的文字:,现在我们从抓取的网页中得到了一个干净的文本。,
下一步，将文本转换为tokens,像这样:,text已经处理完毕了，现在使用Python NLTK统计token的频率分布。,可以通过调用NLTK中的,方法实现:,如果搜索输出结果，可以发现最常见的token是PHP。,
您可以调用,函数做出频率分布图:,这上面这些单词。比如,,,,,等等，这些词都属于停用词。,一般来说，停用词应该删除，防止它们影响分析结果。,NLTK自带了许多种语言的停用词列表，如果你获取英文停用词:,现在，修改下代码,在绘图之前清除一些无效的token:,最终的代码应该是这样的:,现在再做一次词频统计图，效果会比之前好些，因为剔除了停用词:,在之前我们用,方法将文本分割成tokens，现在我们使用NLTK来Tokenize文本。,文本没有Tokenize之前是无法处理的，所以对文本进行Tokenize非常重要的。token化过程意味着将大的部件分割为小部件。,你可以将段落tokenize成句子，将句子tokenize成单个词，NLTK分别提供了句子tokenizer和单词tokenizer。,假如有这样这段文本:,使用句子tokenizer将文本tokenize成句子:,输出如下:,这是你可能会想，这也太简单了，不需要使用NLTK的tokenizer都可以，直接使用正则表达式来拆分句子就行，因为每个句子都有标点和空格。,那么再来看下面的文本:,这样如果使用标点符号拆分,,将会被认为是一个句子，如果使用NLTK:,输出如下:,这才是正确的拆分。,接下来试试单词tokenizer:,输出如下:,这个词也没有被分开。NLTK使用的是punkt模块的PunktSentenceTokenizer，它是NLTK.tokenize的一部分。而且这个tokenizer经过训练，可以适用于多种语言。,Tokenize时可以指定语言:,输出结果如下:,使用,安装界面，其中一个包是WordNet。,WordNet是一个为自然语言处理而建立的数据库。它包括一些同义词组和一些简短的定义。,您可以这样获取某个给定单词的定义和示例:,输出结果是:,WordNet包含了很多定义：,结果如下:,可以像这样使用WordNet来获取同义词:,输出:,也可以用同样的方法得到反义词：,输出:,语言形态学和信息检索里，词干提取是去除词缀得到词根的过程，例如working的词干为work。,搜索引擎在索引页面时就会使用这种技术，所以很多人为相同的单词写出不同的版本。,有很多种算法可以避免这种情况，最常见的是,。NLTK有一个名为PorterStemmer的类，就是这个算法的实现:,输出结果是:,还有其他的一些词干提取算法，比如 ,。,除了英文之外，SnowballStemmer还支持13种语言。,支持的语言:,你可以使用,类的,函数来提取像这样的非英文单词：,单词变体还原类似于词干，但不同的是，变体还原的结果是一个真实的单词。不同于词干，当你试图提取某些词时，它会产生类似的词:,结果:,现在，如果用NLTK的WordNet来对同一个单词进行变体还原，才是正确的结果:,结果:,结果可能会是一个同义词或同一个意思的不同单词。,有时候将一个单词做变体还原时，总是得到相同的词。,这是因为语言的默认部分是名词。要得到动词，可以这样指定：,结果:,实际上，这也是一种很好的文本压缩方式，最终得到文本只有原先的50%到60%。,结果还可以是动词(v)、名词(n)、形容词(a)或副词(r)：,输出:,通过下面例子来观察:,输出:,词干提取不会考虑语境，这也是为什么词干提取比变体还原快且准确度低的原因。,个人认为，变体还原比词干提取更好。单词变体还原返回一个真实的单词，即使它不是同一个单词，也是同义词，但至少它是一个真实存在的单词。,如果你只关心速度，不在意准确度，这时你可以选用词干提取。,在此NLP教程中讨论的所有步骤都只是文本预处理。在以后的文章中，将会使用Python NLTK来实现文本分析。,我已经尽量使文章通俗易懂。希望能对你有所帮助。"
http://python.jobbole.com/88726/,Python数据分析 - Numpy,http://jbcdn2.b0.upaiyun.com/2015/02/edecceebedd0d04aa17bccba430ddcaf.jpg,2017-10-21,"NUMPY（以下简称NP）是Python数据分析必不可少的第三方库，np的出现一定程度上解决了Python运算性能不佳的问题，同时提供了更加精确的数据类型。如今，np被Python其它科学计算包作为基础包，已成为Python 数据分析的基础，可以说，NP是SciPy、Pandas等数据处理或科学计算库最基本的函数功能库。因此，理解np的数据类型对python数据分析十分有帮助。,下面，本文将介绍Np的常用操作和基本数据类型。,NP提供了以下重点功能。,为了更加直观的了解Np的强大与作用，我们先看作用再看方法：,在操作数据之前，我们先来理解什么是维度：,维度是一组数据的组织形式，不同数据维度可能表示不同的含义。一维数据由对等关系的有序或无序数据构成，采用线性方式组织，可以用数组表示。,通俗来讲，,这么一行数据就可以称之为一维数据，但如果我们再对其折叠：,那么他就成为了二维数据，又可以称之为矩阵。,数据集，顾名思义就是数据的集合，是用以训练程序的数据集合，一般是二维或者多维数表。,如果我们想自己手工新建一个数据集，可以直接新建一个文本文件，只要有恰当的数据，都可以称之为数据集：,比如这样，我们就可以称上面的文件称之为数据集。我们还注意到，上面数据是使用逗号作为分隔符分隔数据的，它简单描述了数据的内容和含义，并使用半角逗号作为分隔符。像这样，用逗号分隔的数据集就称之为CSV（Comma-Separated Value,逗号分隔值）数据集，它是一种常见的文件格式，用来存储批量的数据。它就像一张excel表，用来存储简单结构的数据。,怎么样，数据集的概念是否特别简单呢？,数据集是一个简单的概念，但每次使用手工的方式去写毕竟不方便，所以，我们可以使用np的内置函数来生成数据集：,我们可以这样写下代码：,这样，我们就会在当前的工作目录下发现一个新的demo.csv，用记事本打开，里面是一个4 * 5的矩阵，元素0~19。,既然生成，那就可以读取，同样使用np：,同样的我们只需要写下代码：,就可以查看到我们先前写入的数组a。,可以发现，CSV文件只能有效存储和读取一维和二维数组，因为更高的维度无法更直观的文本下显现出来，这时，更加灵活的存取方式就呼之欲出了，但讲之前先卖个关子，再介绍一个不太常用的方法：,tofile：对于NP中的ndarray数组，我们可以使用NP中的tofile方法。,同样，我们只需要命令：,就可以生成新的CSV数据集。,此时，我们如果打开a.dat文件，我们可以看到数组1,2,3……99。但是与CSV不同，这个文件并没有包含数字的维度信息，他只是将数组所有元素逐一的列出。而且如果我们不指定sep，将保存为二进制文件，虽然对人不可读，但将占用更小的空间。,既然tofile可以保存文本文件，那么也很容易猜到对应的fromfile可以还原这些信息。,如果我们想要重新恢复数据的维度信息，我们需要重新使用reshape来恢复维度信息：,因此，为了保存更复杂的数据类型，二维以上的数据信息，save / load 函数成功解决了这个问题：（为了方便，两个函数就放到一起了）,Demo:,附录中提供NP的常用方法及注释，做查询用。,如果想要多个随机整数：,还可以使用reshape函数，对数组结构重定义：,下面介绍一些常用的运算操作：,此外，还可以sqrt、log、sin、sum、max等操作：,
我们下定义一个三维数组：,我们可以看到sum方法对lst的所有元素都进行了求和，此外我们还可以通过对sum方法增加参数axis的方式来设置求和的深入维度：,这里的axis取值为数组维数-1，axis可以理解为进行运算操作时的深入程度，axis越大，深入程度越大。同理，不仅sum函数，max等函数也可以一样理解。,numpy.array是np最简单的数据结构。np.array相比与Python原生列表其强大之处在于可以实现对数组数据的运算。我们知道，list只能对元素的追加。而numpy是真正意义上的数据运算。,例如,但np最强大的地方不在于简单的一维运算，Np对矩阵也能进行基本的运算操作：,此外，由于原生list没有确定的数据类型，所以维护起来成本较高，而使用C编写的numpy，则可以声明各种常见的数据类型：,np所支持的数据类型都有bool、int8/16/32/64/128/、uint8/16/32/64/128、float16/32/43、complex64/128、string。,Python作为一门弱类型语言，有其不可避免的缺点。但NP的出现，弥补了这些缺点，使其具备了构造复杂数据类型的能力，为Python数据分析提供了基础。"
http://python.jobbole.com/88729/,Python Re模块,http://jbcdn2.b0.upaiyun.com/2014/12/6da94dec8f6f96417f14c8291e6345801.png,2017-10-23,"等价于,上面的函数返回都可以在if条件语句中进行判断：,上面的函数中，只有match、search有group方法，其他的函数没有。,（ ,）,（ ,）,(?:…) (…)不分组版本,用于使用 | 或者后接数量词,
(?iLmsux) iLmsux的每个字符代表一个匹配模式,只能用在正则表达式的开头,可选多个,
(?#…) #号后的内容将作为注释,
(?=…) 之后的字符串内容需要匹配表达式才能成功匹配,
(?!…) 之后的字符串不匹配表达式才能成功,
(?(?(?(id/name) yes |no) 如果编号为id/名字为name的组匹配到字符串,则需要匹配yes,否则匹配no,no可以省略"
http://python.jobbole.com/88747/,机器学习算法实践-标准与局部加权线性回归,http://pytlab.org/assets/images/blog_img/2017-10-24-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5-%E6%A0%87%E5%87%86%E4%B8%8E%E5%B1%80%E9%83%A8%E5%8A%A0%E6%9D%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/lwlr_k01.png,2017-10-25,"最近开始总结学习回归相关的东东了，与分类的目标变量是标称型不同，回归是对连续型数据进预测。当然还是从最简单的线性回归开始，本文主要介绍无偏差的标准线性回归和有偏局部加权线性回归的理论基础以及相应的Python实现。,标准线性回归的理论知识很简单，我们既可以写出它的标量表达式也可以写成矩阵的形式，其中矩阵的形式也可以通过投影矩阵进行推到得到。本部分就对标准线性回归的表达式进行下简单的推导。,给定一组数据其中包括特征矩阵,, 目标变量向量,:,其中,第一列为截距项，我们做线性回归是为了得到一个最优回归系数向量,使得当我们给定一个,能够通过,预测,的值。其中,那么怎样的,才是最优的呢？在标准线性回归中我们需要找到是误差最小的,, 即预测的,值与真实的,值之间的差值，为了避免简单累加造成的正负差值相互抵消，这里采用了平方误差:,对于上述式子,可以通过梯度下降等方法得到最优解。但是使用矩阵表示将会是的求解和程序更为简单:,将,对,求导可得:,使其等于0，便可得到:,除了通过最小平方差的方法推导得到,的表达式，我们还可以通过投影矩阵(Projection Matrix)来得到。,我们知道如果我们能够求得一个,使得,肯定是最好的，但是实际情况中,一般并不在矩阵,的列空间中，也就是此方程无解，于是我们希望通过将向量,投影到,的列空间中得到投影矩阵,, 然后求解,来获取一个最接近的一个解, 矩阵,的投影矩阵形式为,于是得到,在,列空间的投影为,此时方程,是有解的，得到最接近,的解为:,通过矩阵形式我么可以很方便的通过Numpy的接口进行矩阵运算获取线性回归系数向量,, 实现如下:,通过对现有数据进行标准线性回归并绘制回归直线得到如下图(完整代码和数据见: ,),如何判断获得的模型预测能力的好坏呢？我们需要计算模型计算得到的,的值向量与实际,值向量的匹配程度, 也就是计算相关系数Correlation Coefficient。,相关系数的计算公式:,也就是两个数据序列的协方差并除上各自的标准差，本质上就是一种剔除了两个变量量纲影响、标准化后的特殊协方差。,而协方差便是衡量两个变量变化趋势是否相似的一种方法，是同向变化(同时变大或变小)还是反向变化(一个变大一个变小), 同向或者反向的程度如何，计算公式如下:,通过公式可以看出，如果对于向量中的每个,同时大于或同时小于各自的期望值，协方差为正，相反则为负。可见如果协方差越大相似程度就越高，协方差越小相似程度就越小。也可以看到如果,相同，协方差就是方差，也就是方差是一种特殊情况下的协方差。,关于协方差与相关系数的通俗解释可以参考知乎上的回答:,虽然Numpy中有计算协方差的接口,，是分别对两两向量进行比较并计算协方差，得到协方差矩阵。为了练习，我还是稍微自己计算了下协方差并只计算两列不同数据之间的相关系数:,通过对上面得到的线性回归模型得到的预测的值与实际的值进行相关系数计算可以得到相关系数为,上面的数据点是通过公式,添加噪声生成的数据，而标准的线性回归是一种无偏差估计，在计算所有点的时候都是无偏差的计算误差并通过优化方法优化误差，如果针对不同的点能够对误差进行调整便可以一定程度上避免标准线性回归带来的欠拟合现象。,也就是引入偏差来降低预测的均方误差，本部分总结下局部加权线性回归的方法。当我们获取某个,的预测值的时候，我们需要计算回归系数,，但是如果针对样本中的数据，距离,越近我们就给个越大的权重，如果距离越远就给一个小的权重，这样就会使得针对,的预测值,能够更贴合样本数据。,当我们需要对数据点,相应的目标值进行预测的时候，我们需要给样本中的每个点赋予一个权重值,为了区分权重和回归系数，在这里用,表示回归系数，,表示权重), 那么平方误差的表达式就变成:,通过矩阵可以表示成:,对,求导等于0得到:,通过上面的公式，对于任意给定的未知数据可以计算出对应的回归系数,，并得到相应的预测值,, 其中,是一个对角矩阵，对角线上的元素,对应样本点,的权重值。,那么权重的表达式又是怎样的呢，我们需要距离给定,的样本点的权重越高，LWRL使用核来对附近的点赋予更高的权重，最常用的是高斯核函数，对应表达式如下:,本文总结了标准线性回归以及局部加权线性回归的基础知识，并对两张回归方式给与了Python的实现。可见局部加权线性回归在取得适当的,，便可以较好的发现数据的内在潜质，但是局部加权线性回归有个缺点就是类似kNN一样，每计算一个点的预测值就需要利用所有数据样本进行计算，如果数据量很大，计算量会是一个问题。"
http://python.jobbole.com/88765/,Python 静态方法和类方法的区别,http://jbcdn2.b0.upaiyun.com/2015/02/24004ba5c7c6660ad259e346b2d86114.png,2017-10-25,"尽管 classmethod 和 staticmethod 非常相似，但在用法上依然有一些明显的区别。classmethod 必须有一个指向 , 的引用作为第一个参数，而 staticmethod 可以没有任何参数。,让我们看几个例子。,很明显，这个类的对象可以存储日期信息（不包括时区，假设他们都存储在 UTC）。,这里的 , 方法用于初始化对象的属性，它的第一个参数一定是 self，用于指向已经创建好的对象。,利用 classmethod 可以做一些很棒的东西。,比如我们可以支持从特定格式的日期字符串来创建对象，它的格式是 (‘dd-mm-yyyy’)。很明显，我们只能在其他地方而不是 , 方法里实现这个功能。,大概步骤：,代码如下,理想的情况是 Date 类本身可以具备处理字符串时间的能力，解决了重用性问题，比如添加一个额外的方法。,C++ 可以方便的使用重载来解决这个问题，但是 python 不具备类似的特性。 所以接下来我们要使用 classmethod 来帮我们实现。,让我们在仔细的分析下上面的实现，看看它的好处。,我们在一个方法中实现了功能，因此它是可重用的。 这里的封装处理的不错（如果你发现还可以在代码的任意地方添加一个不属于 Date 的函数来实现类似的功能，那很显然上面的办法更符合 OOP 规范）。 , 是一个保存了 , 的对象（所有的一切都是对象）。 更妙的是， Date 类的衍生类都会具有 from_string 这个有用的方法。,staticmethod 没有任何必选参数，而 classmethod 第一个参数永远是 cls， instancemethod 第一个参数永远是 self。,所以，从静态方法的使用中可以看出，我们不会访问到 class 本身 – 它基本上只是一个函数，在语法上就像一个方法一样，但是没有访问对象和它的内部（字段和其他方法），相反 classmethod 会访问 cls， instancemethod 会访问 self。"
http://python.jobbole.com/88772/,Python 和 SQL Server 2017 的强大功能,http://jbcdn2.b0.upaiyun.com/2017/10/c35705911d053af37a78aff1f5b5d980.jpg,2017-10-28,"MS SQL Server 2017已经通过启用SQL服务器通过“使用Python的机器学习服务”在TSQL中执行Python脚本，添加到其高级分析扩展，现在称为“机器学习服务”。这基本上提供了一种数据库程序员可以直接从Python传递数据的方法。这样做的有用性不仅限于为数据分析提供机器学习功能，因为Python具有许多易于使用的模块和框架来解决许多问题，例如使用数据结构执行大量计算工作，用于分析的图形处理，网络操作，数据库操作，网络操作或基于本地/网络的文件系统操作。显然，其中许多在中间件方面做得最好，但是在数据库系统中，有时候直接与外部系统通信，而不是依靠外部进程通过轮询数据源来执行任务更方便。如果在数据库或数据层中有一个这样的解决方案，并且不提供任何安全性问题时，这不是问题。,在这里，我们将尝试演示在Advanced Analytics Extension中使用Python的示例，显示数据库如何触发外部进程来对作为参数提供的数据执行活动。这是为了考虑安全性，数据可靠性和事务响应时间的问题。,通过从SQL调用Python脚本而不是依赖于中间件，可以更容易地完成某些任务。特别是在数据库中事件发起任务的情况下。任务可能包括,当然也难免存在一些潜在的缺点,衡量这些优点和缺点，似乎有时候Python可以发挥有用的作用，如果可以最小化风险。作为一个例子，让我们考虑一下我们如何使用Python构建数据缓存系统供应用层使用。,缓存数据可以提高应用程序的性能。以缓存的存储开销为代价，当遇到与数据库的聊天网络通信以及数据库面临重复查询时资源消耗高的情况下，我们可以获得有用的性能提升。当我们构建缓存基础架构时，我们面临着什么时候刷新缓存的内容的常见问题。我们倾向于在一定时间间隔之后采用重建缓存的简单解决方案。然而，这是非常低效的。当数据更改时刷新缓存更好，只刷新改变的内容。在创建，更新或删除数据时，我们可以实时接近实时。有许多工具和框架可用于解决刷新问题，但是它们受到如何确定数据发生变化以及何时发生更改的问题。数据库是最好的所有能够做到这一点。,对于我们这里提供的,，我们将把自己限制在微软堆栈中，以防止Python本身。,以下是我们的示例解决方案缓存系统的图示：,在我们的解决方案中，我们将在RESTful.Cache应用程序中缓存实体“产品类型名称”，并且WebApplication将具有创建新产品类型条目并从RESTful.Cache读取的功能。,除此之外，还有一些先决条件和一些我们需要考虑的信息。,RECONFIGURE;,WebApplication有两个主要的MVC动作; 一个使用HTTP动词POST更新TransDB中的一个新实体，另一个使用HTTP动词GET从缓存返回产品类型列表的操作。,RESTful.Cache有两种操作方法，一种是使用HTTP动词POST更新新添加的实体产品类型的缓存，另一种用于从本地缓存获取所有缓存的产品类型。,对于我们的示例解决方案，这两个应用程序都在IIS中托管在各个应用程序池标识下，以保护应用程序安全 但是对于实际的系统实现，托管环境可以是内部网或互联网环境中的单个Web服务器。,RESTful.Cache授权规则只有两个服务帐户来处理HTTP请求，即,abc WebApp_SVC和abc CacherAgent_SVC。 abc CacherAgent_SVC服务帐户允许SQL中的Python脚本通过HTTP到达应用程序来刷新缓存。,abc WebApp_SVC用户用于具有授权规则模式的WebApplication，以允许访问RESTful.Cache应用程序。,OLTP数据库TransDB有几个对象，包括表，存储过程和Service Broker对象。,CacheIntegrationError表。,有关Service Broker的更多信息，请访问,对于我们的示例解决方案，TransDB是创建新的ProductType记录时创建更新缓存消息的源数据库，执行操作的消息，它具有UpdateMessage消息类型，CacheIntegration合同将CacheSource服务发送到目标数据库。该服务具有CacheQueue，由Service Broker组件用于执行可靠的消息传递。 ToCacheTarget路由具有将消息传递到其目标的信息。,为了消除任何增加事务处理时间的机会以及避免事务数据库中其余数据的任何安全风险，我们将通过使用我们的示例解决方案中名为Cacher数据库的代理数据库来解除缓存更新过程。 Service Broker消息传递基础设施将有助于连接TransDB和Cacher数据库，基于事件的消息处理将使我们能够更新驻留在基于网络的系统上的缓存存储。 Cacher数据库正在扮演代理角色，以便在更新消息到达时执行缓存刷新。它通过执行Python脚本更新缓存。,Cacher数据库具有：,Cacher的Service Broker对象，主要是UpdateMessage消息类型和CacheIntegration契约与TransDB的相同，CacheQueue有一个称为PerfomCacheUpdate的激活过程，一个名为CacheTarget的服务，该路由具有有关TransDB服务CacheService和端点地址的信息。,对于我们的示例解决方案，数据库队列的最大队列读取器设置为1。 如果需要，可以增加这一点，例如，如果数据修改很高，并且您需要增加缓存刷新率。,对于我们的解决方案，数据库托管在同一个实例上，因此两者都使用相同的Service Broker Endpoint来发送和接收消息。,但是，如果我们要在单个实例上托管数据库，那么每个SQL实例的服务帐户都应该有一个Service Broker端点。 并且这两个SQL实例都应该有权限允许将消息发送到对方的端点。 连接的授权和授予可以通过以下TSQL命令集完成。 请注意，在消息传递基础结构中，有一个发送方，另一方是接收方，正如所提到的，如果SQL实例是发送方和接收方的一部分，则每个实例都应该有自己的进程标识。 下图显示了每个SQL Server在其自身身份下运行的方式。,这是用于在Cacher数据库的SQL实例中授权和授予端点连接到TransDB的SQL实例服务帐户[identity]的SQL代码。,同样，这里是用于授权和授予端点连接到Cache SQL数据库SQL实例服务帐户[identity]的代码。,这是Python脚本文本，在TSQL变量@UpdateCache中保存为字符串。 它具有具有逻辑的UpdateCache方法，通过传递具有作为输入参数接收的Name和Id字段的数据对象来对RESTful.Cache执行HTTP POST调用。 它接收一个JSON对象，并将其作为方法的输出结果返回给调用者。,在脚本结束时，返回的对象被转换为数组，因此可以将其结构化为SQL结果。,在SQL Server中使用Python脚本时，有一些值得注意的事情。,TransDB是一个OLTP数据库，我们不希望对系统发生任何安全漏洞，因此，通过我们的示例解决方案，这种数据库可以托管在未安装“机器学习服务”的SQL实例上。 Cacher是能够到达基于网络的系统的代理，因此可以保留在安装机器学习服务的SQL实例上。 两个SQL实例都可以具有单独的服务帐户身份，该身份已被授权仅连接到特定端口的Service Broker端点。 安全认证通信的另一种方法是使用证书。 对于Service Broker端点授权，请参阅,.aspx)以获取更多详细信息。,放置所有组件后，我们的WebApplication允许我们创建一个新的ProductType，并通过RESTful HTTP调用从刷新的缓存中列出相同的产品类型。 在墙后面有管理数据的组件，高速缓存对前端应用程序是不可见的。,诸如电子商务，医疗电子治理等应用可以从良好的缓存实现中受益。通过扩展我们熟悉的技术的使用，我们可以获得易于维护的解决方案，而无需学习新框架或功能的成本。,我们的示例解决方案符合我们所需要的"
http://python.jobbole.com/88767/,Python 为什么说 Eval 要慎用？使用 Eval 带来的潜在风险？什么情况下使用 Eval？,http://jbcdn2.b0.upaiyun.com/2015/02/edecceebedd0d04aa17bccba430ddcaf.jpg,2017-10-25,"当内存中的内置模块含有os的话，eval同样可以做到命令执行：,当然，eval只能执行Python的表达式类型的代码，不能直接用它进行import操作，但exec可以。如果非要使用eval进行import，则使用__import__：,在实际的代码中，往往有使用客户端数据带入eval中执行的需求。比如动态模块的引入，举个栗子，一个在线爬虫平台上爬虫可能有多个并且位于不同的模块中，服务器端但往往只需要调用用户在客户端选择的爬虫类型，并通过后端的exec或者eval进行动态调用，后端编码实现非常方便。但如果对用户的请求处理不恰当，就会造成严重的安全漏洞。,现在提倡最多的就是使用eval的后两个参数来设置函数的白名单：,Eval函数的声明为eval(expression[, globals[, locals]]),其中，第二三个参数分别指定能够在eval中使用的函数等，如果不指定，默认为globals()和locals()函数中 包含的模块和函数。,如果指定只允许调用abs函数，可以使用下面的写法：,使用这种方法来防护，确实可以起到一定的作用，但是，这种处理方法可能会被绕过，从而造成其他问题！,绕过执行代码1,被绕过的情景如下，小明知道了eval会带来一定的安全风险，所以使用如下的手段去防止eval执行任意代码：,Python中的__builtins__是内置模块，用来设置内置函数的模块。比如熟悉的abs，open等内置函数，都是在该模块中以字典的方式存储的，下面两种写法是等价的：,我们也可以自定义内置函数，并像使用Python中的内置函数一样使用它们：,小明将eval函数的作用域中的内置模块设置为None，好像看起来很彻底了，但依然可以被绕过。__builtins__是__builtin__的一个引用，在__main__模块下，两者是等价的：,根据乌云drops提到的方法，使用如下代码即可：,上面的代码首先利用__class__和__subclasses__动态加载了object对象，这是因为eval中无法直接使用object。然后使用object的子类的zipimporter对egg压缩文件中的configobj模块进行导入，并调用其内置模块中的os模块从而实现命令执行，当然，前提是要有configobj的egg文件。 configobj模块很有意思，居然内置了os模块：,和configobj类似的模块如urllib，urllib2，setuptools等都有os的内置，理论上使用哪个都行。 如果无法下载egg压缩文件，可以下载带有setup.py的文件夹，加入：,然后执行:,就可以在dist文件夹中找到对应的egg文件。 绕过demo如下：,object的子类中有很多有趣的东西，执行以下代码查看：,这里我就不输出结果了，如果你执行的话，可以看到很多有趣的模块，比如file，zipimporter，Quitter等。经过测试，file的构造函数是被解释器沙箱隔离的。 简单的，或者直接使object暴露出的子类Quitter进行退出：,C:/>,
如果运气好，遇到对方程序中导入了os等敏感模块，那么Popen就可以用，并且绕过__builins__为空的限制，例子如下：,事实上，这种情况非常多，比如导入os模块，一般用来处理路径问题。所以说，遇到这种情况，完全可以列举大量的功能函数，来探测目标object的子类中是否含有一些危险的函数可以直接使用。,同样，我们甚至可以绕过__builtins__为None，造成一次拒绝服务攻击，Payload(来自老外blog)如下：,运行上面的代码，Python直接crash掉了，造成拒绝服务攻击。 原理是通过嵌套的lambda来构造一片代码段，即code对象。为这个code对象分配空的栈，并给出相应的代码字符串，这里是KABOOM，在空栈上执行代码，会出现crash。构造完成后，调用fc函数即可触发，其思路不可谓不淫荡。,从上面的内容我们可以看出，单单将内置模块置为空，是不够的，最好的机制是构造白名单，如果觉得比较麻烦，可以使用ast.literal_eval代替不安全的eval。"
http://python.jobbole.com/88735/,《流畅的 Python 》阅读笔记,http://jbcdn2.b0.upaiyun.com/2017/10/74fe6d8c7b47cda27671bb237522e294.png,2017-10-24,"《流畅的python》是一本适合python进阶的书, 里面介绍的基本都是高级的python用法. 对于初学python的人来说, 基础大概也就够用了, 但往往由于够用让他们忘了深入, 去精通. 我们希望全面了解这个语言的能力边界, 可能一些高级的特性并不能马上掌握使用, 因此这本书是工作之余, 还有余力的人来阅读, 我这边就将其有用, 精妙的进阶内容整理出来.,这本书有21个章节, 整理也是根据这些章节过来.,这部分主要介绍了python的魔术方法, 它们经常是两个下划线包围来命名的(比如 , , ,, , ). 这些特殊方法是为了被python解释器调用的, 这些方法会注册到他们的类型中方法集合中, 相当于为cpython提供抄近路. 这些方法的速度也比普通方法要快, 当然在自己不清楚这些魔术方法的用途时, 不要随意添加.,关于字符串的表现形式是两种, , 与 , . python的内置函数 , 就是通过 , 这个特殊方法来得到一个对象的字符串表示形式. 这个在交互模式下比较常用, 如果没有实现 , , 当控制台打印一个对象时往往是 . 而 , 则是 , 函数时使用的, 或是在 , 函数打印一个对象的时候才被调用, 终端用户友好.,两者还有一个区别, 在字符串格式化时, , 对应了 , . 而 , 对应了 ,. , 和 , 在使用上比较推荐的是，前者是给终端用户看，而后者则更方便我们调试和记录日志.,更多的特殊方法: ,这部分主要是介绍序列, 着重介绍数组和元组的一些高级用法.,序列按照容纳数据的类型可以分为:,如果按照是否能被修改可以分为:,列表推导是构建列表的快捷方式, 可读性更好且效率更高.,例如, 把一个字符串变成unicode的码位列表的例子, 一般:,使用列表推导:,能用列表推导来创建一个列表, 尽量使用推导, 并且保持它简短.,生成器表达式是能逐个产出元素, 节省内存. 例如:,实例中列表元素比较少, 如果换成两个各有1000个元素的列表, 显然这样组合的笛卡尔积是一个含有100万元素的列表, 内存将会占用很大, 而是用生成器表达式就可以帮忙省掉for循环的开销.,元组经常被作为 , 的代表. 经常只要数字索引获取元素, 但其实它还可以给元素命名:,列表中是以0作为第一个元素的下标, 切片可以根据下标提取某一个片段.,用 , 的形式对 , 在 , 和 , 之间以 , 为间隔取值。, 的值还可以为负, 负值意味着反向取值., 类型不但在各种程序里广泛使用, 它也是 , 语言的基石. 正是因为 , 类型的重要, , 对其的实现做了高度的优化, 其中最重要的原因就是背后的「散列表」 set（集合）和dict一样, 其实现基础也是依赖于散列表.,散列表也叫哈希表, 对于dict类型, 它的key必须是可哈希的数据类型. 什么是可哈希的数据类型呢, 它的官方解释是:,的，而且这个对象需要实现 , 方法。另外可散列对象还要有,
, 方法，这样才能跟其他键做比较。如果两个可散列对象是相等的，那么它们的散列值一定是一样的……,, ,, , 和 , 都是可散列类型.,当某个键不在映射里, 我们也希望也能得到一个默认值. 这就是 , , 它是 , 的子类, 并实现了 , 方法.,标准库里 , 模块中，除了 , 之外的不同映射类型:,说到不可变, 第一想到的肯定是元组, 但是对于字典来说, 要将key和value的对应关系变成不可变, , 模块的 , 可以做到:, 是动态的, 也就是说对 , 所做的任何改动都会反馈到它上面.,集合的本质是许多唯一对象的聚集. 因此, 集合可以用于去重. 集合中的元素必须是可散列的, 但是 , 本身是不可散列的, 而 , 本身可以散列.,集合具有唯一性, 与此同时, 集合还实现了很多基础的中缀运算符. 给定两个集合 a 和 b, , 返,
回的是它们的合集, , 得到的是交集, 而 , 得到的是差集.,合理的利用这些特性, 不仅能减少代码的数量, 更能增加运行效率.,本章讨论了文本字符串和字节序列, 以及一些编码上的转换. 本章讨论的 , 指的是python3下的.,字符串是个比较简单的概念: 一个字符串是一个字符序列. 但是关于 , 的定义却五花八门, 其中, , 的最佳定义是 , . 因此, python3中的 , 对象中获得的元素就是 unicode 字符.,把码位转换成字节序列的过程就是 ,, 把字节序列转换成码位的过程就是 , :,码位可以认为是人类可读的文本, 而字符序列则可以认为是对机器更友好. 所以要区分 , 和 , 也很简单. 从字节序列到人类能理解的文本就是解码(decode). 而把人类能理解的变成人类不好理解的字节序列就是编码(encode).,python3有两种字节序列, 不可变的 , 类型和可变的 , 类型. 字节序列中的各个元素都是介于 , 之间的整数.,python自带了超过100中编解码器. 每个编解码器都有一个名称, 甚至有的会有一些别名, 如 , 就有 ,, ,, , 这些别名.,如果字符序列和预期不符, 在进行解码或编码时容易抛出 , 的异常. 造成这种错误是因为目标编码中没有定义某个字符(没有定义某个码位对应的字符), 这里说说解决这类问题的方式.,这两行代码完全等价. 而有一种是要避免的是, 在Unicode标准中 , 和 , 这样的序列叫 ,. 这种情况用NFC使用最少的码位构成等价的字符串:,改进后:,对于字符串来说, 比较的码位. 所以在非 ascii 字符时, 得到的结果可能会不尽人意.,在python中, 函数是一等对象. 编程语言把 , 定义为满足下列条件:,在python中, 整数, 字符串, 列表, 字典都是一等对象.,Python即可以函数式编程，也可以面向对象编程. 这里我们创建了一个函数, 然后读取它的 , 属性, 并且确定函数对象其实是 , 类的实例:,高阶函数就是接受函数作为参数, 或者把函数作为返回结果的函数. 如 ,, , , , 等.,比如调用 , 时, 将 , 作为参数传递:, 关键字是用来创建匿名函数. 匿名函数一些限制, 匿名函数的定义体只能使用纯表达式. 换句话说, , 函数内不能赋值, 也不能使用while和try等语句.,除了用户定义的函数, 调用运算符即 , 还可以应用到其他对象上. 如果像判断对象能否被调用, 可以使用内置的 , 函数进行判断. python的数据模型中有7种可是可以被调用的:,就是可变参数和关键字参数:,其中 , 和 , 都是可迭代对象, 展开后映射到单个参数. args是个元组, kwargs是字典.,虽然设计模式与语言无关, 但这并不意味着每一个模式都能在每一个语言中使用. Gamma 等人合著的 , 一书中有 , 个模式, 其中有 , 个在动态语言中”不见了, 或者简化了”.,这里不举例设计模式, 因为书里的模式不常用.,能，但是若想掌握，必须理解闭包。,修饰器和闭包经常在一起讨论, 因为修饰器就是闭包的一种形式. 闭包还是回调式异步编程和函数式编程风格的基础.,装饰器是可调用的对象, 其参数是另一个函数(被装饰的函数). 装饰器可能会处理被,
装饰的函数, 然后把它返回, 或者将其替换成另一个函数或可调用对象.,这种写法与下面写法完全等价:,装饰器是语法糖, 它其实是将函数作为参数让其他函数处理. 装饰器有两大特征:,要理解立即执行看下等价的代码就知道了, , 这句调用了函数. 一般情况下装饰函数都会将某个函数作为返回值.,要理解装饰器中变量的作用域, 应该要理解闭包, 我觉得书里将闭包和作用域的顺序换一下比较好. 在python中, 一个变量的查找顺序是 , (L：Local 局部环境，E：Enclosing 闭包，G：Global 全局，B：Built-in 内建).,在闭包的函数 , 中, 使用的变量 , 其实是 , 的. 因为base这个变量在闭包中就能命中, 而不需要去 , 中获取.,闭包其实挺好理解的, 当匿名函数出现的时候, 才使得这部分难以掌握. 简单简短的解释闭包就是:,这个名字空间就是 , 中的 , . 所以闭包不仅仅是将函数作为返回值. 而是将名字空间和函数捆绑后作为返回值的. 多少人忘了理解这个 , , 不知道变量最终取的哪和哪啊. 哎.,python内置了三个用于装饰方法的函数: , 、 , 和 , .,
这些是用来丰富类的.,很多人把变量理解为盒子, 要存什么数据往盒子里扔就行了.,变量 , 和 , 引用同一个列表, 而不是那个列表的副本. 因此赋值语句应该理解为将变量和值进行引用的关系而已.,要知道变量a和b是否是同一个值的引用, 可以用 , 来进行判断:,如果两个变量都是指向同一个对象, 我们通常会说变量是另一个变量的 , .,
运算符 , 是用来判断两个对象值是否相等(注意是对象值). 而 , 则是用于判断两个变量是否指向同一个对象, 或者说判断变量是不是两一个的别名, is 并不关心对象的值. 从使用上, , 使用比较多, 而 , 的执行速度比较快.,尽管 l2 是 l1 的副本, 但是复制的过程是先复制(即复制了最外层容器，副本中的元素是源容器中元素的引用). 因此在操作 l2[1] 时, l1[1] 也会跟着变化. 而如果列表中的所有元素是不可变的, 那么就没有这样的问题, 而且还能节省内存. 但是, 如果有可变元素存在, 就可能造成意想不到的问题.,python标准库中提供了两个工具 , 和 , . 分别用于浅拷贝与深拷贝:,python中的函数参数都是采用共享传参. 共享传参指函数的各个形式参数获得实参中各个引用的副本. 也就是说, 函数内部的形参,
是实参的别名.,这种方案就是当传入参数是可变对象时, 在函数内对参数的修改也就是对外部可变对象进行修改. 但这种参数试图重新赋值为一个新的对象时则无效, 因为这只是相当于把参数作为另一个东西的引用, 原有的对象并不变. 也就是说, 在函数内, 参数是不能把一个对象替换成另一个对象的.,参数默认值是个很棒的特性. 对于开发者来说, 应该避免使用可变对象作为参数默认值. 因为如果参数默认值是可变对象, 而且修改了它的内容, 那么后续的函数调用上都会收到影响.,在python中, 当一个对象失去了最后一个引用时, 会当做垃圾, 然后被回收掉. 虽然python提供了 , 语句用来删除变量. 但实际上只是删除了变量和对象之间的引用, 并不一定能让对象进行回收, 因为这个对象可能还存在其他引用.,在CPython中, 垃圾回收主要用的是引用计数的算法. 每个对象都会统计有多少引用指向自己. 当引用计数归零时, 意味着这个对象没有在使用, 对象就会被立即销毁.,行为，靠的不是继承，而是鸭子类型（duck typing）：我们只需按照预定行为实现对象所,
需的方法即可。,每门面向对象的语言至少都有一种获取对象的字符串表示形式的标准方式。Python 提供了,
两种方式。,这两个都是python内置提供了装饰器, 一般python教程都没有提到这两个装饰器. 这两个都是在类 , 定义中使用的, 一般情况下, class 里面定义的函数是与其类的实例进行绑定的. 而这两个装饰器则可以改变这种调用方式.,先来看看 , , 这个装饰器不是操作实例的方法, 并且将类本身作为第一个参数. 而 , 装饰器也会改变方法的调用方式, 它就是一个普通的函数,, 与 , 的区别就是 , 会把类本身作为第一个参数传入, 其他都一样了.,看看例子:,内置的 , 函数和 , 方法把各个类型的格式化方式委托给相应的 , 方法. , 是格式说明符，它是：,python中对于实例变量没有像 , 这样的修饰符来创建私有属性, 在python中, 有一个简单的机制来处理私有属性.,如果属性以 , 的 , 命名的实例属性, python会把它名称前面加一个下划线加类名, 再放入 , 中, 以 , 为例, 就会变成 , .,名称改写算是一种安全措施, 但是不能保证万无一失, 它能避免意外访问, 但不能阻止故意做坏事.,只要知道私有属性的机制, 任何人都能直接读取和改写私有属性. 因此很多python程序员严格规定: , . Python 解释器不会对使用单个下划线的属性名做特殊处理, 由程序员自行控制, 不在类外部访问这些属性. 这种方法也是所推荐的, 两个下划线的那种方式就不要再用了. 引用python大神的话:,确使用一种名称改写方式（如 _MyThing_blahblah）。这其实与使用双下划线一,
样，不过自己定的规则比双下划线易于理解。,默认情况下, python在各个实例中, 用 , 的字典存储实例属性. 因此实例的属性是动态变化的, 可以在运行期间任意添加属性. 而字典是消耗内存比较大的结构. 因此当对象的属性名称确定时, 使用 , 可以节约内存.,在类中定义, 属性的目的是告诉解释器：”这个类中的所有实例属性都在这儿,
了！” 这样, Python 会在各个实例中使用类似元组的结构存储实例变量, 从而避免使用消,
耗内存的 , 属性. 如果有数百万个实例同时活动, 这样做能节省大量内存.,在python中, 序列类型不需要使用继承, 只需要符合序列协议的方法即可. 这里的协议就是实现 , 和 , 两个方法. 任何类, 只要实现了这两个方法, 它就满足了序列操作, 因为它的行为像序列.,协议是非正式的, 没有强制力, 因此你知道类的具体使用场景, 通常只要实现一个协议的部分. 例如, 为了支持迭代, 只需实现 , 方法, 没必要提供 , 方法, 这也就解释了 , :,那么这只鸟就可以被称为鸭子,切片(Slice)是用来获取序列某一段范围的元素. 切片操作也是通过 , 来完成的:,通过访问分量名来获取属性:,实现 , 方法。加上现有的 , 方法，这会把实例变成可散列的对象.,当序列是多维是时候, 我们有一个效率更高的方法:,这些协议定义为非正式的接口, 是让编程语言实现多态的方式. 在python中, 没有 , 关键字, 而且除了抽象基类, 每个类都有接口: 所有类都可以自行实现 , 和 , .,有写规定则是程序员在开发过程中慢慢总结出来的, 如受保护的属性命名采用单个前导下划线, 还有一些编码规范之类的.,协议是接口, 但不是正式的, 这些规定并不是强制性的, 一个类可能只实现部分接口, 这是允许的.,既然有非正式的协议, 那么有没有正式的协议呢? 有, 抽象基类就是一种强制性的协议.,抽象基类要求其子类需要实现定义的某个接口, 且抽象基类不能实例化.,引入抽象基类之前, python就已经非常成功了, 即使现在也很少使用抽象基类. 通过鸭子类型和协议, 我们把协议定义为非正式接口, 是让python实现多态的方式.,另一边面, 不要觉得把公开数据属性放入对象的接口中不妥, 如果需要, 总能实现读值和设值方法, 把数据属性变成特性. 对象公开方法的自己, 让对象在系统中扮演特定的角色. 因此, 接口是实现特定角色的方法集合.,序列协议是python最基础的协议之一, 即便对象只实现那个协议最基本的一部分, 解释器也会负责地处理.,鸭子类型在很多情况下十分有用, 但是随着发展, 通常由了更好的方式.,近代, 属和种基本是根据表型系统学分类的, 鸭科属于水禽, 而水禽还包括鹅, 鸿雁等. 水禽是对某一类表现一致进行的分类, 他们有一些统一”描述”部分.,因此, 根据分类的演化, 需要有个水禽类型, 只要 , 是抽象基类, 即 , 的元类是 , , 就可以使用 , 来进行判断.,与具类相比, 抽象基类有很多理论上的优点, 被注册的类必须满足抽象基类对方法和签名的要求, 更重要的是满足底层语义契约.,大多数的标准库的抽象基类在 , 模块中定义. 少部分在 , 和 , 包中有一些抽象基类. 标准库中有两个 , 模块, 这里只讨论 , .,这个模块中定义了 16 个抽象基类.,
各个集合应该继承这三个抽象基类，或者至少实现兼容的协议。, 通过 , 方法支持迭代，Container 通过 , 方法支持 in 运算符，Sized,
通过 , 方法支持 len() 函数。,
这三个是主要的不可变集合类型，而且各自都有可变的子类。,
在 Python3 中，映射方法 ,、, 和 , 返回的对象分别是,
ItemsView、KeysView 和 ValuesView 的实例。前两个类还从 Set 类继承了丰富的接,
口。,
这两个抽象基类与集合没有太大的关系，只不过因为 , 是标准库中,
定义抽象基类的第一个模块，而它们又太重要了，因此才把它们放到 ,
模块中。我从未见过 , 或 , 的子类。这两个抽象基类的主要作用是为内,
置函数 , 提供支持，以一种安全的方式判断对象能不能调用或散列。,
注意它是 Iterable 的子类。,很多人觉得多重继承得不偿失, 那些不支持多继承的编程语言好像也没什么损失.,python2.2 以前, 内置类型(如list, dict)是不能子类化的. 它们是不能被其他类所继承的, 原因是内置类型是C语言实现的, 不会调用用户定义的类覆盖的方法.,至于内置类型的子类覆盖的方法会不会隐式调用, CPython 官方也没有制定规则. 基本上, 内置类型的方法不会调用子类覆盖的方法. 例如, dict 的子类覆盖的 , 方法不会覆盖内置类型的 , 方法调用.,任何实现多重继承的语言都要处理潜在的命名冲突，这种冲突由不相关的祖先类实现同名,
方法引起。这种冲突称为“菱形问题”，如图.,Python 会按照特定的顺序遍历继承,
图。这个顺序叫方法解析顺序（Method Resolution Order，MRO）。类都有一个名为,
, 的属性，它的值是一个元组，按照方法解析顺序列出各个超类，从当前类一直,
向上，直到 object 类。,在python中, 大多数的运算符是可以重载的, 如 , 对应了 , , , 对应 , .,某些运算符不能重载, 如 ,.,迭代是数据处理的基石. 扫描内存中放不下的数据集时, 我们要找到一种惰性获取数据的方式, 即按需一次获取一个数据. 这就是 , .,python中有 , 关键字, 用于构建 ,, 其作用用于迭代器一样.,所有的生成器都是迭代器, 因为生成器完全实现了迭代器的接口.,检查对象 x 是否迭代, 最准确的方法是调用 , , 如果不可迭代, 则抛出 , 异常. 这个方法比 , 更准确, 因为它还考虑到遗留的 , 方法.,我们需要对可迭代的对象进行一下定义:, 方法，那么对象就是可迭代的。序列都可以迭代；实现了 , 方,
法，而且其参数是从零开始的索引，这种对象也可以迭代。,我们要明确可迭代对象和迭代器之间的关系: 从可迭代的对象中获取迭代器.,标准的迭代器接口有两个方法:,为了清楚地说明可迭代对象与迭代器之间的重要区别, 我们将两者分开, 写成两个类:,这个例子主要是为了区分可迭代对象和迭代器, 这种情况工作量一般比较大, 程序员也不愿这样写.,构建可迭代对象和迭代器经常会出现错误, 原因是混淆了二者. 要知道, 可迭代的对象有个 , 方法, 每次都实例化一个新的迭代器; 而迭代器是要实现 , 方法, 返回单个元素, 同时还要提供 , 方法返回迭代器本身.,可迭代对象一定不能是自身的迭代器. 也就是说, 可迭代对象必须实现 , 方法, 但不能实现 , 方法.,小结下, 迭代器可以迭代, 但是可迭代对象不是迭代器.,实现相同功能, 覆盖python习惯的方式, 就是用生成器代替迭代器 , . 将上个例子改成生成器的方式:,在这个例子中, 迭代器其实就是生成器对象, 每次调用 , 都会自动创建, 因为这里的 , 方法是生成器函数.,
只要python函数的定义体中有 , 关键字, 改函数就是生成器函数. 调用生成器函数时, 会返回一个生成器对象. 也就是说, 生成器函数是生成器工厂.,普通函数与生成器函数的唯一区别就是, 生成器函数里面有 , 关键字.,生成器函数会创建一个生成器对象, 包装生成器函数的定义体. 吧生成器传给 , 函数时, 生成器函数会向前, 执行函数体中下一个 , 语句, 返回产出的值, 并在函数定义体的当前位置暂停.,惰性的方式就是索性把所有数据都产出, 这是区别于 , 一次生成一次元素的.,生成器表达式可以理解为列表推导的惰性版本: 不会迫切地构建列表, 而是返回一个生成器, 按需惰性生成元素. 也就是, 如果列表推导是产出列表的工厂, 那么生成器表达式就是产出生成器的工厂.,可以看出, 生成器表达式会产出生成器, 因此可以使用生成器表达式减少代码:,这里的 , 不是生成器函数了, 而是使用生成器表达式构建生成器, 最终的效果一样. 调用 , 方法会得到一个生成器对象.,生成器表达式是语法糖, 完全可以替换生成器函数.,标准库提供了很多生成器, 有用于逐行迭代纯文本文件的对象, 还有出色的 , 函数. 这个函数在遍历目录树的过程中产出文件名, 因此递归搜索文件系统像 for 循环那样简单.,标准库中的生成器大多在 , 和 , 中, 表格中不代表所有.,如果生成器函数需要产出另一个生成器生成的值, 传统的方式是嵌套的 for 循环, 例如, 我们要自己实现 , 生成器:, 生成器函数把操作依次交给接收到的可迭代对象处理. 而改用 , 语句可以简化:,可以看出, , 取代一个 for 循环. 并且让代码读起来更流畅.,有些函数接受可迭代对象, 但仅返回单个结果, 这类函数叫规约函数.,本章讨论的是其他语言不常见的流程控制特性, 正因如此, python新手往往忽视或没有充分使用这些特性. 下面讨论的特性有:, 语句会设置一个临时的上下文, 交给上下文管理器对象控制, 并且负责清理上下文. 这么做能避免错误并减少代码量, 因此API更安全, 而且更易于使用. 除了自动关闭文件之外, with 块还有其他很多用途., 子句先做这个，选择性再做那个的作用.,这里的 else 不是在在 if 语句中使用的, 而是在 for while try 语句中使用的., 子句的行为如下:,在所有情况下, 如果异常或者 , , , 或 , 语句导致控制权跳到了复合语句的住块外, , 子句也会被跳过.,这一些情况下, 使用 else 子句通常让代码更便于阅读, 而且能省去一些麻烦, 不用设置控制标志作用的变量和额外的if判断.,上下文管理器对象的目的就是管理 , 语句, with 语句的目的是简化 , 模式. 这种模式用于保证一段代码运行完毕后执行某项操作, 即便那段代码由于异常, , 或者 , 调用而终止, 也会执行执行的操作. , 子句中的代码通常用于释放重要的资源, 或者还原临时变更的状态.,上下文管理器协议包含 , 和 , 两个方法. with 语句开始运行时, 会在上下文管理器上调用 , 方法, 待 with 语句运行结束后, 再调用 , 方法, 以此扮演了 , 子句的角色.,with 最常见的例子就是确保关闭文件对象.,上下文管理器调用 , 没有参数, 而调用 , 时, 会传入3个参数:,在ptyhon的标准库中, contextlib 模块中还有一些类和其他函数，使用范围更广。,显然，在这些实用工具中，使用最广泛的是 , 装饰器，因此要格外留心。这个装饰器也有迷惑人的一面，因为它与迭代无关，却要使用 yield 语句。,@contextmanager 装饰器能减少创建上下文管理器的样板代码量, 因为不用定义 , 和 , 方法, 只需要实现一个 , 语句的生成器., 语句起到了分割的作用, yield 语句前面的所有代码在 with 块开始时（即解释器调用 , 方法时）执行， yield 语句后面的代码在 with 块结束时（即调用 , 方法时）执行.,为了理解协程的概念, 先从 , 来说. , 会产出一个值, 提供给 , 调用方; 此外还会做出让步, 暂停执行生成器, 让调用方继续工作, 直到需要使用另一个值时再调用 , 从暂停的地方继续执行.,从句子语法上看, 协程与生成器类似, 都是通过 , 关键字的函数. 可是, 在协程中, , 通常出现在表达式的右边(datum = yield), 可以产出值, 也可以不产出(如果yield后面没有表达式, 那么会产出None). 协程可能会从调用方接收数据, 不过调用方把数据提供给协程使用的是 , 方法. 而不是 , . 通常, 调用方会把值推送给协程.,生成器调用方是一直索要数据, 而协程这是调用方可以想它传入数据, 协程也不一定要产出数据.,不管数据如何流动, , 都是一种流程控制工具, 使用它可以实现写作式多任务: 协程可以把控制器让步给中心调度程序, 从而激活其他的协程.,协程的底层框架实现后, 生成器API中增加了 , 方法. 生成器的调用方可以使用 , 来发送数据, 发送的数据会变成生成器函数中 , 表达式的值. 因此, 生成器可以作为协程使用. 除了 , 方法, 还添加了 , 和 , 方法, 用来让调用方抛出异常和终止生成器.,在 , 表达式中, 如果协程只需从调用那接受数据, 那么产出的值是 , . 与创建生成器的方式一样, 调用函数得到生成器对象. 协程都要先调用 , 函数, 因为生成器还没启动, 没在 yield 出暂定, 所以一开始无法发送数据. 如果控制器流动到协程定义体末尾, 会像迭代器一样抛出 , 异常.,使用协程的好处是不用加锁, 因为所有协程只在一个线程中运行, 他们是非抢占式的. 协程也有一些状态, 可以调用 , 来获得, 协程都是这4个状态中的一种:,只有在多线程应用中才能看到这个状态。此外，生成器对象在自己身上调用 , 函数也行，不过这样做没什么用。,为了更好理解继承的行为, 来看看产生两个值的协程:,关键的一点是, 协程在 , 关键字所在的位置暂停执行. 对于 , 这行代码来说, 等到客户端代码再激活协程时才会设定 b 的值. 这种方式要花点时间才能习惯, 理解了这个, 才能弄懂异步编程中 , 的作用. 对于实例的代码中函数 , 的执行过程可以分为三个阶段:,这是一个动态计算平均值的协程代码, 这个无限循环表明, 它会一直接收值然后生成结果. 只有当调用方在协程上调用 , 方法, 或者没有该协程的引用时, 协程才会终止.,协程的好处是, 无需使用实例属性或者闭包, 在多次调用之间都能保持上下文.,如果没有执行 , , 协程没什么用. 为了简化协程的用法, 有时会使用一个预激装饰器.,协程中未处理的异常会向上冒泡, 传给 , 函数或者 , 的调用方. 如果这个异常没有处理, 会导致协程终止.,这要求在协程内部要处理这些异常, 另外, 客户端代码也可以显示的发送异常给协程, 方法是 , 和 , :,协程内部如果不能处理这个异常, 就会导致协程终止.,而 , 是致使在暂停的 , 表达式处抛出 , 异常. 协程内部当然允许处理这个异常, 但收到这个异常时一定不能产出值, 不然解释器会抛出 , 异常.,为了返回值, 协程必须正常终止, 而正常终止的的协程会抛出 , 异常, 因此需要调用方处理这个异常., 是全新的语法结构. 它的作用比 , 多很多.,可以改写成:,在生成器 , 中使用 , 时, subgen 会得到控制权, 把产出的值传给 gen 的调用方, 既调用方可以直接调用 subgen. 而此时, gen 会阻塞, 等待 subgen 终止., 表达式对 , 对象所做的第一件事是, 调用 , 获得迭代器. 因此, x 对象可以是任何可迭代对象.,这个语义过于复杂, 来看看作者 , 的解释:,中。此外，子生成器可以执行 return 语句，返回一个值，而返回的值会成为 yield,
from 表达式的值。”,子生成器是从 ,中获得的生成器. 而后, 如果调用方使用 , 方法, 其实也是直接传给子生成器. 如果发送的是 , , 那么会调用子生成器的 , 方法. 如果不是 , , 那么会调用子生成器的 , 方法. 当子生成器抛出 , 异常, 那么委派生成器恢复运行. 任何其他异常都会向上冒泡, 传给委派生成器.,生成器在 , 表达式中会触发 , 异常., 是什么概念呢? 期物指一种对象, 表示异步执行的操作. 这个概念是 , 模块和 , 包的基础.,为了高效处理网络io, 需要使用并发, 因为网络有很高的延迟, 所以为了不浪费 CPU 周期去等待.,以一个下载网络 20 个图片的程序看, 串行下载的耗时 7.18s . 多线程的下载耗时 1.40s, asyncio的耗时 1.35s . 两个并发下载的脚本之间差异不大, 当对于串行的来说, 快了很多.,CPython解释器不是线程安全的, 因此有全局解释锁(GIL), 一次只允许使用一个线程执行 python 字节码, 所以一个python进程不能同时使用多个 CPU 核心.,python程序员编写代码时无法控制 GIL, 然而, 在标准库中所有执行阻塞型I/O操作的函数, 在登台操作系统返回结果时都会释放GIL. 这意味着IO密集型python程序能从中受益.,一个python进程只有一个 GIL. 多个python进程就能绕开GIL, 因此这种方法就能利用所有的 CPU 核心. , 模块就实现了真正的并行计算, 因为它使用 , 把工作交个多个python进程处理., 和 , 类都实现了通用的 , 接口, 因此使用 , 能很轻松把基于线程的方案转成基于进程的方案.,改成:, 方法需要 , 参数，指定线程池中线程的数量; 在 , 类中, 这个参数是可选的.,并行是指一次做多件事。,
二者不同，但是有联系。,
一个关于结构，一个关于执行。,
并发用于制定方案，用来解决可能（但未必）并行的问题。—— Rob Pike Go 语言的创造者之一,并行是指两个或者多个事件在同一时刻发生, 而并发是指两个或多个事件在同一时间间隔发生. 真正运行并行需要多个核心, 现在笔记本一般有 4 个 CPU 核心, 但是通常就有超过 100 个进程同时运行. 因此, 实际上大多数进程都是并发处理的, 而不是并行处理. 计算机始终运行着 100 多个进程, 确保每个进程都有机会取得发展, 不过 CPU 本身同时做的事情不会超过四件.,本章介绍 , 包, 这个包使用事件循环驱动的协程实现并发. 这个库有龟叔亲自操刀. , 大量使用 , 表达式, 因此不兼容 python3.3 以下的版本.,一个借由 , 模块使用线程, 一个借由 , 包使用协程实现来进行比对.,这是使用 , 的案例, 让子线程在 3 秒内不断打印, 在python中, 没有提供终止线程的API. 若想关闭线程, 必须给线程发送消息.,下面看看使用 , 装饰器替代协程, 实现相同的行为:, 包使用的协程是比较严格的定义, 适合 asyncio API 的协程在定义体中必须使用 , , 而不是使用 , . 此外, , 的协程要由调用方驱动, 例如 , , 从而驱动协程. 最后由 , 装饰器应用在协程上.,这两种 , 实现之间的主要区别概述如下:,多线程编程是比较困难的, 因为调度程序任何时候都能中断线程, 必须记住保留锁, 去保护程序中重要部分, 防止多线程在执行的过程中断.,而协程默认会做好全方位保护, 以防止中断. 我们必须显示产出才能让程序的余下部分运行. 对协程来说, 无需保留锁, 而在多个线程之间同步操作, 协程自身就会同步, 因为在任意时刻, 只有一个协程运行.,在 , 包中, 期物和协程关系紧密, 因为可以使用 , 从 , 对象中产出结果. 也就是说, 如果 , 是协程函数, 或者是返回 , 或 , 实例的普通函数, 那么可以用 , .,为了执行这个操作, 必须排定协程的运行时间, 然后使用 , 对象包装协程. 对协程来说, 获取 , 对象主要有两种方式:, 包中有多个函数会自动(使用 , 函数) 把参数指定的协程包装在 , 对象中., 包只直接支持 TCP 和 UDP. 如果像使用 HTTP 或其他协议, 就需要借助第三方包. 使用的几乎都是 , 包. 以下载图片为例:, 协程参数是一个由期物或协程构成的可迭代对象, wait 会分别把各个协程装进一个 , 对象. 最终的结果是, wait 处理的所有对象都通过某种方式变成 , 类的实例. wait 是协程函数, 因此返回的是一个协程或生成器对象. 为了驱动协程, 我们把协程传给 , 方法., 方法的参数是一个期物或协程. 如果是协程, , 方法与 wait 函数一样, 把协程包装进一个 , 对象中. 因为协程都是由 , 驱动, 这正是 , 对 wait 返回返回的 wait_coro 对象所做的事. 运行结束后返回两个元素, 第一个是是结束的期物, 第二个是未结束的期物.,有两种方法能避免阻塞型调用中止整个应用程序的进程:,多线程是可以的, 但是会消耗比较大的内存. 为了降低内存的消耗, 通常使用回调来实现异步调用. 这是一种底层概念, 类似所有并发机制中最古老最原始的那种–硬件中断. 使用回调时, 我们不等待响应, 而是注册一个函数, 在发生某件事时调用. 这样, 所有的调用都是非阻塞的.,异步应用程序底层的事件循环能依靠基础设置的中断, 线程, 轮询和后台进程等待等, 确保多个并发请求能取得进展并最终完成, 这样才能使用回调. 事件循环获得响应后, 会回过头来调用我们指定的回调. 如果做法正确, 事件循环和应用代码公共的主线程绝不会阻塞.,把生成器当做协程使用是异步编程的另一种方式. 对事件循环来说, 调用回调与在暂停的协程上调用 , 效果差不多.,访问本地文件会阻塞, 而CPython底层在阻塞型I/O调用时会释放 GIL, 因此另一个线程可以继续.,因为 , 事件不是通过多线程来完成, 因此 , 用来保存图片的函数阻塞了与 , 事件循环共用的唯一线程, 因此保存文件时, 真个应用程序都会冻结. 这个问题的解决办法是, 使用事件循环对象的 , 方法., 的事件循环背后维护者一个 , 对象, 我们可以调用 , 方法, 把可调用的对象发给它执行:,在python中, 数据的属性和处理数据的方法都可以称为 , . 除了属性, pythpn 还提供了丰富的 API, 用于控制属性的访问权限, 以及实现动态属性, 如 , 方式和 , 计算属性.,动态创建属性是一种元编程,,通常, 解析后的 json 数据需要形如 , 形式访问, 必要情况下我们可以将它换成以属性访问方式 , 获得那个值.,我们通常把 , 成为构造方法, 这是从其他语言借鉴过来的术语. 其实, 用于构造实例的特殊方法是 , : 这是个类方法, 必须返回一个实例. 返回的实例将作为以后的 , 传给 , 方法.,描述符是实现了特性协议的类, 这个协议包括 ,, , 和 , 方法. 通常, 可以实现部分协议.,python存取属性的方式是不对等的. 通过实例读取属性时, 通常返回的是实例中定义的属性, 但是, 如果实例中没有指定的属性, 那么会从获取类属性. 而实例中属性赋值时, 通常会在实例中创建属性, 根本不影响类.,这种不对等的处理方式对描述符也有影响. 根据是否定义 , 方法, 描述符可分为两大类: 覆盖型描述符和与非覆盖型描述符.,实现 , 方法的描述符属于覆盖型描述符, 因为虽然描述符是类属性, 但是实现 , 方法的话, 会覆盖对实例属性的赋值操作. 因此作为类方法的 , 需要传入一个实例 , . 看个例子:,名为 , 的实例属性, 会覆盖读取和赋值 , 的行为.,只有在赋值操作的时候才回覆盖行为.,python的类中定义的函数属于绑定方法, 如果用户定义的函数都有 , 方法, 所以依附到类上, 就相当于描述符., 和 , 获取的是不同的对象. 前者是 后者是 .,函数都是非覆盖型描述符. 在函数上调用 , 方法时传入实例作为 , , 得到的是绑定到那个实例的方法. 调用函数的 , 时传入的 instance 是 , , 那么得到的是函数本身. 这就是形参 , 的隐式绑定方式.,
内置的 , 类创建的是覆盖型描述符, , 和 , 都实现了.,
如果要实现只读属性, , 和 , 两个方法必须都定义, 柔则, 实例的同名属性会覆盖描述符.,
什么是用于验证的描述符, 比方有个年龄属性, 但它只能被设置为数字, 这时候就可以只定义 , 来验证值是否合法. 这种情况不需要设置 , , 因为实例属性直接从 , 中获取, 而不用去触发 , 方法.,类元编程是指在运行时创建或定制类的技艺. 在python中, 类是一等对象, 因此任何时候都可以使用函数创建类, 而无需使用 , 关键字. 类装饰器也是函数, 不过能够审查, 修改, 甚至把被装饰的类替换成其他类.,元类是类元编程最高级的工具. 什么是元类呢? 比如说 , 是创建字符串的类, , 是创建整数的类. 那么元类就是创建类的类. 所有的类都由元类创建. 其他 , 只是原来的”实例”.,本章讨论如何在运行时创建类.,标准库中就有一个例子是类工厂函数–具名元组( , ). 我们把一个类名和几个属性传给这个函数, 它会创建一个 , 的子类, 其中的元素通过名称获取.,假设我们创建一个 , , 与具名元组具有相似的功能:,我们要做一个在运行时创建类的, 类工厂函数:, 就是元类, 实例的最后一行会构造一个类, 类名是 ,, 唯一直接的超类是 , .,在python中做元编程时, 最好不要用 , 和 , 函数. 这两个函数会带来严重的安全风险.,元类是制造类的工厂, 不过不是函数, 本身也是类. ,.,为了避免无限回溯, , 是其自身的实例. , 类和 , 类关系很独特, , 是 , 的实例, 而 , 是 , 的子类., 构造方法以及元类的 , 和 , 方法都会收到要计算的类的定义体, 形式是名称到属性的映像. 在默认情况下, 这个映射是字典, 属性在类的定义体中顺序会丢失. 这个问题的解决办法是, 使用python3引入的特殊方法 , , 这个方法只在元类中有用, 而且必须声明为类方法(即要使用 , 装饰器定义). 解释器调用元类的 , 方法之前会先调用 , 方法, 使用类定义体中的属性创建映射., 的第一个参数是元类, 随后两个参数分别是要构建类的名称和基类组成的原则, 返回值必须是映射.,python是一门即容易上手又强大的语言."
